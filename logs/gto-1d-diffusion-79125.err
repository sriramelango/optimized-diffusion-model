2025-08-24 18:45:59,095 - Training run started at: 2025.08.24_184559
2025-08-24 18:45:59,095 - Run directory: Training Runs/2025.08.24_184559
2025-08-24 18:46:18,417 - Unet1D(
  (init_conv): Conv1d(3, 128, kernel_size=(7,), stride=(1,), padding=(3,))
  (time_mlp): Sequential(
    (0): RandomOrLearnedSinusoidalPosEmb()
    (1): Linear(in_features=17, out_features=512, bias=True)
    (2): GELU(approximate='none')
    (3): Linear(in_features=512, out_features=512, bias=True)
  )
  (classes_mlp): Sequential(
    (0): Linear(in_features=1, out_features=128, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=256, out_features=512, bias=True)
  )
  (downs): ModuleList(
    (0): ModuleList(
      (0-1): 2 x ResnetBlock(
        (mlp): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1024, out_features=256, bias=True)
        )
        (block1): Block(
          (proj): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (block2): Block(
          (proj): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (res_conv): Identity()
      )
      (2): Residual(
        (fn): PreNorm(
          (fn): LinearAttention(
            (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
            (to_out): Sequential(
              (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
              (1): RMSNorm()
            )
          )
          (norm): RMSNorm()
        )
      )
      (3): Conv1d(128, 512, kernel_size=(4,), stride=(2,), padding=(1,))
    )
    (1): ModuleList(
      (0-1): 2 x ResnetBlock(
        (mlp): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (block1): Block(
          (proj): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (block2): Block(
          (proj): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (res_conv): Identity()
      )
      (2): Residual(
        (fn): PreNorm(
          (fn): LinearAttention(
            (to_qkv): Conv1d(512, 384, kernel_size=(1,), stride=(1,), bias=False)
            (to_out): Sequential(
              (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (1): RMSNorm()
            )
          )
          (norm): RMSNorm()
        )
      )
      (3): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))
    )
    (2): ModuleList(
      (0-1): 2 x ResnetBlock(
        (mlp): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (block1): Block(
          (proj): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (block2): Block(
          (proj): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (res_conv): Identity()
      )
      (2): Residual(
        (fn): PreNorm(
          (fn): LinearAttention(
            (to_qkv): Conv1d(512, 384, kernel_size=(1,), stride=(1,), bias=False)
            (to_out): Sequential(
              (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (1): RMSNorm()
            )
          )
          (norm): RMSNorm()
        )
      )
      (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (ups): ModuleList(
    (0): ModuleList(
      (0-1): 2 x ResnetBlock(
        (mlp): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1024, out_features=2048, bias=True)
        )
        (block1): Block(
          (proj): Conv1d(1536, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (block2): Block(
          (proj): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (res_conv): Conv1d(1536, 1024, kernel_size=(1,), stride=(1,))
      )
      (2): Residual(
        (fn): PreNorm(
          (fn): LinearAttention(
            (to_qkv): Conv1d(1024, 384, kernel_size=(1,), stride=(1,), bias=False)
            (to_out): Sequential(
              (0): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
              (1): RMSNorm()
            )
          )
          (norm): RMSNorm()
        )
      )
      (3): Sequential(
        (0): Upsample(size=11, mode='nearest')
        (1): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
      )
    )
    (1): ModuleList(
      (0-1): 2 x ResnetBlock(
        (mlp): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (block1): Block(
          (proj): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (block2): Block(
          (proj): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (res_conv): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
      )
      (2): Residual(
        (fn): PreNorm(
          (fn): LinearAttention(
            (to_qkv): Conv1d(512, 384, kernel_size=(1,), stride=(1,), bias=False)
            (to_out): Sequential(
              (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (1): RMSNorm()
            )
          )
          (norm): RMSNorm()
        )
      )
      (3): Sequential(
        (0): Upsample(size=22, mode='nearest')
        (1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
      )
    )
    (2): ModuleList(
      (0-1): 2 x ResnetBlock(
        (mlp): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (block1): Block(
          (proj): Conv1d(640, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (block2): Block(
          (proj): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)
          (act): SiLU()
        )
        (res_conv): Conv1d(640, 512, kernel_size=(1,), stride=(1,))
      )
      (2): Residual(
        (fn): PreNorm(
          (fn): LinearAttention(
            (to_qkv): Conv1d(512, 384, kernel_size=(1,), stride=(1,), bias=False)
            (to_out): Sequential(
              (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (1): RMSNorm()
            )
          )
          (norm): RMSNorm()
        )
      )
      (3): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (mid_block1): ResnetBlock(
    (mlp): Sequential(
      (0): SiLU()
      (1): Linear(in_features=1024, out_features=2048, bias=True)
    )
    (block1): Block(
      (proj): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)
      (act): SiLU()
    )
    (block2): Block(
      (proj): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)
      (act): SiLU()
    )
    (res_conv): Identity()
  )
  (mid_attn): Residual(
    (fn): PreNorm(
      (fn): Attention(
        (to_qkv): Conv1d(1024, 768, kernel_size=(1,), stride=(1,), bias=False)
        (to_out): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))
      )
      (norm): RMSNorm()
    )
  )
  (mid_block2): ResnetBlock(
    (mlp): Sequential(
      (0): SiLU()
      (1): Linear(in_features=1024, out_features=2048, bias=True)
    )
    (block1): Block(
      (proj): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)
      (act): SiLU()
    )
    (block2): Block(
      (proj): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)
      (act): SiLU()
    )
    (res_conv): Identity()
  )
  (final_res_block): ResnetBlock(
    (mlp): Sequential(
      (0): SiLU()
      (1): Linear(in_features=1024, out_features=256, bias=True)
    )
    (block1): Block(
      (proj): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm): GroupNorm(8, 128, eps=1e-05, affine=True)
      (act): SiLU()
    )
    (block2): Block(
      (proj): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm): GroupNorm(8, 128, eps=1e-05, affine=True)
      (act): SiLU()
    )
    (res_conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
  )
  (final_conv): Conv1d(128, 3, kernel_size=(1,), stride=(1,))
)
2025-08-24 18:46:18,420 - EMA: <models.ema.ExponentialMovingAverage object at 0x15538bfba4d0>
2025-08-24 18:46:18,421 - Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0002
    maximize: False
    weight_decay: 0
)
2025-08-24 18:46:18,421 - Scaler: None.
2025-08-24 18:46:18,421 - No checkpoint found at Training Runs/2025.08.24_184559/checkpoints-meta/checkpoint.pth. Returned the same state as input
2025-08-24 18:46:18,609 - Starting training loop at step 0.
2025-08-24 18:47:27,462 - step: 0, training_loss: 5.30363e+00
2025-08-24 18:47:27,765 - step: 0, evaluation_loss: 5.84039e+00
2025-08-24 18:47:56,307 - step: 50, training_loss: 7.76619e-01
2025-08-24 18:48:43,971 - step: 100, training_loss: 5.09101e-01
2025-08-24 18:49:50,691 - step: 150, training_loss: 4.50825e-01
2025-08-24 18:51:16,447 - step: 200, training_loss: 4.26276e-01
2025-08-24 18:53:01,355 - step: 250, training_loss: 4.13314e-01
2025-08-24 18:55:05,127 - step: 300, training_loss: 5.97214e-01
2025-08-24 18:57:27,876 - step: 350, training_loss: 5.21899e-01
2025-08-24 19:00:09,675 - step: 400, training_loss: 4.26959e-01
2025-08-24 19:03:10,425 - step: 450, training_loss: 4.02660e-01
2025-08-24 19:06:30,547 - step: 500, training_loss: 4.25586e-01
2025-08-24 19:06:30,628 - step: 500, evaluation_loss: 3.66364e-01
2025-08-24 19:06:31,956 - Generating samples at step: 500
Error executing job with overrides: []
Traceback (most recent call last):
  File "/scratch/gpfs/se7159/Second-Model/optimized-diffusion-model/Reflected-Diffusion/run_train.py", line 327, in main
    _run_single(cfg, work_dir, checkpoint_path=cfg.checkpoint_path)
  File "/scratch/gpfs/se7159/Second-Model/optimized-diffusion-model/Reflected-Diffusion/run_train.py", line 294, in _run_single
    sample, n = sampling_fn(score_model, weight=weight, class_labels=class_labels)
  File "/scratch/gpfs/se7159/Second-Model/optimized-diffusion-model/Reflected-Diffusion/sampling.py", line 347, in pc_sampler
    x, x_mean = pred.update_fn(x, vec_t)
  File "/scratch/gpfs/se7159/Second-Model/optimized-diffusion-model/Reflected-Diffusion/sampling.py", line 201, in update_fn
    drift, diffusion = self.rsde.sde(x, t)
  File "/scratch/gpfs/se7159/Second-Model/optimized-diffusion-model/Reflected-Diffusion/sde_lib.py", line 96, in sde
    score = score_fn(x, t)
  File "/scratch/gpfs/se7159/Second-Model/optimized-diffusion-model/Reflected-Diffusion/models/utils.py", line 125, in weighted_score_fn
    concat_score = score_fn(concat_x, concat_t, concat_cl)
  File "/scratch/gpfs/se7159/Second-Model/optimized-diffusion-model/Reflected-Diffusion/models/utils.py", line 102, in score_fn
    score = model_fn(x, time_cond, class_labels=class_labels)
  File "/scratch/gpfs/se7159/Second-Model/optimized-diffusion-model/Reflected-Diffusion/models/utils.py", line 82, in model_fn
    return model(x, time_cond, class_labels=class_labels)
  File "/home/se7159/miniconda3/envs/diffusion-env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/gpfs/se7159/Second-Model/optimized-diffusion-model/Reflected-Diffusion/models/unet1d_gto.py", line 828, in forward
    classes_emb = torch.where(
RuntimeError: The size of tensor a (2) must match the size of tensor b (4000) at non-singleton dimension 0

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
