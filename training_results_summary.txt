2025-07-02 18:56:33,356 - step: 0, training_loss: 1.81734e+01
2025-07-02 18:56:33,764 - step: 0, evaluation_loss: 1.89192e+01
2025-07-02 18:57:24,931 - step: 50, training_loss: 2.16420e+01
2025-07-02 18:58:17,034 - step: 100, training_loss: 1.58412e+01
2025-07-02 18:58:17,483 - step: 100, evaluation_loss: 1.88643e+01
2025-07-02 18:59:09,741 - step: 150, training_loss: 1.64628e+01
2025-07-02 19:00:01,329 - step: 200, training_loss: 1.69847e+01
2025-07-02 19:00:01,747 - step: 200, evaluation_loss: 1.79095e+01
2025-07-02 19:00:53,043 - step: 250, training_loss: 2.01240e+01
2025-07-02 19:01:44,236 - step: 300, training_loss: 1.79202e+01
2025-07-02 19:01:44,643 - step: 300, evaluation_loss: 1.73075e+01
