2025-07-26 13:31:21,769 - Training run started at: 2025.07.26_133121
2025-07-26 13:31:21,769 - Run directory: Training Runs/2025.07.26_133121
2025-07-26 13:31:22,536 - NCSNpp(
  (act): SiLU()
  (time_embed): GaussianFourierProjection()
  (time_mlp): Sequential(
    (0): Linear(in_features=128, out_features=256, bias=True)
    (1): SiLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
  )
  (label_emb): Linear(in_features=1, out_features=256, bias=True)
  (input_conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (down_blocks): ModuleList(
    (0-1): 2 x ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Conv_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=64, bias=True)
      (GroupNorm_1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.2, inplace=False)
      (Conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): SiLU()
    )
    (2): ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Conv_0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=128, bias=True)
      (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.2, inplace=False)
      (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (NIN_0): NIN()
      (act): SiLU()
    )
    (3-5): 3 x ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=128, bias=True)
      (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.2, inplace=False)
      (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): SiLU()
    )
  )
  (down_attn): ModuleList(
    (0-1): 2 x AttnBlockpp(
      (GroupNorm_0): GroupNorm(16, 64, eps=1e-06, affine=True)
      (NIN_0): NIN()
      (NIN_1): NIN()
      (NIN_2): NIN()
      (NIN_3): NIN()
    )
    (2-5): 4 x None
  )
  (downsample): ModuleList(
    (0): Downsample(
      (Conv_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))
    )
    (1): Downsample(
      (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
    )
    (2): None
  )
  (mid_block1): ResnetBlockDDPMpp(
    (GroupNorm_0): GroupNorm(32, 128, eps=1e-06, affine=True)
    (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (Dense_0): Linear(in_features=256, out_features=128, bias=True)
    (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
    (Dropout_0): Dropout(p=0.2, inplace=False)
    (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (act): SiLU()
  )
  (mid_block2): ResnetBlockDDPMpp(
    (GroupNorm_0): GroupNorm(32, 128, eps=1e-06, affine=True)
    (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (Dense_0): Linear(in_features=256, out_features=128, bias=True)
    (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
    (Dropout_0): Dropout(p=0.2, inplace=False)
    (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (act): SiLU()
  )
  (up_blocks): ModuleList(
    (0-5): 6 x ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(32, 256, eps=1e-06, affine=True)
      (Conv_0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=128, bias=True)
      (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.2, inplace=False)
      (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (NIN_0): NIN()
      (act): SiLU()
    )
    (6): ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(32, 192, eps=1e-06, affine=True)
      (Conv_0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=64, bias=True)
      (GroupNorm_1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.2, inplace=False)
      (Conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (NIN_0): NIN()
      (act): SiLU()
    )
    (7-8): 2 x ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Conv_0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=64, bias=True)
      (GroupNorm_1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.2, inplace=False)
      (Conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (NIN_0): NIN()
      (act): SiLU()
    )
  )
  (up_attn): ModuleList(
    (0-5): 6 x None
    (6-8): 3 x AttnBlockpp(
      (GroupNorm_0): GroupNorm(16, 64, eps=1e-06, affine=True)
      (NIN_0): NIN()
      (NIN_1): NIN()
      (NIN_2): NIN()
      (NIN_3): NIN()
    )
  )
  (upsample): ModuleList(
    (0-1): 2 x Upsample(
      (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): None
  )
  (out_norm): GroupNorm(16, 64, eps=1e-06, affine=True)
  (out_act): SiLU()
  (out_conv): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2025-07-26 13:31:22,538 - EMA: <models.ema.ExponentialMovingAverage object at 0x14caef9abc40>
2025-07-26 13:31:22,538 - Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
2025-07-26 13:31:22,538 - Scaler: None.
2025-07-26 13:31:22,538 - No checkpoint found at Training Runs/2025.07.26_133121/checkpoints-meta/checkpoint.pth. Returned the same state as input
2025-07-26 13:31:22,676 - Starting training loop at step 0.
2025-07-26 13:31:25,002 - step: 0, training_loss: 6.16844e+01
2025-07-26 13:31:33,127 - step: 0, evaluation_loss: 6.19781e+01
2025-07-26 13:31:33,681 - step: 1, training_loss: 6.51981e+01
2025-07-26 13:31:34,131 - step: 2, training_loss: 6.12898e+01
2025-07-26 13:31:34,589 - step: 3, training_loss: 6.14295e+01
2025-07-26 13:31:35,056 - step: 4, training_loss: 6.33085e+01
2025-07-26 13:31:35,530 - step: 5, training_loss: 6.09984e+01
2025-07-26 13:31:36,010 - step: 6, training_loss: 6.18279e+01
2025-07-26 13:31:36,500 - step: 7, training_loss: 6.15825e+01
2025-07-26 13:31:36,997 - step: 8, training_loss: 6.26049e+01
2025-07-26 13:31:37,502 - step: 9, training_loss: 6.15873e+01
2025-07-26 13:31:38,016 - step: 10, training_loss: 6.33763e+01
2025-07-26 13:31:38,537 - step: 11, training_loss: 6.29125e+01
2025-07-26 13:31:39,068 - step: 12, training_loss: 6.28287e+01
2025-07-26 13:31:39,605 - step: 13, training_loss: 6.18925e+01
2025-07-26 13:31:40,151 - step: 14, training_loss: 6.17298e+01
2025-07-26 13:31:40,705 - step: 15, training_loss: 6.31989e+01
2025-07-26 13:31:41,269 - step: 16, training_loss: 6.39957e+01
2025-07-26 13:31:41,839 - step: 17, training_loss: 6.44387e+01
2025-07-26 13:31:42,417 - step: 18, training_loss: 6.25792e+01
2025-07-26 13:31:43,006 - step: 19, training_loss: 6.28440e+01
2025-07-26 13:31:43,601 - step: 20, training_loss: 6.34992e+01
2025-07-26 13:31:44,204 - step: 21, training_loss: 6.14067e+01
2025-07-26 13:31:44,816 - step: 22, training_loss: 6.41759e+01
2025-07-26 13:31:45,434 - step: 23, training_loss: 6.26258e+01
2025-07-26 13:31:46,063 - step: 24, training_loss: 6.34447e+01
2025-07-26 13:31:46,702 - step: 25, training_loss: 6.31774e+01
2025-07-26 13:31:47,346 - step: 26, training_loss: 6.41088e+01
2025-07-26 13:31:47,997 - step: 27, training_loss: 6.16547e+01
2025-07-26 13:31:48,660 - step: 28, training_loss: 6.07439e+01
2025-07-26 13:31:49,338 - step: 29, training_loss: 6.10634e+01
2025-07-26 13:31:50,015 - step: 30, training_loss: 6.14988e+01
2025-07-26 13:31:50,711 - step: 31, training_loss: 6.00193e+01
2025-07-26 13:31:51,406 - step: 32, training_loss: 6.10000e+01
2025-07-26 13:31:52,106 - step: 33, training_loss: 6.19799e+01
2025-07-26 13:31:52,813 - step: 34, training_loss: 6.20760e+01
2025-07-26 13:31:53,530 - step: 35, training_loss: 6.29935e+01
2025-07-26 13:31:54,262 - step: 36, training_loss: 6.19322e+01
2025-07-26 13:31:54,997 - step: 37, training_loss: 6.24346e+01
2025-07-26 13:31:55,738 - step: 38, training_loss: 6.44990e+01
2025-07-26 13:31:56,487 - step: 39, training_loss: 6.10278e+01
2025-07-26 13:31:57,243 - step: 40, training_loss: 6.31102e+01
2025-07-26 13:31:58,009 - step: 41, training_loss: 6.49013e+01
2025-07-26 13:31:58,782 - step: 42, training_loss: 6.29008e+01
2025-07-26 13:31:59,564 - step: 43, training_loss: 6.28718e+01
2025-07-26 13:32:00,355 - step: 44, training_loss: 6.19190e+01
2025-07-26 13:32:01,152 - step: 45, training_loss: 6.02404e+01
2025-07-26 13:32:01,958 - step: 46, training_loss: 6.29370e+01
2025-07-26 13:32:02,772 - step: 47, training_loss: 6.27558e+01
2025-07-26 13:32:04,142 - step: 48, training_loss: 6.19669e+01
2025-07-26 13:32:05,078 - step: 49, training_loss: 6.02866e+01
2025-07-26 13:32:05,916 - step: 50, training_loss: 6.17426e+01
2025-07-26 13:32:06,763 - step: 51, training_loss: 5.97412e+01
2025-07-26 13:32:07,618 - step: 52, training_loss: 6.15861e+01
2025-07-26 13:32:08,481 - step: 53, training_loss: 6.13140e+01
2025-07-26 13:32:09,351 - step: 54, training_loss: 6.35626e+01
2025-07-26 13:32:10,230 - step: 55, training_loss: 6.22515e+01
2025-07-26 13:32:11,117 - step: 56, training_loss: 6.17002e+01
2025-07-26 13:32:12,011 - step: 57, training_loss: 6.05646e+01
2025-07-26 13:32:12,914 - step: 58, training_loss: 6.18428e+01
2025-07-26 13:32:13,825 - step: 59, training_loss: 6.14237e+01
2025-07-26 13:32:14,746 - step: 60, training_loss: 6.29141e+01
2025-07-26 13:32:15,675 - step: 61, training_loss: 6.26315e+01
2025-07-26 13:32:16,612 - step: 62, training_loss: 6.28217e+01
2025-07-26 13:32:17,556 - step: 63, training_loss: 6.19330e+01
2025-07-26 13:32:18,512 - step: 64, training_loss: 6.20618e+01
2025-07-26 13:32:19,479 - step: 65, training_loss: 6.15963e+01
2025-07-26 13:32:20,447 - step: 66, training_loss: 6.18043e+01
2025-07-26 13:32:21,435 - step: 67, training_loss: 6.20054e+01
2025-07-26 13:32:22,421 - step: 68, training_loss: 6.19534e+01
2025-07-26 13:32:23,417 - step: 69, training_loss: 6.04462e+01
2025-07-26 13:32:24,417 - step: 70, training_loss: 6.41548e+01
2025-07-26 13:32:25,425 - step: 71, training_loss: 6.36237e+01
2025-07-26 13:32:26,442 - step: 72, training_loss: 6.14571e+01
2025-07-26 13:32:27,466 - step: 73, training_loss: 6.13315e+01
2025-07-26 13:32:28,498 - step: 74, training_loss: 6.18112e+01
2025-07-26 13:32:29,539 - step: 75, training_loss: 6.28947e+01
2025-07-26 13:32:30,588 - step: 76, training_loss: 6.17837e+01
2025-07-26 13:32:31,644 - step: 77, training_loss: 6.37553e+01
2025-07-26 13:32:32,710 - step: 78, training_loss: 6.34708e+01
2025-07-26 13:32:33,782 - step: 79, training_loss: 6.15490e+01
2025-07-26 13:32:34,864 - step: 80, training_loss: 6.06878e+01
2025-07-26 13:32:35,953 - step: 81, training_loss: 6.29744e+01
2025-07-26 13:32:37,049 - step: 82, training_loss: 6.17197e+01
2025-07-26 13:32:38,154 - step: 83, training_loss: 6.05698e+01
2025-07-26 13:32:39,269 - step: 84, training_loss: 6.06676e+01
2025-07-26 13:32:40,393 - step: 85, training_loss: 6.14083e+01
2025-07-26 13:32:41,522 - step: 86, training_loss: 6.09521e+01
2025-07-26 13:32:42,660 - step: 87, training_loss: 6.27834e+01
2025-07-26 13:32:43,806 - step: 88, training_loss: 6.20461e+01
2025-07-26 13:32:44,960 - step: 89, training_loss: 6.19722e+01
2025-07-26 13:32:46,122 - step: 90, training_loss: 6.10125e+01
2025-07-26 13:32:47,296 - step: 91, training_loss: 6.02116e+01
2025-07-26 13:32:48,478 - step: 92, training_loss: 6.14552e+01
2025-07-26 13:32:49,666 - step: 93, training_loss: 6.29741e+01
2025-07-26 13:32:50,872 - step: 94, training_loss: 6.25671e+01
2025-07-26 13:32:52,075 - step: 95, training_loss: 6.32709e+01
2025-07-26 13:32:53,285 - step: 96, training_loss: 6.15193e+01
2025-07-26 13:32:54,459 - step: 97, training_loss: 6.18149e+01
2025-07-26 13:32:55,688 - step: 98, training_loss: 6.24846e+01
2025-07-26 13:32:56,923 - step: 99, training_loss: 6.52416e+01
2025-07-26 13:32:58,167 - step: 100, training_loss: 6.01731e+01
2025-07-26 13:32:59,419 - step: 101, training_loss: 6.17740e+01
2025-07-26 13:33:00,678 - step: 102, training_loss: 6.33170e+01
2025-07-26 13:33:01,945 - step: 103, training_loss: 6.26910e+01
2025-07-26 13:33:03,221 - step: 104, training_loss: 6.36976e+01
2025-07-26 13:33:04,504 - step: 105, training_loss: 6.20365e+01
2025-07-26 13:33:05,796 - step: 106, training_loss: 6.41472e+01
2025-07-26 13:33:07,096 - step: 107, training_loss: 6.35085e+01
2025-07-26 13:33:08,403 - step: 108, training_loss: 6.09383e+01
2025-07-26 13:33:09,717 - step: 109, training_loss: 6.11444e+01
2025-07-26 13:33:11,041 - step: 110, training_loss: 6.09747e+01
2025-07-26 13:33:12,372 - step: 111, training_loss: 6.18768e+01
2025-07-26 13:33:13,711 - step: 112, training_loss: 6.20406e+01
2025-07-26 13:33:15,065 - step: 113, training_loss: 6.15324e+01
2025-07-26 13:33:16,422 - step: 114, training_loss: 6.19618e+01
2025-07-26 13:33:17,786 - step: 115, training_loss: 6.27789e+01
2025-07-26 13:33:19,159 - step: 116, training_loss: 6.33448e+01
2025-07-26 13:33:20,544 - step: 117, training_loss: 6.08980e+01
2025-07-26 13:33:21,938 - step: 118, training_loss: 6.20672e+01
2025-07-26 13:33:23,334 - step: 119, training_loss: 6.32845e+01
2025-07-26 13:33:24,738 - step: 120, training_loss: 6.19594e+01
2025-07-26 13:33:26,149 - step: 121, training_loss: 6.19284e+01
2025-07-26 13:33:27,571 - step: 122, training_loss: 6.18511e+01
2025-07-26 13:33:28,999 - step: 123, training_loss: 6.28997e+01
2025-07-26 13:33:30,436 - step: 124, training_loss: 6.09942e+01
2025-07-26 13:33:31,879 - step: 125, training_loss: 5.98094e+01
2025-07-26 13:33:33,333 - step: 126, training_loss: 6.17543e+01
2025-07-26 13:33:34,792 - step: 127, training_loss: 6.11915e+01
2025-07-26 13:33:36,260 - step: 128, training_loss: 6.01896e+01
2025-07-26 13:33:37,737 - step: 129, training_loss: 6.17884e+01
2025-07-26 13:33:39,222 - step: 130, training_loss: 6.13231e+01
2025-07-26 13:33:40,714 - step: 131, training_loss: 5.92976e+01
2025-07-26 13:33:42,216 - step: 132, training_loss: 6.11849e+01
2025-07-26 13:33:43,724 - step: 133, training_loss: 6.05622e+01
2025-07-26 13:33:45,250 - step: 134, training_loss: 6.19682e+01
2025-07-26 13:33:46,775 - step: 135, training_loss: 6.38492e+01
2025-07-26 13:33:48,308 - step: 136, training_loss: 6.23277e+01
2025-07-26 13:33:49,849 - step: 137, training_loss: 6.10731e+01
2025-07-26 13:33:51,409 - step: 138, training_loss: 6.13558e+01
2025-07-26 13:33:52,966 - step: 139, training_loss: 6.09746e+01
2025-07-26 13:33:54,532 - step: 140, training_loss: 6.19361e+01
2025-07-26 13:33:56,107 - step: 141, training_loss: 6.16683e+01
2025-07-26 13:33:57,691 - step: 142, training_loss: 6.09503e+01
2025-07-26 13:33:59,280 - step: 143, training_loss: 6.11387e+01
2025-07-26 13:34:00,879 - step: 144, training_loss: 6.28559e+01
2025-07-26 13:34:02,486 - step: 145, training_loss: 6.21938e+01
2025-07-26 13:34:04,053 - step: 146, training_loss: 6.02802e+01
2025-07-26 13:34:05,676 - step: 147, training_loss: 5.96592e+01
2025-07-26 13:34:07,306 - step: 148, training_loss: 6.09916e+01
2025-07-26 13:34:08,943 - step: 149, training_loss: 6.18102e+01
2025-07-26 13:34:10,589 - step: 150, training_loss: 6.00040e+01
2025-07-26 13:34:12,242 - step: 151, training_loss: 6.20168e+01
2025-07-26 13:34:13,902 - step: 152, training_loss: 6.24249e+01
2025-07-26 13:34:15,573 - step: 153, training_loss: 6.16275e+01
2025-07-26 13:34:17,248 - step: 154, training_loss: 6.19671e+01
2025-07-26 13:34:18,935 - step: 155, training_loss: 6.20579e+01
2025-07-26 13:34:20,638 - step: 156, training_loss: 6.29988e+01
2025-07-26 13:34:22,340 - step: 157, training_loss: 6.27670e+01
2025-07-26 13:34:24,049 - step: 158, training_loss: 5.94423e+01
2025-07-26 13:34:25,770 - step: 159, training_loss: 6.06482e+01
2025-07-26 13:34:27,496 - step: 160, training_loss: 6.09268e+01
2025-07-26 13:34:29,228 - step: 161, training_loss: 6.19875e+01
2025-07-26 13:34:30,970 - step: 162, training_loss: 6.18200e+01
2025-07-26 13:34:32,718 - step: 163, training_loss: 6.09099e+01
2025-07-26 13:34:34,475 - step: 164, training_loss: 6.01932e+01
2025-07-26 13:34:36,241 - step: 165, training_loss: 6.11017e+01
2025-07-26 13:34:38,015 - step: 166, training_loss: 6.25127e+01
2025-07-26 13:34:39,798 - step: 167, training_loss: 6.05525e+01
2025-07-26 13:34:41,589 - step: 168, training_loss: 5.98601e+01
2025-07-26 13:34:43,389 - step: 169, training_loss: 6.15187e+01
2025-07-26 13:34:45,195 - step: 170, training_loss: 5.85329e+01
2025-07-26 13:34:47,009 - step: 171, training_loss: 5.99521e+01
2025-07-26 13:34:48,830 - step: 172, training_loss: 6.14840e+01
2025-07-26 13:34:50,672 - step: 173, training_loss: 6.20677e+01
2025-07-26 13:34:52,511 - step: 174, training_loss: 5.94871e+01
2025-07-26 13:34:54,359 - step: 175, training_loss: 6.12278e+01
2025-07-26 13:34:56,214 - step: 176, training_loss: 6.14442e+01
2025-07-26 13:34:58,079 - step: 177, training_loss: 6.14224e+01
2025-07-26 13:34:59,950 - step: 178, training_loss: 6.19639e+01
2025-07-26 13:35:01,827 - step: 179, training_loss: 6.25186e+01
2025-07-26 13:35:03,714 - step: 180, training_loss: 6.14408e+01
2025-07-26 13:35:05,612 - step: 181, training_loss: 6.19397e+01
2025-07-26 13:35:07,516 - step: 182, training_loss: 6.18258e+01
2025-07-26 13:35:09,428 - step: 183, training_loss: 6.19706e+01
2025-07-26 13:35:11,345 - step: 184, training_loss: 6.06028e+01
2025-07-26 13:35:13,272 - step: 185, training_loss: 6.07628e+01
2025-07-26 13:35:15,209 - step: 186, training_loss: 6.10751e+01
2025-07-26 13:35:17,153 - step: 187, training_loss: 6.20225e+01
2025-07-26 13:35:19,103 - step: 188, training_loss: 6.26953e+01
2025-07-26 13:35:21,072 - step: 189, training_loss: 6.03074e+01
2025-07-26 13:35:23,041 - step: 190, training_loss: 6.09284e+01
2025-07-26 13:35:25,017 - step: 191, training_loss: 5.98971e+01
2025-07-26 13:35:27,000 - step: 192, training_loss: 6.22947e+01
2025-07-26 13:35:28,995 - step: 193, training_loss: 6.26334e+01
2025-07-26 13:35:30,999 - step: 194, training_loss: 6.32895e+01
2025-07-26 13:35:32,961 - step: 195, training_loss: 6.43993e+01
2025-07-26 13:35:34,977 - step: 196, training_loss: 6.38750e+01
2025-07-26 13:35:37,002 - step: 197, training_loss: 6.42851e+01
2025-07-26 13:35:39,035 - step: 198, training_loss: 6.28765e+01
2025-07-26 13:35:41,078 - step: 199, training_loss: 6.01369e+01
2025-07-26 13:35:43,126 - step: 200, training_loss: 5.92082e+01
2025-07-26 13:35:45,182 - step: 201, training_loss: 5.99759e+01
2025-07-26 13:35:47,244 - step: 202, training_loss: 5.93375e+01
2025-07-26 13:35:49,315 - step: 203, training_loss: 5.91529e+01
2025-07-26 13:35:51,403 - step: 204, training_loss: 6.04519e+01
2025-07-26 13:35:53,491 - step: 205, training_loss: 6.29240e+01
2025-07-26 13:35:55,590 - step: 206, training_loss: 6.03266e+01
2025-07-26 13:35:57,694 - step: 207, training_loss: 6.19912e+01
2025-07-26 13:35:59,810 - step: 208, training_loss: 6.29790e+01
2025-07-26 13:36:01,929 - step: 209, training_loss: 5.92738e+01
2025-07-26 13:36:04,060 - step: 210, training_loss: 5.97288e+01
2025-07-26 13:36:06,196 - step: 211, training_loss: 6.02213e+01
2025-07-26 13:36:08,342 - step: 212, training_loss: 6.02547e+01
2025-07-26 13:36:10,498 - step: 213, training_loss: 6.07427e+01
2025-07-26 13:36:12,661 - step: 214, training_loss: 6.20732e+01
2025-07-26 13:36:14,830 - step: 215, training_loss: 5.96053e+01
2025-07-26 13:36:17,011 - step: 216, training_loss: 6.07031e+01
2025-07-26 13:36:19,201 - step: 217, training_loss: 5.97666e+01
2025-07-26 13:36:21,409 - step: 218, training_loss: 5.84715e+01
2025-07-26 13:36:23,615 - step: 219, training_loss: 6.03293e+01
2025-07-26 13:36:25,828 - step: 220, training_loss: 6.04362e+01
2025-07-26 13:36:28,052 - step: 221, training_loss: 6.16284e+01
2025-07-26 13:36:30,283 - step: 222, training_loss: 6.06767e+01
2025-07-26 13:36:32,521 - step: 223, training_loss: 6.14857e+01
2025-07-26 13:36:34,767 - step: 224, training_loss: 6.04249e+01
2025-07-26 13:36:37,020 - step: 225, training_loss: 5.89018e+01
2025-07-26 13:36:39,280 - step: 226, training_loss: 6.01335e+01
2025-07-26 13:36:41,550 - step: 227, training_loss: 5.88933e+01
2025-07-26 13:36:43,829 - step: 228, training_loss: 6.01688e+01
2025-07-26 13:36:46,113 - step: 229, training_loss: 6.05458e+01
2025-07-26 13:36:48,411 - step: 230, training_loss: 6.15567e+01
2025-07-26 13:36:50,727 - step: 231, training_loss: 6.28851e+01
2025-07-26 13:36:53,038 - step: 232, training_loss: 6.01744e+01
2025-07-26 13:36:55,360 - step: 233, training_loss: 5.98554e+01
2025-07-26 13:36:57,689 - step: 234, training_loss: 6.12783e+01
2025-07-26 13:37:00,021 - step: 235, training_loss: 5.98205e+01
2025-07-26 13:37:02,367 - step: 236, training_loss: 6.13465e+01
2025-07-26 13:37:04,716 - step: 237, training_loss: 6.15744e+01
2025-07-26 13:37:07,076 - step: 238, training_loss: 6.22845e+01
2025-07-26 13:37:09,447 - step: 239, training_loss: 5.95193e+01
2025-07-26 13:37:11,823 - step: 240, training_loss: 6.07894e+01
2025-07-26 13:37:14,209 - step: 241, training_loss: 6.09343e+01
2025-07-26 13:37:16,599 - step: 242, training_loss: 6.17265e+01
2025-07-26 13:37:19,000 - step: 243, training_loss: 5.87304e+01
2025-07-26 13:37:21,369 - step: 244, training_loss: 6.28433e+01
2025-07-26 13:37:23,787 - step: 245, training_loss: 6.23678e+01
2025-07-26 13:37:26,218 - step: 246, training_loss: 6.14740e+01
2025-07-26 13:37:28,655 - step: 247, training_loss: 6.18972e+01
2025-07-26 13:37:31,119 - step: 248, training_loss: 6.09910e+01
2025-07-26 13:37:33,566 - step: 249, training_loss: 6.04510e+01
2025-07-26 13:37:36,021 - step: 250, training_loss: 6.18272e+01
2025-07-26 13:37:38,488 - step: 251, training_loss: 6.04577e+01
2025-07-26 13:37:40,959 - step: 252, training_loss: 5.92864e+01
2025-07-26 13:37:43,441 - step: 253, training_loss: 6.55313e+01
2025-07-26 13:37:45,933 - step: 254, training_loss: 6.26805e+01
2025-07-26 13:37:48,431 - step: 255, training_loss: 6.12605e+01
2025-07-26 13:37:50,950 - step: 256, training_loss: 6.21704e+01
2025-07-26 13:37:53,473 - step: 257, training_loss: 5.91061e+01
2025-07-26 13:37:55,997 - step: 258, training_loss: 6.03582e+01
2025-07-26 13:37:58,527 - step: 259, training_loss: 5.95936e+01
2025-07-26 13:38:01,075 - step: 260, training_loss: 5.80890e+01
2025-07-26 13:38:03,623 - step: 261, training_loss: 6.04967e+01
2025-07-26 13:38:06,181 - step: 262, training_loss: 6.13938e+01
2025-07-26 13:38:08,752 - step: 263, training_loss: 6.18929e+01
2025-07-26 13:38:11,325 - step: 264, training_loss: 6.18701e+01
2025-07-26 13:38:13,906 - step: 265, training_loss: 5.82531e+01
2025-07-26 13:38:16,495 - step: 266, training_loss: 5.73811e+01
2025-07-26 13:38:19,092 - step: 267, training_loss: 6.17747e+01
2025-07-26 13:38:21,720 - step: 268, training_loss: 6.07522e+01
2025-07-26 13:38:24,343 - step: 269, training_loss: 6.19771e+01
2025-07-26 13:38:26,962 - step: 270, training_loss: 6.35886e+01
2025-07-26 13:38:29,588 - step: 271, training_loss: 6.01263e+01
2025-07-26 13:38:32,229 - step: 272, training_loss: 6.09842e+01
2025-07-26 13:38:34,869 - step: 273, training_loss: 6.07326e+01
2025-07-26 13:38:37,528 - step: 274, training_loss: 5.86420e+01
2025-07-26 13:38:40,196 - step: 275, training_loss: 5.87502e+01
2025-07-26 13:38:42,880 - step: 276, training_loss: 6.25851e+01
2025-07-26 13:38:45,549 - step: 277, training_loss: 6.16562e+01
2025-07-26 13:38:48,240 - step: 278, training_loss: 6.23313e+01
2025-07-26 13:38:50,958 - step: 279, training_loss: 5.78191e+01
2025-07-26 13:38:53,663 - step: 280, training_loss: 6.22029e+01
2025-07-26 13:38:56,383 - step: 281, training_loss: 6.21598e+01
2025-07-26 13:38:59,107 - step: 282, training_loss: 6.01026e+01
2025-07-26 13:39:01,845 - step: 283, training_loss: 6.10579e+01
2025-07-26 13:39:04,586 - step: 284, training_loss: 5.88820e+01
2025-07-26 13:39:07,329 - step: 285, training_loss: 5.93319e+01
2025-07-26 13:39:10,095 - step: 286, training_loss: 6.13853e+01
2025-07-26 13:39:12,865 - step: 287, training_loss: 5.97913e+01
2025-07-26 13:39:15,635 - step: 288, training_loss: 6.16608e+01
2025-07-26 13:39:18,412 - step: 289, training_loss: 6.08223e+01
2025-07-26 13:39:21,228 - step: 290, training_loss: 5.96447e+01
2025-07-26 13:39:24,040 - step: 291, training_loss: 5.92391e+01
2025-07-26 13:39:26,855 - step: 292, training_loss: 6.03171e+01
2025-07-26 13:39:29,628 - step: 293, training_loss: 6.01657e+01
2025-07-26 13:39:32,455 - step: 294, training_loss: 5.95017e+01
2025-07-26 13:39:35,298 - step: 295, training_loss: 6.11725e+01
2025-07-26 13:39:38,151 - step: 296, training_loss: 5.98503e+01
2025-07-26 13:39:40,994 - step: 297, training_loss: 6.01192e+01
2025-07-26 13:39:43,853 - step: 298, training_loss: 5.98341e+01
2025-07-26 13:39:46,723 - step: 299, training_loss: 6.05250e+01
2025-07-26 13:39:49,604 - step: 300, training_loss: 5.88084e+01
2025-07-26 13:39:52,512 - step: 301, training_loss: 5.89593e+01
2025-07-26 13:39:55,408 - step: 302, training_loss: 5.95424e+01
2025-07-26 13:39:58,317 - step: 303, training_loss: 5.90039e+01
2025-07-26 13:40:01,226 - step: 304, training_loss: 6.03755e+01
2025-07-26 13:40:04,153 - step: 305, training_loss: 6.07261e+01
2025-07-26 13:40:07,078 - step: 306, training_loss: 6.19851e+01
2025-07-26 13:40:10,022 - step: 307, training_loss: 6.01105e+01
2025-07-26 13:40:12,972 - step: 308, training_loss: 5.99113e+01
2025-07-26 13:40:15,923 - step: 309, training_loss: 5.91441e+01
2025-07-26 13:40:18,889 - step: 310, training_loss: 6.00909e+01
2025-07-26 13:40:21,874 - step: 311, training_loss: 5.73632e+01
2025-07-26 13:40:24,857 - step: 312, training_loss: 5.92260e+01
2025-07-26 13:40:27,840 - step: 313, training_loss: 5.91297e+01
2025-07-26 13:40:30,829 - step: 314, training_loss: 5.91204e+01
2025-07-26 13:40:33,839 - step: 315, training_loss: 6.04863e+01
2025-07-26 13:40:36,863 - step: 316, training_loss: 5.86583e+01
2025-07-26 13:40:39,879 - step: 317, training_loss: 5.98942e+01
2025-07-26 13:40:42,904 - step: 318, training_loss: 6.30652e+01
2025-07-26 13:40:45,941 - step: 319, training_loss: 6.23174e+01
2025-07-26 13:40:48,986 - step: 320, training_loss: 5.86002e+01
2025-07-26 13:40:52,052 - step: 321, training_loss: 5.85729e+01
2025-07-26 13:40:55,120 - step: 322, training_loss: 5.68417e+01
2025-07-26 13:40:58,197 - step: 323, training_loss: 5.81576e+01
2025-07-26 13:41:01,273 - step: 324, training_loss: 5.86386e+01
2025-07-26 13:41:04,365 - step: 325, training_loss: 5.81308e+01
2025-07-26 13:41:07,467 - step: 326, training_loss: 5.86677e+01
2025-07-26 13:41:10,573 - step: 327, training_loss: 5.82184e+01
2025-07-26 13:41:13,698 - step: 328, training_loss: 5.78184e+01
2025-07-26 13:41:16,821 - step: 329, training_loss: 5.72691e+01
2025-07-26 13:41:19,953 - step: 330, training_loss: 5.99470e+01
2025-07-26 13:41:23,106 - step: 331, training_loss: 6.00890e+01
2025-07-26 13:41:26,265 - step: 332, training_loss: 6.01473e+01
2025-07-26 13:41:29,421 - step: 333, training_loss: 5.95040e+01
2025-07-26 13:41:32,588 - step: 334, training_loss: 6.09489e+01
2025-07-26 13:41:35,766 - step: 335, training_loss: 6.13793e+01
2025-07-26 13:41:38,963 - step: 336, training_loss: 5.99390e+01
2025-07-26 13:41:42,166 - step: 337, training_loss: 5.79000e+01
2025-07-26 13:41:45,371 - step: 338, training_loss: 5.85206e+01
2025-07-26 13:41:48,583 - step: 339, training_loss: 5.73127e+01
2025-07-26 13:41:51,821 - step: 340, training_loss: 6.05342e+01
2025-07-26 13:41:55,051 - step: 341, training_loss: 5.84488e+01
2025-07-26 13:41:58,230 - step: 342, training_loss: 5.82600e+01
2025-07-26 13:42:01,470 - step: 343, training_loss: 5.99373e+01
2025-07-26 13:42:04,728 - step: 344, training_loss: 5.78179e+01
2025-07-26 13:42:07,987 - step: 345, training_loss: 6.03706e+01
2025-07-26 13:42:11,249 - step: 346, training_loss: 5.74824e+01
2025-07-26 13:42:14,522 - step: 347, training_loss: 5.66810e+01
2025-07-26 13:42:17,810 - step: 348, training_loss: 5.76142e+01
2025-07-26 13:42:21,120 - step: 349, training_loss: 5.78157e+01
2025-07-26 13:42:24,426 - step: 350, training_loss: 6.08674e+01
2025-07-26 13:42:27,741 - step: 351, training_loss: 5.81977e+01
2025-07-26 13:42:31,063 - step: 352, training_loss: 5.75388e+01
2025-07-26 13:42:34,390 - step: 353, training_loss: 5.93720e+01
2025-07-26 13:42:37,720 - step: 354, training_loss: 6.03705e+01
2025-07-26 13:42:41,072 - step: 355, training_loss: 5.97223e+01
2025-07-26 13:42:44,425 - step: 356, training_loss: 6.09457e+01
2025-07-26 13:42:47,792 - step: 357, training_loss: 5.98094e+01
2025-07-26 13:42:51,172 - step: 358, training_loss: 5.92342e+01
2025-07-26 13:42:54,552 - step: 359, training_loss: 5.72675e+01
2025-07-26 13:42:57,940 - step: 360, training_loss: 5.94906e+01
2025-07-26 13:43:01,338 - step: 361, training_loss: 5.79877e+01
2025-07-26 13:43:04,738 - step: 362, training_loss: 5.65403e+01
2025-07-26 13:43:08,149 - step: 363, training_loss: 6.09262e+01
2025-07-26 13:43:11,569 - step: 364, training_loss: 6.11785e+01
2025-07-26 13:43:15,000 - step: 365, training_loss: 5.71452e+01
2025-07-26 13:43:18,432 - step: 366, training_loss: 5.79353e+01
2025-07-26 13:43:21,885 - step: 367, training_loss: 5.92945e+01
2025-07-26 13:43:25,347 - step: 368, training_loss: 6.05799e+01
2025-07-26 13:43:28,817 - step: 369, training_loss: 5.75277e+01
2025-07-26 13:43:32,284 - step: 370, training_loss: 5.94125e+01
2025-07-26 13:43:35,767 - step: 371, training_loss: 6.01363e+01
2025-07-26 13:43:39,260 - step: 372, training_loss: 5.77488e+01
2025-07-26 13:43:42,764 - step: 373, training_loss: 5.97217e+01
2025-07-26 13:43:46,268 - step: 374, training_loss: 5.87858e+01
2025-07-26 13:43:49,786 - step: 375, training_loss: 5.95177e+01
2025-07-26 13:43:53,327 - step: 376, training_loss: 5.62577e+01
2025-07-26 13:43:56,864 - step: 377, training_loss: 5.88809e+01
2025-07-26 13:44:00,407 - step: 378, training_loss: 5.97138e+01
2025-07-26 13:44:03,957 - step: 379, training_loss: 5.61637e+01
2025-07-26 13:44:07,520 - step: 380, training_loss: 5.92520e+01
2025-07-26 13:44:11,087 - step: 381, training_loss: 5.64965e+01
2025-07-26 13:44:14,659 - step: 382, training_loss: 5.82580e+01
2025-07-26 13:44:18,256 - step: 383, training_loss: 5.86155e+01
2025-07-26 13:44:21,867 - step: 384, training_loss: 5.96714e+01
2025-07-26 13:44:25,476 - step: 385, training_loss: 5.72691e+01
2025-07-26 13:44:29,098 - step: 386, training_loss: 5.78837e+01
2025-07-26 13:44:32,724 - step: 387, training_loss: 5.88740e+01
2025-07-26 13:44:36,357 - step: 388, training_loss: 5.77205e+01
2025-07-26 13:44:40,001 - step: 389, training_loss: 5.73326e+01
2025-07-26 13:44:43,656 - step: 390, training_loss: 5.71053e+01
2025-07-26 13:44:47,252 - step: 391, training_loss: 5.84909e+01
2025-07-26 13:44:50,931 - step: 392, training_loss: 5.84404e+01
2025-07-26 13:44:54,588 - step: 393, training_loss: 5.87349e+01
2025-07-26 13:44:58,265 - step: 394, training_loss: 5.76234e+01
2025-07-26 13:45:01,958 - step: 395, training_loss: 6.07804e+01
2025-07-26 13:45:05,648 - step: 396, training_loss: 5.94160e+01
2025-07-26 13:45:09,350 - step: 397, training_loss: 5.83998e+01
2025-07-26 13:45:13,070 - step: 398, training_loss: 5.83003e+01
2025-07-26 13:45:16,791 - step: 399, training_loss: 5.72900e+01
2025-07-26 13:45:20,533 - step: 400, training_loss: 5.94158e+01
2025-07-26 13:45:22,669 - step: 400, evaluation_loss: 5.83216e+01
2025-07-26 13:45:26,484 - step: 401, training_loss: 5.77741e+01
2025-07-26 13:45:30,231 - step: 402, training_loss: 5.97093e+01
2025-07-26 13:45:33,999 - step: 403, training_loss: 5.78102e+01
2025-07-26 13:45:37,772 - step: 404, training_loss: 5.81404e+01
2025-07-26 13:45:41,547 - step: 405, training_loss: 5.85682e+01
2025-07-26 13:45:45,336 - step: 406, training_loss: 5.81672e+01
2025-07-26 13:45:49,141 - step: 407, training_loss: 5.95479e+01
2025-07-26 13:45:52,967 - step: 408, training_loss: 5.89558e+01
2025-07-26 13:45:56,786 - step: 409, training_loss: 5.82186e+01
2025-07-26 13:46:00,619 - step: 410, training_loss: 5.77554e+01
2025-07-26 13:46:04,457 - step: 411, training_loss: 5.82575e+01
2025-07-26 13:46:08,297 - step: 412, training_loss: 5.82111e+01
2025-07-26 13:46:12,146 - step: 413, training_loss: 5.58554e+01
2025-07-26 13:46:15,996 - step: 414, training_loss: 5.76079e+01
2025-07-26 13:46:19,857 - step: 415, training_loss: 5.69988e+01
2025-07-26 13:46:23,739 - step: 416, training_loss: 5.74823e+01
2025-07-26 13:46:27,630 - step: 417, training_loss: 5.63736e+01
2025-07-26 13:46:31,513 - step: 418, training_loss: 5.86857e+01
2025-07-26 13:46:35,408 - step: 419, training_loss: 5.72238e+01
2025-07-26 13:46:39,319 - step: 420, training_loss: 6.02135e+01
2025-07-26 13:46:43,226 - step: 421, training_loss: 5.69098e+01
2025-07-26 13:46:47,152 - step: 422, training_loss: 5.93275e+01
2025-07-26 13:46:51,092 - step: 423, training_loss: 5.76540e+01
2025-07-26 13:46:55,039 - step: 424, training_loss: 5.90725e+01
2025-07-26 13:46:58,990 - step: 425, training_loss: 5.68765e+01
2025-07-26 13:47:02,944 - step: 426, training_loss: 5.58454e+01
2025-07-26 13:47:06,913 - step: 427, training_loss: 5.88183e+01
2025-07-26 13:47:10,894 - step: 428, training_loss: 5.85323e+01
2025-07-26 13:47:14,871 - step: 429, training_loss: 6.07503e+01
2025-07-26 13:47:18,870 - step: 430, training_loss: 5.81925e+01
2025-07-26 13:47:22,884 - step: 431, training_loss: 5.85058e+01
2025-07-26 13:47:26,892 - step: 432, training_loss: 5.80528e+01
2025-07-26 13:47:30,910 - step: 433, training_loss: 5.80993e+01
2025-07-26 13:47:34,930 - step: 434, training_loss: 5.82093e+01
2025-07-26 13:47:38,968 - step: 435, training_loss: 5.87084e+01
2025-07-26 13:47:43,014 - step: 436, training_loss: 6.10266e+01
2025-07-26 13:47:47,062 - step: 437, training_loss: 5.95707e+01
2025-07-26 13:47:51,130 - step: 438, training_loss: 6.08773e+01
2025-07-26 13:47:55,194 - step: 439, training_loss: 5.89363e+01
2025-07-26 13:47:59,216 - step: 440, training_loss: 5.86719e+01
2025-07-26 13:48:03,313 - step: 441, training_loss: 5.83957e+01
2025-07-26 13:48:07,408 - step: 442, training_loss: 5.70528e+01
2025-07-26 13:48:11,508 - step: 443, training_loss: 5.81048e+01
2025-07-26 13:48:15,618 - step: 444, training_loss: 5.68424e+01
2025-07-26 13:48:19,739 - step: 445, training_loss: 5.93519e+01
2025-07-26 13:48:23,875 - step: 446, training_loss: 5.84729e+01
2025-07-26 13:48:28,001 - step: 447, training_loss: 5.84672e+01
2025-07-26 13:48:32,143 - step: 448, training_loss: 5.94582e+01
2025-07-26 13:48:36,290 - step: 449, training_loss: 5.71467e+01
2025-07-26 13:48:40,463 - step: 450, training_loss: 5.76474e+01
2025-07-26 13:48:44,629 - step: 451, training_loss: 5.81387e+01
2025-07-26 13:48:48,809 - step: 452, training_loss: 5.67212e+01
2025-07-26 13:48:53,000 - step: 453, training_loss: 5.90824e+01
2025-07-26 13:48:57,199 - step: 454, training_loss: 5.75071e+01
2025-07-26 13:49:01,406 - step: 455, training_loss: 5.75817e+01
2025-07-26 13:49:05,624 - step: 456, training_loss: 5.79931e+01
2025-07-26 13:49:09,841 - step: 457, training_loss: 5.83313e+01
2025-07-26 13:49:14,071 - step: 458, training_loss: 5.79683e+01
2025-07-26 13:49:18,314 - step: 459, training_loss: 5.68531e+01
2025-07-26 13:49:22,575 - step: 460, training_loss: 5.75550e+01
2025-07-26 13:49:26,833 - step: 461, training_loss: 5.74037e+01
2025-07-26 13:49:31,091 - step: 462, training_loss: 5.76269e+01
2025-07-26 13:49:35,369 - step: 463, training_loss: 5.67463e+01
2025-07-26 13:49:39,642 - step: 464, training_loss: 5.88635e+01
2025-07-26 13:49:43,928 - step: 465, training_loss: 5.72336e+01
2025-07-26 13:49:48,220 - step: 466, training_loss: 5.45583e+01
2025-07-26 13:49:52,533 - step: 467, training_loss: 5.79240e+01
2025-07-26 13:49:56,845 - step: 468, training_loss: 5.80921e+01
2025-07-26 13:50:01,168 - step: 469, training_loss: 5.77411e+01
2025-07-26 13:50:05,496 - step: 470, training_loss: 5.85369e+01
2025-07-26 13:50:09,833 - step: 471, training_loss: 5.81960e+01
2025-07-26 13:50:14,184 - step: 472, training_loss: 5.88657e+01
2025-07-26 13:50:18,531 - step: 473, training_loss: 5.90009e+01
2025-07-26 13:50:22,905 - step: 474, training_loss: 5.85626e+01
2025-07-26 13:50:27,290 - step: 475, training_loss: 5.99584e+01
2025-07-26 13:50:31,677 - step: 476, training_loss: 5.80505e+01
2025-07-26 13:50:36,058 - step: 477, training_loss: 5.95579e+01
2025-07-26 13:50:40,456 - step: 478, training_loss: 6.02513e+01
2025-07-26 13:50:44,864 - step: 479, training_loss: 5.79532e+01
2025-07-26 13:50:49,284 - step: 480, training_loss: 5.74287e+01
2025-07-26 13:50:53,719 - step: 481, training_loss: 5.68449e+01
2025-07-26 13:50:58,156 - step: 482, training_loss: 5.59327e+01
2025-07-26 13:51:02,605 - step: 483, training_loss: 5.74607e+01
2025-07-26 13:51:07,046 - step: 484, training_loss: 5.74609e+01
2025-07-26 13:51:11,500 - step: 485, training_loss: 5.96200e+01
2025-07-26 13:51:15,973 - step: 486, training_loss: 5.74031e+01
2025-07-26 13:51:20,455 - step: 487, training_loss: 5.81676e+01
2025-07-26 13:51:24,963 - step: 488, training_loss: 5.78067e+01
2025-07-26 13:51:29,407 - step: 489, training_loss: 5.83164e+01
2025-07-26 13:51:33,917 - step: 490, training_loss: 5.83539e+01
2025-07-26 13:51:38,437 - step: 491, training_loss: 5.93415e+01
2025-07-26 13:51:42,950 - step: 492, training_loss: 5.83776e+01
2025-07-26 13:51:47,488 - step: 493, training_loss: 5.88814e+01
2025-07-26 13:51:52,034 - step: 494, training_loss: 5.91100e+01
2025-07-26 13:51:56,589 - step: 495, training_loss: 5.72806e+01
2025-07-26 13:52:01,145 - step: 496, training_loss: 5.77922e+01
2025-07-26 13:52:05,702 - step: 497, training_loss: 5.75260e+01
2025-07-26 13:52:10,285 - step: 498, training_loss: 5.84810e+01
2025-07-26 13:52:14,872 - step: 499, training_loss: 5.63395e+01
2025-07-26 13:52:19,453 - step: 500, training_loss: 5.65597e+01
2025-07-26 13:52:19,654 - Generating samples at step: 500
2025-07-26 13:53:27,820 - step: 501, training_loss: 5.93549e+01
2025-07-26 13:53:32,417 - step: 502, training_loss: 5.97382e+01
2025-07-26 13:53:37,026 - step: 503, training_loss: 5.63962e+01
2025-07-26 13:53:41,657 - step: 504, training_loss: 5.92992e+01
2025-07-26 13:53:46,272 - step: 505, training_loss: 5.87231e+01
2025-07-26 13:53:50,936 - step: 506, training_loss: 5.71655e+01
2025-07-26 13:53:55,566 - step: 507, training_loss: 5.73426e+01
2025-07-26 13:54:00,211 - step: 508, training_loss: 5.72015e+01
2025-07-26 13:54:04,864 - step: 509, training_loss: 5.69061e+01
2025-07-26 13:54:09,537 - step: 510, training_loss: 5.61221e+01
2025-07-26 13:54:14,224 - step: 511, training_loss: 5.76295e+01
2025-07-26 13:54:18,930 - step: 512, training_loss: 5.70170e+01
2025-07-26 13:54:23,633 - step: 513, training_loss: 5.69389e+01
2025-07-26 13:54:28,345 - step: 514, training_loss: 5.88241e+01
2025-07-26 13:54:33,056 - step: 515, training_loss: 5.61726e+01
2025-07-26 13:54:37,784 - step: 516, training_loss: 5.86589e+01
2025-07-26 13:54:42,510 - step: 517, training_loss: 5.54356e+01
2025-07-26 13:54:47,251 - step: 518, training_loss: 5.64964e+01
2025-07-26 13:54:52,002 - step: 519, training_loss: 5.71012e+01
2025-07-26 13:54:56,769 - step: 520, training_loss: 5.74740e+01
2025-07-26 13:55:01,534 - step: 521, training_loss: 5.72209e+01
2025-07-26 13:55:06,296 - step: 522, training_loss: 5.95258e+01
2025-07-26 13:55:11,097 - step: 523, training_loss: 5.65328e+01
2025-07-26 13:55:15,899 - step: 524, training_loss: 5.65817e+01
2025-07-26 13:55:20,721 - step: 525, training_loss: 5.63239e+01
2025-07-26 13:55:25,525 - step: 526, training_loss: 5.65171e+01
2025-07-26 13:55:30,336 - step: 527, training_loss: 5.76032e+01
2025-07-26 13:55:35,153 - step: 528, training_loss: 5.89295e+01
2025-07-26 13:55:39,988 - step: 529, training_loss: 5.86358e+01
2025-07-26 13:55:44,830 - step: 530, training_loss: 5.60503e+01
2025-07-26 13:55:49,679 - step: 531, training_loss: 5.48690e+01
2025-07-26 13:55:54,554 - step: 532, training_loss: 5.70129e+01
2025-07-26 13:55:59,428 - step: 533, training_loss: 5.84197e+01
2025-07-26 13:56:04,308 - step: 534, training_loss: 5.80875e+01
2025-07-26 13:56:09,193 - step: 535, training_loss: 5.63413e+01
2025-07-26 13:56:14,098 - step: 536, training_loss: 5.75960e+01
2025-07-26 13:56:19,004 - step: 537, training_loss: 5.69926e+01
2025-07-26 13:56:23,880 - step: 538, training_loss: 5.59580e+01
2025-07-26 13:56:28,812 - step: 539, training_loss: 5.79268e+01
2025-07-26 13:56:33,738 - step: 540, training_loss: 5.88127e+01
2025-07-26 13:56:38,686 - step: 541, training_loss: 5.69595e+01
2025-07-26 13:56:43,629 - step: 542, training_loss: 5.77911e+01
2025-07-26 13:56:48,574 - step: 543, training_loss: 5.74709e+01
2025-07-26 13:56:53,546 - step: 544, training_loss: 5.87980e+01
2025-07-26 13:56:58,507 - step: 545, training_loss: 5.57463e+01
2025-07-26 13:57:03,477 - step: 546, training_loss: 5.72737e+01
2025-07-26 13:57:08,463 - step: 547, training_loss: 5.75191e+01
2025-07-26 13:57:13,454 - step: 548, training_loss: 5.77947e+01
2025-07-26 13:57:18,462 - step: 549, training_loss: 5.61738e+01
2025-07-26 13:57:23,491 - step: 550, training_loss: 5.79272e+01
2025-07-26 13:57:28,520 - step: 551, training_loss: 5.63658e+01
2025-07-26 13:57:33,562 - step: 552, training_loss: 5.78802e+01
2025-07-26 13:57:38,609 - step: 553, training_loss: 5.82019e+01
2025-07-26 13:57:43,651 - step: 554, training_loss: 5.84726e+01
2025-07-26 13:57:48,702 - step: 555, training_loss: 5.59250e+01
2025-07-26 13:57:53,773 - step: 556, training_loss: 5.66628e+01
2025-07-26 13:57:58,846 - step: 557, training_loss: 5.58806e+01
2025-07-26 13:58:03,919 - step: 558, training_loss: 5.70133e+01
2025-07-26 13:58:09,012 - step: 559, training_loss: 5.78325e+01
2025-07-26 13:58:14,120 - step: 560, training_loss: 5.59379e+01
2025-07-26 13:58:19,221 - step: 561, training_loss: 5.68480e+01
2025-07-26 13:58:24,349 - step: 562, training_loss: 5.52778e+01
2025-07-26 13:58:29,463 - step: 563, training_loss: 5.77338e+01
2025-07-26 13:58:34,599 - step: 564, training_loss: 5.60612e+01
2025-07-26 13:58:39,731 - step: 565, training_loss: 5.72815e+01
2025-07-26 13:58:44,877 - step: 566, training_loss: 5.65191e+01
2025-07-26 13:58:50,033 - step: 567, training_loss: 5.82799e+01
2025-07-26 13:58:55,214 - step: 568, training_loss: 5.80404e+01
2025-07-26 13:59:00,385 - step: 569, training_loss: 5.59202e+01
2025-07-26 13:59:05,570 - step: 570, training_loss: 5.66550e+01
2025-07-26 13:59:10,749 - step: 571, training_loss: 5.71364e+01
2025-07-26 13:59:15,953 - step: 572, training_loss: 5.69363e+01
2025-07-26 13:59:21,171 - step: 573, training_loss: 5.79101e+01
2025-07-26 13:59:26,398 - step: 574, training_loss: 5.78790e+01
2025-07-26 13:59:31,633 - step: 575, training_loss: 5.62213e+01
2025-07-26 13:59:36,874 - step: 576, training_loss: 5.60533e+01
2025-07-26 13:59:42,106 - step: 577, training_loss: 5.91898e+01
2025-07-26 13:59:47,355 - step: 578, training_loss: 5.69501e+01
2025-07-26 13:59:52,631 - step: 579, training_loss: 5.76311e+01
2025-07-26 13:59:57,882 - step: 580, training_loss: 5.67723e+01
2025-07-26 14:00:03,147 - step: 581, training_loss: 5.76754e+01
2025-07-26 14:00:08,442 - step: 582, training_loss: 5.65232e+01
2025-07-26 14:00:13,747 - step: 583, training_loss: 5.74433e+01
2025-07-26 14:00:19,044 - step: 584, training_loss: 5.65229e+01
2025-07-26 14:00:24,383 - step: 585, training_loss: 5.62393e+01
2025-07-26 14:00:29,682 - step: 586, training_loss: 5.64279e+01
2025-07-26 14:00:34,957 - step: 587, training_loss: 5.91118e+01
2025-07-26 14:00:40,301 - step: 588, training_loss: 5.78179e+01
2025-07-26 14:00:45,638 - step: 589, training_loss: 5.85517e+01
2025-07-26 14:00:51,012 - step: 590, training_loss: 5.58494e+01
2025-07-26 14:00:56,374 - step: 591, training_loss: 5.86520e+01
2025-07-26 14:01:01,728 - step: 592, training_loss: 5.75292e+01
2025-07-26 14:01:07,115 - step: 593, training_loss: 5.60228e+01
2025-07-26 14:01:12,514 - step: 594, training_loss: 5.85898e+01
2025-07-26 14:01:17,912 - step: 595, training_loss: 5.68443e+01
2025-07-26 14:01:23,320 - step: 596, training_loss: 5.82424e+01
2025-07-26 14:01:28,723 - step: 597, training_loss: 5.49609e+01
2025-07-26 14:01:34,125 - step: 598, training_loss: 5.66459e+01
2025-07-26 14:01:39,570 - step: 599, training_loss: 5.86277e+01
2025-07-26 14:01:45,001 - step: 600, training_loss: 5.60829e+01
2025-07-26 14:01:50,445 - step: 601, training_loss: 5.80315e+01
2025-07-26 14:01:55,892 - step: 602, training_loss: 5.72969e+01
2025-07-26 14:02:01,340 - step: 603, training_loss: 5.78738e+01
2025-07-26 14:02:06,807 - step: 604, training_loss: 5.87832e+01
2025-07-26 14:02:12,287 - step: 605, training_loss: 5.58170e+01
2025-07-26 14:02:17,785 - step: 606, training_loss: 5.73976e+01
2025-07-26 14:02:23,277 - step: 607, training_loss: 5.84990e+01
2025-07-26 14:02:28,779 - step: 608, training_loss: 5.83590e+01
2025-07-26 14:02:34,303 - step: 609, training_loss: 5.54921e+01
2025-07-26 14:02:39,822 - step: 610, training_loss: 5.75997e+01
2025-07-26 14:02:45,353 - step: 611, training_loss: 5.68642e+01
2025-07-26 14:02:50,889 - step: 612, training_loss: 5.77616e+01
2025-07-26 14:02:56,442 - step: 613, training_loss: 5.72132e+01
2025-07-26 14:03:01,995 - step: 614, training_loss: 5.65663e+01
2025-07-26 14:03:07,577 - step: 615, training_loss: 5.69699e+01
2025-07-26 14:03:13,158 - step: 616, training_loss: 5.71465e+01
2025-07-26 14:03:18,756 - step: 617, training_loss: 5.53307e+01
2025-07-26 14:03:24,368 - step: 618, training_loss: 5.74334e+01
2025-07-26 14:03:29,962 - step: 619, training_loss: 5.48758e+01
2025-07-26 14:03:35,557 - step: 620, training_loss: 5.82071e+01
2025-07-26 14:03:41,179 - step: 621, training_loss: 5.59128e+01
2025-07-26 14:03:46,818 - step: 622, training_loss: 5.83989e+01
2025-07-26 14:03:52,484 - step: 623, training_loss: 5.48513e+01
2025-07-26 14:03:58,113 - step: 624, training_loss: 5.54426e+01
2025-07-26 14:04:03,744 - step: 625, training_loss: 5.66287e+01
2025-07-26 14:04:09,398 - step: 626, training_loss: 5.75147e+01
2025-07-26 14:04:15,058 - step: 627, training_loss: 5.64270e+01
2025-07-26 14:04:20,754 - step: 628, training_loss: 5.80594e+01
2025-07-26 14:04:26,443 - step: 629, training_loss: 5.80520e+01
2025-07-26 14:04:32,144 - step: 630, training_loss: 5.85699e+01
2025-07-26 14:04:37,834 - step: 631, training_loss: 5.71693e+01
2025-07-26 14:04:43,550 - step: 632, training_loss: 5.61938e+01
2025-07-26 14:04:49,254 - step: 633, training_loss: 5.75347e+01
2025-07-26 14:04:54,998 - step: 634, training_loss: 5.66957e+01
2025-07-26 14:05:00,719 - step: 635, training_loss: 5.84244e+01
2025-07-26 14:05:06,406 - step: 636, training_loss: 5.66925e+01
2025-07-26 14:05:12,171 - step: 637, training_loss: 5.98335e+01
2025-07-26 14:05:17,940 - step: 638, training_loss: 5.78385e+01
2025-07-26 14:05:23,714 - step: 639, training_loss: 5.58303e+01
2025-07-26 14:05:29,504 - step: 640, training_loss: 5.72796e+01
2025-07-26 14:05:35,299 - step: 641, training_loss: 5.51230e+01
2025-07-26 14:05:41,107 - step: 642, training_loss: 5.65186e+01
2025-07-26 14:05:46,921 - step: 643, training_loss: 5.58820e+01
2025-07-26 14:05:52,753 - step: 644, training_loss: 5.78667e+01
2025-07-26 14:05:58,583 - step: 645, training_loss: 5.68475e+01
2025-07-26 14:06:04,421 - step: 646, training_loss: 5.79837e+01
2025-07-26 14:06:10,275 - step: 647, training_loss: 5.79567e+01
2025-07-26 14:06:16,131 - step: 648, training_loss: 5.84487e+01
2025-07-26 14:06:22,012 - step: 649, training_loss: 5.79425e+01
2025-07-26 14:06:27,880 - step: 650, training_loss: 5.83353e+01
2025-07-26 14:06:33,766 - step: 651, training_loss: 5.73710e+01
2025-07-26 14:06:39,658 - step: 652, training_loss: 5.57981e+01
2025-07-26 14:06:45,559 - step: 653, training_loss: 5.65730e+01
2025-07-26 14:06:51,487 - step: 654, training_loss: 5.58463e+01
2025-07-26 14:06:57,399 - step: 655, training_loss: 5.53969e+01
2025-07-26 14:07:03,323 - step: 656, training_loss: 5.68061e+01
2025-07-26 14:07:09,258 - step: 657, training_loss: 5.84257e+01
2025-07-26 14:07:15,193 - step: 658, training_loss: 5.63967e+01
2025-07-26 14:07:21,158 - step: 659, training_loss: 5.86225e+01
2025-07-26 14:07:27,114 - step: 660, training_loss: 5.62391e+01
2025-07-26 14:07:33,082 - step: 661, training_loss: 5.70393e+01
2025-07-26 14:07:39,057 - step: 662, training_loss: 5.78896e+01
2025-07-26 14:07:45,026 - step: 663, training_loss: 5.65246e+01
2025-07-26 14:07:51,029 - step: 664, training_loss: 5.69138e+01
2025-07-26 14:07:57,026 - step: 665, training_loss: 5.55275e+01
2025-07-26 14:08:03,043 - step: 666, training_loss: 5.57238e+01
2025-07-26 14:08:09,061 - step: 667, training_loss: 5.80208e+01
2025-07-26 14:08:15,089 - step: 668, training_loss: 5.91737e+01
2025-07-26 14:08:21,134 - step: 669, training_loss: 5.54620e+01
2025-07-26 14:08:27,177 - step: 670, training_loss: 5.70117e+01
2025-07-26 14:08:33,227 - step: 671, training_loss: 5.52978e+01
2025-07-26 14:08:39,290 - step: 672, training_loss: 5.71516e+01
2025-07-26 14:08:45,371 - step: 673, training_loss: 5.62727e+01
2025-07-26 14:08:51,460 - step: 674, training_loss: 5.44466e+01
2025-07-26 14:08:57,536 - step: 675, training_loss: 5.73901e+01
2025-07-26 14:09:03,635 - step: 676, training_loss: 5.85109e+01
2025-07-26 14:09:09,733 - step: 677, training_loss: 5.85177e+01
2025-07-26 14:09:15,832 - step: 678, training_loss: 5.67125e+01
2025-07-26 14:09:21,961 - step: 679, training_loss: 5.98792e+01
2025-07-26 14:09:28,096 - step: 680, training_loss: 5.65782e+01
2025-07-26 14:09:34,224 - step: 681, training_loss: 5.73948e+01
2025-07-26 14:09:40,355 - step: 682, training_loss: 5.75491e+01
2025-07-26 14:09:46,500 - step: 683, training_loss: 5.90351e+01
2025-07-26 14:09:52,677 - step: 684, training_loss: 5.57835e+01
2025-07-26 14:09:58,794 - step: 685, training_loss: 5.94081e+01
2025-07-26 14:10:04,966 - step: 686, training_loss: 5.72258e+01
2025-07-26 14:10:11,147 - step: 687, training_loss: 5.85070e+01
2025-07-26 14:10:17,349 - step: 688, training_loss: 5.54230e+01
2025-07-26 14:10:23,563 - step: 689, training_loss: 5.49751e+01
2025-07-26 14:10:29,770 - step: 690, training_loss: 5.66531e+01
2025-07-26 14:10:35,973 - step: 691, training_loss: 5.75488e+01
2025-07-26 14:10:42,194 - step: 692, training_loss: 5.72574e+01
2025-07-26 14:10:48,429 - step: 693, training_loss: 5.77292e+01
2025-07-26 14:10:54,680 - step: 694, training_loss: 5.57666e+01
2025-07-26 14:11:00,934 - step: 695, training_loss: 5.82372e+01
2025-07-26 14:11:07,184 - step: 696, training_loss: 5.75266e+01
2025-07-26 14:11:13,456 - step: 697, training_loss: 5.62578e+01
2025-07-26 14:11:19,739 - step: 698, training_loss: 5.73651e+01
2025-07-26 14:11:26,042 - step: 699, training_loss: 5.68192e+01
2025-07-26 14:11:32,343 - step: 700, training_loss: 5.72569e+01
2025-07-26 14:11:38,649 - step: 701, training_loss: 5.75514e+01
2025-07-26 14:11:44,965 - step: 702, training_loss: 5.71746e+01
2025-07-26 14:11:51,278 - step: 703, training_loss: 5.61096e+01
2025-07-26 14:11:57,616 - step: 704, training_loss: 5.67500e+01
2025-07-26 14:12:03,951 - step: 705, training_loss: 5.62728e+01
2025-07-26 14:12:10,305 - step: 706, training_loss: 5.78866e+01
2025-07-26 14:12:16,638 - step: 707, training_loss: 5.67101e+01
2025-07-26 14:12:23,023 - step: 708, training_loss: 5.61390e+01
2025-07-26 14:12:29,387 - step: 709, training_loss: 5.65732e+01
2025-07-26 14:12:35,757 - step: 710, training_loss: 5.64462e+01
2025-07-26 14:12:42,153 - step: 711, training_loss: 5.91846e+01
2025-07-26 14:12:48,566 - step: 712, training_loss: 5.63581e+01
2025-07-26 14:12:54,980 - step: 713, training_loss: 5.74681e+01
2025-07-26 14:13:01,391 - step: 714, training_loss: 5.50342e+01
2025-07-26 14:13:07,796 - step: 715, training_loss: 5.66231e+01
2025-07-26 14:13:14,218 - step: 716, training_loss: 5.62866e+01
2025-07-26 14:13:20,666 - step: 717, training_loss: 5.63025e+01
2025-07-26 14:13:27,111 - step: 718, training_loss: 5.67304e+01
2025-07-26 14:13:33,551 - step: 719, training_loss: 5.58566e+01
2025-07-26 14:13:40,002 - step: 720, training_loss: 5.70888e+01
2025-07-26 14:13:46,473 - step: 721, training_loss: 5.93551e+01
2025-07-26 14:13:52,973 - step: 722, training_loss: 5.75842e+01
2025-07-26 14:13:59,464 - step: 723, training_loss: 5.82016e+01
2025-07-26 14:14:05,955 - step: 724, training_loss: 5.74437e+01
2025-07-26 14:14:12,458 - step: 725, training_loss: 5.79461e+01
2025-07-26 14:14:18,971 - step: 726, training_loss: 5.61006e+01
2025-07-26 14:14:25,507 - step: 727, training_loss: 5.52927e+01
2025-07-26 14:14:32,052 - step: 728, training_loss: 5.71906e+01
2025-07-26 14:14:38,594 - step: 729, training_loss: 5.73902e+01
2025-07-26 14:14:45,140 - step: 730, training_loss: 5.94238e+01
2025-07-26 14:14:51,700 - step: 731, training_loss: 5.58836e+01
2025-07-26 14:14:58,274 - step: 732, training_loss: 5.64525e+01
2025-07-26 14:15:04,852 - step: 733, training_loss: 5.69742e+01
2025-07-26 14:15:11,374 - step: 734, training_loss: 5.59785e+01
2025-07-26 14:15:17,967 - step: 735, training_loss: 5.71539e+01
2025-07-26 14:15:24,594 - step: 736, training_loss: 5.68143e+01
2025-07-26 14:15:31,215 - step: 737, training_loss: 5.96857e+01
2025-07-26 14:15:37,835 - step: 738, training_loss: 5.67336e+01
2025-07-26 14:15:44,453 - step: 739, training_loss: 5.79214e+01
2025-07-26 14:15:51,101 - step: 740, training_loss: 5.61072e+01
2025-07-26 14:15:57,738 - step: 741, training_loss: 5.70051e+01
2025-07-26 14:16:04,391 - step: 742, training_loss: 5.60942e+01
2025-07-26 14:16:11,058 - step: 743, training_loss: 5.54641e+01
2025-07-26 14:16:17,726 - step: 744, training_loss: 5.66789e+01
2025-07-26 14:16:24,410 - step: 745, training_loss: 5.73422e+01
2025-07-26 14:16:31,088 - step: 746, training_loss: 5.94285e+01
2025-07-26 14:16:37,780 - step: 747, training_loss: 5.64823e+01
2025-07-26 14:16:44,491 - step: 748, training_loss: 5.52952e+01
2025-07-26 14:16:51,234 - step: 749, training_loss: 5.65108e+01
2025-07-26 14:16:57,949 - step: 750, training_loss: 5.45406e+01
2025-07-26 14:17:04,688 - step: 751, training_loss: 5.49666e+01
2025-07-26 14:17:11,431 - step: 752, training_loss: 5.82611e+01
2025-07-26 14:17:18,188 - step: 753, training_loss: 5.53512e+01
2025-07-26 14:17:24,965 - step: 754, training_loss: 5.77602e+01
2025-07-26 14:17:31,727 - step: 755, training_loss: 5.60433e+01
2025-07-26 14:17:38,507 - step: 756, training_loss: 5.71423e+01
2025-07-26 14:17:45,304 - step: 757, training_loss: 5.68073e+01
2025-07-26 14:17:52,098 - step: 758, training_loss: 5.74683e+01
2025-07-26 14:17:58,893 - step: 759, training_loss: 5.76268e+01
2025-07-26 14:18:05,707 - step: 760, training_loss: 5.66342e+01
2025-07-26 14:18:12,529 - step: 761, training_loss: 5.65479e+01
2025-07-26 14:18:19,351 - step: 762, training_loss: 5.64626e+01
2025-07-26 14:18:26,192 - step: 763, training_loss: 5.65586e+01
2025-07-26 14:18:33,032 - step: 764, training_loss: 5.55292e+01
2025-07-26 14:18:39,880 - step: 765, training_loss: 5.72986e+01
2025-07-26 14:18:46,734 - step: 766, training_loss: 5.82122e+01
2025-07-26 14:18:53,630 - step: 767, training_loss: 5.49976e+01
2025-07-26 14:19:00,498 - step: 768, training_loss: 5.65332e+01
2025-07-26 14:19:07,399 - step: 769, training_loss: 5.50493e+01
2025-07-26 14:19:14,282 - step: 770, training_loss: 5.61490e+01
2025-07-26 14:19:21,196 - step: 771, training_loss: 5.47632e+01
2025-07-26 14:19:28,098 - step: 772, training_loss: 5.75379e+01
2025-07-26 14:19:35,008 - step: 773, training_loss: 5.64430e+01
2025-07-26 14:19:41,915 - step: 774, training_loss: 5.71231e+01
2025-07-26 14:19:48,853 - step: 775, training_loss: 5.64812e+01
2025-07-26 14:19:55,798 - step: 776, training_loss: 5.68117e+01
2025-07-26 14:20:02,750 - step: 777, training_loss: 5.35100e+01
2025-07-26 14:20:09,694 - step: 778, training_loss: 5.74357e+01
2025-07-26 14:20:16,680 - step: 779, training_loss: 5.72236e+01
2025-07-26 14:20:23,657 - step: 780, training_loss: 5.59640e+01
2025-07-26 14:20:30,633 - step: 781, training_loss: 5.74737e+01
2025-07-26 14:20:37,635 - step: 782, training_loss: 5.69309e+01
2025-07-26 14:20:44,587 - step: 783, training_loss: 5.69405e+01
2025-07-26 14:20:51,650 - step: 784, training_loss: 5.71019e+01
2025-07-26 14:20:58,671 - step: 785, training_loss: 5.54734e+01
2025-07-26 14:21:05,693 - step: 786, training_loss: 5.63664e+01
2025-07-26 14:21:12,727 - step: 787, training_loss: 5.69386e+01
2025-07-26 14:21:19,760 - step: 788, training_loss: 5.51195e+01
2025-07-26 14:21:26,822 - step: 789, training_loss: 5.64930e+01
2025-07-26 14:21:33,881 - step: 790, training_loss: 5.72010e+01
2025-07-26 14:21:40,938 - step: 791, training_loss: 5.41519e+01
2025-07-26 14:21:48,028 - step: 792, training_loss: 5.60908e+01
2025-07-26 14:21:55,147 - step: 793, training_loss: 5.72737e+01
2025-07-26 14:22:02,239 - step: 794, training_loss: 5.60724e+01
2025-07-26 14:22:09,336 - step: 795, training_loss: 5.54243e+01
2025-07-26 14:22:16,480 - step: 796, training_loss: 5.64914e+01
2025-07-26 14:22:23,604 - step: 797, training_loss: 5.59588e+01
2025-07-26 14:22:30,769 - step: 798, training_loss: 5.80601e+01
2025-07-26 14:22:37,905 - step: 799, training_loss: 5.82372e+01
2025-07-26 14:22:45,078 - step: 800, training_loss: 5.72047e+01
2025-07-26 14:22:47,190 - step: 800, evaluation_loss: 5.64854e+01
2025-07-26 14:22:54,426 - step: 801, training_loss: 5.80408e+01
2025-07-26 14:23:01,615 - step: 802, training_loss: 5.58921e+01
2025-07-26 14:23:08,807 - step: 803, training_loss: 5.76861e+01
2025-07-26 14:23:15,983 - step: 804, training_loss: 5.84122e+01
2025-07-26 14:23:23,177 - step: 805, training_loss: 5.41996e+01
2025-07-26 14:23:30,412 - step: 806, training_loss: 5.88229e+01
2025-07-26 14:23:37,657 - step: 807, training_loss: 5.59226e+01
2025-07-26 14:23:44,903 - step: 808, training_loss: 5.64796e+01
2025-07-26 14:23:52,166 - step: 809, training_loss: 5.85618e+01
2025-07-26 14:23:59,434 - step: 810, training_loss: 5.63702e+01
2025-07-26 14:24:06,683 - step: 811, training_loss: 5.58096e+01
2025-07-26 14:24:13,928 - step: 812, training_loss: 5.84446e+01
2025-07-26 14:24:21,195 - step: 813, training_loss: 5.36448e+01
2025-07-26 14:24:28,496 - step: 814, training_loss: 5.70837e+01
2025-07-26 14:24:35,802 - step: 815, training_loss: 5.49116e+01
2025-07-26 14:24:43,138 - step: 816, training_loss: 5.53320e+01
2025-07-26 14:24:50,481 - step: 817, training_loss: 5.66155e+01
2025-07-26 14:24:57,798 - step: 818, training_loss: 5.73611e+01
2025-07-26 14:25:05,160 - step: 819, training_loss: 5.61422e+01
2025-07-26 14:25:12,459 - step: 820, training_loss: 5.40504e+01
2025-07-26 14:25:19,853 - step: 821, training_loss: 5.78278e+01
2025-07-26 14:25:27,199 - step: 822, training_loss: 5.50792e+01
2025-07-26 14:25:34,562 - step: 823, training_loss: 5.67911e+01
2025-07-26 14:25:41,938 - step: 824, training_loss: 5.42826e+01
2025-07-26 14:25:49,351 - step: 825, training_loss: 5.56774e+01
2025-07-26 14:25:56,786 - step: 826, training_loss: 5.53766e+01
2025-07-26 14:26:04,235 - step: 827, training_loss: 5.70634e+01
2025-07-26 14:26:11,665 - step: 828, training_loss: 5.74475e+01
2025-07-26 14:26:19,112 - step: 829, training_loss: 5.52053e+01
2025-07-26 14:26:26,557 - step: 830, training_loss: 5.52343e+01
2025-07-26 14:26:34,011 - step: 831, training_loss: 5.55331e+01
2025-07-26 14:26:41,427 - step: 832, training_loss: 5.81874e+01
2025-07-26 14:26:48,903 - step: 833, training_loss: 5.71463e+01
2025-07-26 14:26:56,362 - step: 834, training_loss: 5.56854e+01
2025-07-26 14:27:03,819 - step: 835, training_loss: 5.52731e+01
2025-07-26 14:27:11,315 - step: 836, training_loss: 5.73294e+01
2025-07-26 14:27:18,792 - step: 837, training_loss: 5.68316e+01
2025-07-26 14:27:26,312 - step: 838, training_loss: 5.27993e+01
2025-07-26 14:27:33,804 - step: 839, training_loss: 5.67855e+01
2025-07-26 14:27:41,334 - step: 840, training_loss: 5.70539e+01
2025-07-26 14:27:48,879 - step: 841, training_loss: 5.70836e+01
2025-07-26 14:27:56,431 - step: 842, training_loss: 5.70107e+01
2025-07-26 14:28:04,010 - step: 843, training_loss: 5.76272e+01
2025-07-26 14:28:11,583 - step: 844, training_loss: 5.73746e+01
2025-07-26 14:28:19,136 - step: 845, training_loss: 5.54825e+01
2025-07-26 14:28:26,732 - step: 846, training_loss: 5.42262e+01
2025-07-26 14:28:34,322 - step: 847, training_loss: 5.56924e+01
2025-07-26 14:28:41,898 - step: 848, training_loss: 5.73126e+01
2025-07-26 14:28:49,512 - step: 849, training_loss: 5.63042e+01
2025-07-26 14:28:57,160 - step: 850, training_loss: 5.68044e+01
2025-07-26 14:29:04,813 - step: 851, training_loss: 5.68573e+01
2025-07-26 14:29:12,487 - step: 852, training_loss: 5.59298e+01
2025-07-26 14:29:20,104 - step: 853, training_loss: 5.63189e+01
2025-07-26 14:29:27,740 - step: 854, training_loss: 5.58820e+01
2025-07-26 14:29:35,378 - step: 855, training_loss: 5.74396e+01
2025-07-26 14:29:43,033 - step: 856, training_loss: 5.47431e+01
2025-07-26 14:29:50,693 - step: 857, training_loss: 5.40030e+01
2025-07-26 14:29:58,365 - step: 858, training_loss: 5.68442e+01
2025-07-26 14:30:06,025 - step: 859, training_loss: 5.57943e+01
2025-07-26 14:30:13,734 - step: 860, training_loss: 5.49843e+01
2025-07-26 14:30:21,475 - step: 861, training_loss: 5.51512e+01
2025-07-26 14:30:29,161 - step: 862, training_loss: 5.70577e+01
2025-07-26 14:30:36,890 - step: 863, training_loss: 5.70709e+01
2025-07-26 14:30:44,644 - step: 864, training_loss: 5.74232e+01
2025-07-26 14:30:52,402 - step: 865, training_loss: 5.69558e+01
2025-07-26 14:31:00,133 - step: 866, training_loss: 5.66733e+01
2025-07-26 14:31:07,882 - step: 867, training_loss: 5.52289e+01
2025-07-26 14:31:15,623 - step: 868, training_loss: 5.34837e+01
2025-07-26 14:31:23,433 - step: 869, training_loss: 5.57591e+01
2025-07-26 14:31:31,214 - step: 870, training_loss: 5.30953e+01
2025-07-26 14:31:39,002 - step: 871, training_loss: 5.71164e+01
2025-07-26 14:31:46,842 - step: 872, training_loss: 5.85488e+01
2025-07-26 14:31:54,690 - step: 873, training_loss: 5.64797e+01
2025-07-26 14:32:02,529 - step: 874, training_loss: 5.71040e+01
2025-07-26 14:32:10,360 - step: 875, training_loss: 5.29990e+01
2025-07-26 14:32:18,216 - step: 876, training_loss: 5.60397e+01
2025-07-26 14:32:26,080 - step: 877, training_loss: 5.72216e+01
2025-07-26 14:32:33,916 - step: 878, training_loss: 5.51250e+01
2025-07-26 14:32:41,753 - step: 879, training_loss: 5.42755e+01
2025-07-26 14:32:49,627 - step: 880, training_loss: 5.62117e+01
2025-07-26 14:32:57,472 - step: 881, training_loss: 5.68742e+01
2025-07-26 14:33:05,389 - step: 882, training_loss: 5.46971e+01
2025-07-26 14:33:13,307 - step: 883, training_loss: 5.57108e+01
2025-07-26 14:33:21,233 - step: 884, training_loss: 5.68861e+01
2025-07-26 14:33:29,127 - step: 885, training_loss: 5.64714e+01
2025-07-26 14:33:37,077 - step: 886, training_loss: 5.57604e+01
2025-07-26 14:33:45,012 - step: 887, training_loss: 5.49924e+01
2025-07-26 14:33:52,979 - step: 888, training_loss: 5.41757e+01
2025-07-26 14:34:00,895 - step: 889, training_loss: 5.44963e+01
2025-07-26 14:34:08,869 - step: 890, training_loss: 5.47763e+01
2025-07-26 14:34:16,798 - step: 891, training_loss: 5.67273e+01
2025-07-26 14:34:24,796 - step: 892, training_loss: 5.46365e+01
2025-07-26 14:34:32,800 - step: 893, training_loss: 5.63656e+01
2025-07-26 14:34:40,788 - step: 894, training_loss: 5.53382e+01
2025-07-26 14:34:48,772 - step: 895, training_loss: 5.52126e+01
2025-07-26 14:34:56,797 - step: 896, training_loss: 5.48986e+01
2025-07-26 14:35:04,832 - step: 897, training_loss: 5.38511e+01
2025-07-26 14:35:12,870 - step: 898, training_loss: 5.47823e+01
2025-07-26 14:35:20,936 - step: 899, training_loss: 5.58202e+01
2025-07-26 14:35:28,983 - step: 900, training_loss: 5.50859e+01
2025-07-26 14:35:37,038 - step: 901, training_loss: 5.53154e+01
2025-07-26 14:35:45,093 - step: 902, training_loss: 5.51162e+01
2025-07-26 14:35:53,168 - step: 903, training_loss: 5.19232e+01
2025-07-26 14:36:01,226 - step: 904, training_loss: 5.49974e+01
2025-07-26 14:36:09,291 - step: 905, training_loss: 5.55810e+01
2025-07-26 14:36:17,388 - step: 906, training_loss: 5.65217e+01
2025-07-26 14:36:25,501 - step: 907, training_loss: 5.52602e+01
2025-07-26 14:36:33,612 - step: 908, training_loss: 5.63598e+01
2025-07-26 14:36:41,736 - step: 909, training_loss: 5.30540e+01
2025-07-26 14:36:49,872 - step: 910, training_loss: 5.69798e+01
2025-07-26 14:36:58,005 - step: 911, training_loss: 5.45962e+01
2025-07-26 14:37:06,155 - step: 912, training_loss: 5.56224e+01
2025-07-26 14:37:14,294 - step: 913, training_loss: 5.40503e+01
2025-07-26 14:37:22,480 - step: 914, training_loss: 5.46096e+01
2025-07-26 14:37:30,631 - step: 915, training_loss: 5.62434e+01
2025-07-26 14:37:38,806 - step: 916, training_loss: 5.62272e+01
2025-07-26 14:37:47,009 - step: 917, training_loss: 5.62720e+01
2025-07-26 14:37:55,220 - step: 918, training_loss: 5.38721e+01
2025-07-26 14:38:03,431 - step: 919, training_loss: 5.47632e+01
2025-07-26 14:38:11,626 - step: 920, training_loss: 5.45918e+01
2025-07-26 14:38:19,854 - step: 921, training_loss: 5.63179e+01
2025-07-26 14:38:28,098 - step: 922, training_loss: 5.61397e+01
2025-07-26 14:38:36,339 - step: 923, training_loss: 5.53991e+01
2025-07-26 14:38:44,603 - step: 924, training_loss: 5.68470e+01
2025-07-26 14:38:52,866 - step: 925, training_loss: 5.66861e+01
2025-07-26 14:39:01,118 - step: 926, training_loss: 5.48071e+01
2025-07-26 14:39:09,370 - step: 927, training_loss: 5.61885e+01
2025-07-26 14:39:17,654 - step: 928, training_loss: 5.59056e+01
2025-07-26 14:39:25,963 - step: 929, training_loss: 5.59097e+01
2025-07-26 14:39:34,218 - step: 930, training_loss: 5.64463e+01
2025-07-26 14:39:42,529 - step: 931, training_loss: 5.60488e+01
2025-07-26 14:39:50,860 - step: 932, training_loss: 5.46009e+01
2025-07-26 14:39:59,203 - step: 933, training_loss: 5.42031e+01
2025-07-26 14:40:07,539 - step: 934, training_loss: 5.56922e+01
2025-07-26 14:40:15,897 - step: 935, training_loss: 5.50240e+01
2025-07-26 14:40:24,251 - step: 936, training_loss: 5.56357e+01
2025-07-26 14:40:32,604 - step: 937, training_loss: 5.50249e+01
2025-07-26 14:40:40,968 - step: 938, training_loss: 5.59327e+01
2025-07-26 14:40:49,320 - step: 939, training_loss: 5.44553e+01
2025-07-26 14:40:57,711 - step: 940, training_loss: 5.55124e+01
2025-07-26 14:41:06,113 - step: 941, training_loss: 5.77199e+01
2025-07-26 14:41:14,496 - step: 942, training_loss: 5.42751e+01
2025-07-26 14:41:22,914 - step: 943, training_loss: 5.49743e+01
2025-07-26 14:41:31,332 - step: 944, training_loss: 5.34044e+01
2025-07-26 14:41:39,759 - step: 945, training_loss: 5.47371e+01
2025-07-26 14:41:48,194 - step: 946, training_loss: 5.69688e+01
2025-07-26 14:41:56,656 - step: 947, training_loss: 5.68419e+01
2025-07-26 14:42:05,114 - step: 948, training_loss: 5.71176e+01
2025-07-26 14:42:13,578 - step: 949, training_loss: 5.43425e+01
2025-07-26 14:42:22,061 - step: 950, training_loss: 5.48765e+01
2025-07-26 14:42:30,537 - step: 951, training_loss: 5.50411e+01
2025-07-26 14:42:39,019 - step: 952, training_loss: 5.60617e+01
2025-07-26 14:42:47,510 - step: 953, training_loss: 5.46246e+01
2025-07-26 14:42:56,039 - step: 954, training_loss: 5.76920e+01
2025-07-26 14:43:04,532 - step: 955, training_loss: 5.65985e+01
2025-07-26 14:43:13,056 - step: 956, training_loss: 5.42093e+01
2025-07-26 14:43:21,604 - step: 957, training_loss: 5.35307e+01
2025-07-26 14:43:30,144 - step: 958, training_loss: 5.35660e+01
2025-07-26 14:43:38,699 - step: 959, training_loss: 5.47368e+01
2025-07-26 14:43:47,257 - step: 960, training_loss: 5.44504e+01
2025-07-26 14:43:55,837 - step: 961, training_loss: 5.39291e+01
2025-07-26 14:44:04,426 - step: 962, training_loss: 5.62877e+01
2025-07-26 14:44:13,017 - step: 963, training_loss: 5.19468e+01
2025-07-26 14:44:21,614 - step: 964, training_loss: 5.50553e+01
2025-07-26 14:44:30,224 - step: 965, training_loss: 5.56538e+01
2025-07-26 14:44:38,836 - step: 966, training_loss: 5.51021e+01
2025-07-26 14:44:47,457 - step: 967, training_loss: 5.38535e+01
2025-07-26 14:44:56,102 - step: 968, training_loss: 5.38541e+01
2025-07-26 14:45:04,744 - step: 969, training_loss: 5.49302e+01
2025-07-26 14:45:13,391 - step: 970, training_loss: 5.63028e+01
2025-07-26 14:45:22,053 - step: 971, training_loss: 5.62288e+01
2025-07-26 14:45:30,728 - step: 972, training_loss: 5.52908e+01
2025-07-26 14:45:39,392 - step: 973, training_loss: 5.46521e+01
2025-07-26 14:45:48,078 - step: 974, training_loss: 5.69945e+01
2025-07-26 14:45:56,774 - step: 975, training_loss: 5.46875e+01
2025-07-26 14:46:05,477 - step: 976, training_loss: 5.64304e+01
2025-07-26 14:46:14,190 - step: 977, training_loss: 5.36397e+01
2025-07-26 14:46:22,907 - step: 978, training_loss: 5.77643e+01
2025-07-26 14:46:31,563 - step: 979, training_loss: 5.49376e+01
2025-07-26 14:46:40,284 - step: 980, training_loss: 5.54880e+01
2025-07-26 14:46:49,027 - step: 981, training_loss: 5.52683e+01
2025-07-26 14:46:57,792 - step: 982, training_loss: 5.41108e+01
2025-07-26 14:47:06,542 - step: 983, training_loss: 5.42228e+01
2025-07-26 14:47:15,299 - step: 984, training_loss: 5.51166e+01
2025-07-26 14:47:24,089 - step: 985, training_loss: 5.52249e+01
2025-07-26 14:47:32,870 - step: 986, training_loss: 5.63817e+01
2025-07-26 14:47:41,671 - step: 987, training_loss: 5.68784e+01
2025-07-26 14:47:50,473 - step: 988, training_loss: 5.68185e+01
2025-07-26 14:47:59,276 - step: 989, training_loss: 5.47269e+01
2025-07-26 14:48:08,105 - step: 990, training_loss: 5.53681e+01
2025-07-26 14:48:16,936 - step: 991, training_loss: 5.85473e+01
2025-07-26 14:48:25,785 - step: 992, training_loss: 5.48847e+01
2025-07-26 14:48:34,639 - step: 993, training_loss: 5.41443e+01
2025-07-26 14:48:43,507 - step: 994, training_loss: 5.42382e+01
2025-07-26 14:48:52,392 - step: 995, training_loss: 5.39057e+01
2025-07-26 14:49:01,238 - step: 996, training_loss: 5.68147e+01
2025-07-26 14:49:10,099 - step: 997, training_loss: 5.35149e+01
2025-07-26 14:49:18,985 - step: 998, training_loss: 5.59714e+01
2025-07-26 14:49:27,887 - step: 999, training_loss: 5.60315e+01
2025-07-26 14:49:36,794 - step: 1000, training_loss: 5.51982e+01
2025-07-26 14:49:37,015 - Generating samples at step: 1000
2025-07-26 14:50:48,597 - step: 1001, training_loss: 5.38320e+01
2025-07-26 14:50:57,522 - step: 1002, training_loss: 5.65416e+01
2025-07-26 14:51:06,436 - step: 1003, training_loss: 5.77402e+01
2025-07-26 14:51:15,386 - step: 1004, training_loss: 5.53829e+01
2025-07-26 14:51:24,322 - step: 1005, training_loss: 5.65164e+01
2025-07-26 14:51:33,235 - step: 1006, training_loss: 5.70340e+01
2025-07-26 14:51:42,201 - step: 1007, training_loss: 5.37714e+01
2025-07-26 14:51:51,177 - step: 1008, training_loss: 5.64376e+01
2025-07-26 14:52:00,114 - step: 1009, training_loss: 5.21662e+01
2025-07-26 14:52:09,093 - step: 1010, training_loss: 5.59576e+01
2025-07-26 14:52:18,075 - step: 1011, training_loss: 5.33878e+01
2025-07-26 14:52:27,081 - step: 1012, training_loss: 5.45766e+01
2025-07-26 14:52:36,101 - step: 1013, training_loss: 5.53328e+01
2025-07-26 14:52:45,113 - step: 1014, training_loss: 5.60744e+01
2025-07-26 14:52:54,142 - step: 1015, training_loss: 5.65192e+01
2025-07-26 14:53:03,170 - step: 1016, training_loss: 5.63489e+01
2025-07-26 14:53:12,227 - step: 1017, training_loss: 5.33134e+01
2025-07-26 14:53:21,301 - step: 1018, training_loss: 5.36623e+01
2025-07-26 14:53:30,352 - step: 1019, training_loss: 5.68110e+01
2025-07-26 14:53:39,417 - step: 1020, training_loss: 5.54567e+01
2025-07-26 14:53:48,478 - step: 1021, training_loss: 5.52580e+01
2025-07-26 14:53:57,560 - step: 1022, training_loss: 5.70246e+01
2025-07-26 14:54:06,641 - step: 1023, training_loss: 5.61858e+01
2025-07-26 14:54:15,731 - step: 1024, training_loss: 5.48582e+01
2025-07-26 14:54:24,864 - step: 1025, training_loss: 5.40681e+01
2025-07-26 14:54:33,967 - step: 1026, training_loss: 5.37528e+01
2025-07-26 14:54:43,055 - step: 1027, training_loss: 5.51846e+01
2025-07-26 14:54:52,149 - step: 1028, training_loss: 5.72797e+01
2025-07-26 14:55:01,287 - step: 1029, training_loss: 5.44770e+01
2025-07-26 14:55:10,421 - step: 1030, training_loss: 5.48608e+01
2025-07-26 14:55:19,575 - step: 1031, training_loss: 5.38350e+01
2025-07-26 14:55:28,723 - step: 1032, training_loss: 5.56549e+01
2025-07-26 14:55:37,882 - step: 1033, training_loss: 5.44584e+01
2025-07-26 14:55:47,066 - step: 1034, training_loss: 5.51711e+01
2025-07-26 14:55:56,258 - step: 1035, training_loss: 5.57467e+01
2025-07-26 14:56:05,441 - step: 1036, training_loss: 5.45551e+01
2025-07-26 14:56:14,653 - step: 1037, training_loss: 5.33525e+01
2025-07-26 14:56:23,846 - step: 1038, training_loss: 5.69092e+01
2025-07-26 14:56:33,067 - step: 1039, training_loss: 5.60510e+01
2025-07-26 14:56:42,296 - step: 1040, training_loss: 5.56526e+01
2025-07-26 14:56:51,558 - step: 1041, training_loss: 5.57894e+01
2025-07-26 14:57:00,799 - step: 1042, training_loss: 5.37094e+01
2025-07-26 14:57:10,054 - step: 1043, training_loss: 5.38015e+01
2025-07-26 14:57:19,323 - step: 1044, training_loss: 5.56420e+01
2025-07-26 14:57:28,624 - step: 1045, training_loss: 5.53867e+01
2025-07-26 14:57:37,943 - step: 1046, training_loss: 5.66644e+01
2025-07-26 14:57:47,258 - step: 1047, training_loss: 5.39029e+01
2025-07-26 14:57:56,550 - step: 1048, training_loss: 5.65205e+01
2025-07-26 14:58:05,805 - step: 1049, training_loss: 5.58130e+01
2025-07-26 14:58:15,103 - step: 1050, training_loss: 5.39271e+01
2025-07-26 14:58:24,427 - step: 1051, training_loss: 5.39465e+01
2025-07-26 14:58:33,750 - step: 1052, training_loss: 5.27974e+01
2025-07-26 14:58:43,084 - step: 1053, training_loss: 5.61454e+01
2025-07-26 14:58:52,461 - step: 1054, training_loss: 5.55429e+01
2025-07-26 14:59:01,785 - step: 1055, training_loss: 5.39528e+01
2025-07-26 14:59:11,155 - step: 1056, training_loss: 5.68541e+01
2025-07-26 14:59:20,523 - step: 1057, training_loss: 5.39800e+01
2025-07-26 14:59:29,911 - step: 1058, training_loss: 5.75586e+01
2025-07-26 14:59:39,303 - step: 1059, training_loss: 5.50585e+01
2025-07-26 14:59:48,703 - step: 1060, training_loss: 5.55532e+01
2025-07-26 14:59:58,121 - step: 1061, training_loss: 5.42229e+01
2025-07-26 15:00:07,530 - step: 1062, training_loss: 5.45081e+01
2025-07-26 15:00:16,951 - step: 1063, training_loss: 5.42632e+01
2025-07-26 15:00:26,392 - step: 1064, training_loss: 5.39767e+01
2025-07-26 15:00:35,845 - step: 1065, training_loss: 5.48620e+01
2025-07-26 15:00:45,283 - step: 1066, training_loss: 5.44562e+01
2025-07-26 15:00:54,750 - step: 1067, training_loss: 5.39588e+01
2025-07-26 15:01:04,213 - step: 1068, training_loss: 5.41438e+01
2025-07-26 15:01:13,676 - step: 1069, training_loss: 5.56916e+01
2025-07-26 15:01:23,173 - step: 1070, training_loss: 5.59951e+01
2025-07-26 15:01:32,651 - step: 1071, training_loss: 5.29704e+01
2025-07-26 15:01:42,131 - step: 1072, training_loss: 5.48833e+01
2025-07-26 15:01:51,663 - step: 1073, training_loss: 5.55309e+01
2025-07-26 15:02:01,193 - step: 1074, training_loss: 5.40610e+01
2025-07-26 15:02:10,720 - step: 1075, training_loss: 5.38759e+01
2025-07-26 15:02:20,260 - step: 1076, training_loss: 5.47145e+01
2025-07-26 15:02:29,767 - step: 1077, training_loss: 5.54793e+01
2025-07-26 15:02:39,345 - step: 1078, training_loss: 5.61610e+01
2025-07-26 15:02:48,897 - step: 1079, training_loss: 5.61441e+01
2025-07-26 15:02:58,461 - step: 1080, training_loss: 5.40832e+01
2025-07-26 15:03:08,027 - step: 1081, training_loss: 5.32397e+01
2025-07-26 15:03:17,601 - step: 1082, training_loss: 5.37023e+01
2025-07-26 15:03:27,200 - step: 1083, training_loss: 5.38922e+01
2025-07-26 15:03:36,787 - step: 1084, training_loss: 5.52579e+01
2025-07-26 15:03:46,384 - step: 1085, training_loss: 5.51815e+01
2025-07-26 15:03:56,029 - step: 1086, training_loss: 5.34155e+01
2025-07-26 15:04:05,671 - step: 1087, training_loss: 5.52461e+01
2025-07-26 15:04:15,306 - step: 1088, training_loss: 5.57057e+01
2025-07-26 15:04:24,977 - step: 1089, training_loss: 5.32795e+01
2025-07-26 15:04:34,629 - step: 1090, training_loss: 5.36243e+01
2025-07-26 15:04:44,287 - step: 1091, training_loss: 5.44859e+01
2025-07-26 15:04:53,945 - step: 1092, training_loss: 5.42032e+01
2025-07-26 15:05:03,652 - step: 1093, training_loss: 5.54619e+01
2025-07-26 15:05:13,315 - step: 1094, training_loss: 5.43179e+01
2025-07-26 15:05:23,009 - step: 1095, training_loss: 5.46485e+01
2025-07-26 15:05:32,717 - step: 1096, training_loss: 5.54733e+01
2025-07-26 15:05:42,432 - step: 1097, training_loss: 5.20451e+01
2025-07-26 15:05:52,131 - step: 1098, training_loss: 5.52061e+01
2025-07-26 15:06:01,858 - step: 1099, training_loss: 5.45119e+01
2025-07-26 15:06:11,612 - step: 1100, training_loss: 5.35311e+01
2025-07-26 15:06:21,360 - step: 1101, training_loss: 5.49215e+01
2025-07-26 15:06:31,112 - step: 1102, training_loss: 5.32639e+01
2025-07-26 15:06:40,870 - step: 1103, training_loss: 5.36827e+01
2025-07-26 15:06:50,662 - step: 1104, training_loss: 5.45315e+01
2025-07-26 15:07:00,454 - step: 1105, training_loss: 5.49711e+01
2025-07-26 15:07:10,216 - step: 1106, training_loss: 5.24783e+01
2025-07-26 15:07:20,008 - step: 1107, training_loss: 5.40673e+01
2025-07-26 15:07:29,833 - step: 1108, training_loss: 5.33912e+01
2025-07-26 15:07:39,639 - step: 1109, training_loss: 5.48972e+01
2025-07-26 15:07:49,460 - step: 1110, training_loss: 5.31920e+01
2025-07-26 15:07:59,257 - step: 1111, training_loss: 5.46300e+01
2025-07-26 15:08:09,094 - step: 1112, training_loss: 5.52884e+01
2025-07-26 15:08:18,950 - step: 1113, training_loss: 5.33501e+01
2025-07-26 15:08:28,826 - step: 1114, training_loss: 5.42264e+01
2025-07-26 15:08:38,660 - step: 1115, training_loss: 5.32750e+01
2025-07-26 15:08:48,526 - step: 1116, training_loss: 5.39360e+01
2025-07-26 15:08:58,377 - step: 1117, training_loss: 5.41590e+01
2025-07-26 15:09:08,227 - step: 1118, training_loss: 5.40829e+01
2025-07-26 15:09:18,110 - step: 1119, training_loss: 5.34353e+01
2025-07-26 15:09:28,028 - step: 1120, training_loss: 5.45382e+01
2025-07-26 15:09:37,926 - step: 1121, training_loss: 5.46158e+01
2025-07-26 15:09:47,865 - step: 1122, training_loss: 5.46133e+01
2025-07-26 15:09:57,806 - step: 1123, training_loss: 5.50298e+01
2025-07-26 15:10:07,757 - step: 1124, training_loss: 5.40701e+01
2025-07-26 15:10:17,674 - step: 1125, training_loss: 5.21322e+01
2025-07-26 15:10:27,580 - step: 1126, training_loss: 5.48444e+01
2025-07-26 15:10:37,544 - step: 1127, training_loss: 5.39725e+01
2025-07-26 15:10:47,485 - step: 1128, training_loss: 5.25232e+01
2025-07-26 15:10:57,469 - step: 1129, training_loss: 5.33106e+01
2025-07-26 15:11:07,454 - step: 1130, training_loss: 5.40595e+01
2025-07-26 15:11:17,420 - step: 1131, training_loss: 5.29385e+01
2025-07-26 15:11:27,427 - step: 1132, training_loss: 5.43051e+01
2025-07-26 15:11:37,451 - step: 1133, training_loss: 5.18909e+01
2025-07-26 15:11:47,451 - step: 1134, training_loss: 5.24453e+01
2025-07-26 15:11:57,470 - step: 1135, training_loss: 5.33550e+01
2025-07-26 15:12:07,501 - step: 1136, training_loss: 5.39385e+01
2025-07-26 15:12:17,519 - step: 1137, training_loss: 5.30792e+01
2025-07-26 15:12:27,590 - step: 1138, training_loss: 5.57881e+01
2025-07-26 15:12:37,624 - step: 1139, training_loss: 5.35917e+01
2025-07-26 15:12:47,694 - step: 1140, training_loss: 5.43576e+01
2025-07-26 15:12:57,765 - step: 1141, training_loss: 5.28948e+01
2025-07-26 15:13:07,808 - step: 1142, training_loss: 5.30222e+01
2025-07-26 15:13:17,887 - step: 1143, training_loss: 5.25990e+01
2025-07-26 15:13:28,022 - step: 1144, training_loss: 5.54017e+01
2025-07-26 15:13:38,118 - step: 1145, training_loss: 5.46097e+01
2025-07-26 15:13:48,258 - step: 1146, training_loss: 5.44483e+01
2025-07-26 15:13:58,383 - step: 1147, training_loss: 5.35933e+01
2025-07-26 15:14:08,561 - step: 1148, training_loss: 5.27744e+01
2025-07-26 15:14:18,683 - step: 1149, training_loss: 5.29114e+01
2025-07-26 15:14:28,868 - step: 1150, training_loss: 5.50107e+01
2025-07-26 15:14:39,016 - step: 1151, training_loss: 5.36248e+01
2025-07-26 15:14:49,211 - step: 1152, training_loss: 5.21309e+01
2025-07-26 15:14:59,396 - step: 1153, training_loss: 5.63484e+01
2025-07-26 15:15:09,567 - step: 1154, training_loss: 5.21687e+01
2025-07-26 15:15:19,768 - step: 1155, training_loss: 5.51088e+01
2025-07-26 15:15:29,993 - step: 1156, training_loss: 5.30426e+01
2025-07-26 15:15:40,200 - step: 1157, training_loss: 5.35882e+01
2025-07-26 15:15:50,403 - step: 1158, training_loss: 5.45855e+01
2025-07-26 15:16:00,632 - step: 1159, training_loss: 5.63249e+01
2025-07-26 15:16:10,861 - step: 1160, training_loss: 5.48019e+01
2025-07-26 15:16:21,125 - step: 1161, training_loss: 5.36807e+01
2025-07-26 15:16:31,390 - step: 1162, training_loss: 5.18392e+01
2025-07-26 15:16:41,638 - step: 1163, training_loss: 5.36532e+01
2025-07-26 15:16:51,910 - step: 1164, training_loss: 5.34610e+01
2025-07-26 15:17:02,159 - step: 1165, training_loss: 5.40202e+01
2025-07-26 15:17:12,422 - step: 1166, training_loss: 5.26396e+01
2025-07-26 15:17:22,725 - step: 1167, training_loss: 5.33906e+01
2025-07-26 15:17:33,011 - step: 1168, training_loss: 5.34712e+01
2025-07-26 15:17:43,314 - step: 1169, training_loss: 5.52119e+01
2025-07-26 15:17:53,674 - step: 1170, training_loss: 5.37709e+01
2025-07-26 15:18:03,973 - step: 1171, training_loss: 5.35780e+01
2025-07-26 15:18:14,284 - step: 1172, training_loss: 5.54834e+01
2025-07-26 15:18:24,666 - step: 1173, training_loss: 5.33260e+01
2025-07-26 15:18:34,982 - step: 1174, training_loss: 5.55092e+01
2025-07-26 15:18:45,328 - step: 1175, training_loss: 5.20262e+01
2025-07-26 15:18:55,700 - step: 1176, training_loss: 5.38056e+01
2025-07-26 15:19:06,090 - step: 1177, training_loss: 5.37440e+01
2025-07-26 15:19:16,461 - step: 1178, training_loss: 5.42191e+01
2025-07-26 15:19:26,862 - step: 1179, training_loss: 5.35269e+01
2025-07-26 15:19:37,265 - step: 1180, training_loss: 5.38117e+01
2025-07-26 15:19:47,709 - step: 1181, training_loss: 5.30202e+01
2025-07-26 15:19:58,150 - step: 1182, training_loss: 5.25258e+01
2025-07-26 15:20:08,574 - step: 1183, training_loss: 5.33393e+01
2025-07-26 15:20:18,998 - step: 1184, training_loss: 4.98408e+01
2025-07-26 15:20:29,424 - step: 1185, training_loss: 5.44187e+01
2025-07-26 15:20:39,841 - step: 1186, training_loss: 5.18933e+01
2025-07-26 15:20:50,300 - step: 1187, training_loss: 5.35391e+01
2025-07-26 15:21:00,754 - step: 1188, training_loss: 5.41553e+01
2025-07-26 15:21:11,207 - step: 1189, training_loss: 5.28583e+01
2025-07-26 15:21:21,700 - step: 1190, training_loss: 5.31315e+01
2025-07-26 15:21:32,181 - step: 1191, training_loss: 5.29786e+01
2025-07-26 15:21:42,676 - step: 1192, training_loss: 5.26260e+01
2025-07-26 15:21:53,202 - step: 1193, training_loss: 5.49728e+01
2025-07-26 15:22:03,699 - step: 1194, training_loss: 5.22680e+01
2025-07-26 15:22:14,219 - step: 1195, training_loss: 5.34162e+01
2025-07-26 15:22:24,761 - step: 1196, training_loss: 5.30437e+01
2025-07-26 15:22:35,276 - step: 1197, training_loss: 5.29918e+01
2025-07-26 15:22:45,794 - step: 1198, training_loss: 5.22056e+01
2025-07-26 15:22:56,380 - step: 1199, training_loss: 5.41164e+01
2025-07-26 15:23:06,929 - step: 1200, training_loss: 5.46269e+01
2025-07-26 15:23:09,022 - step: 1200, evaluation_loss: 5.33717e+01
2025-07-26 15:23:19,673 - step: 1201, training_loss: 5.35723e+01
2025-07-26 15:23:30,257 - step: 1202, training_loss: 5.26120e+01
2025-07-26 15:23:40,859 - step: 1203, training_loss: 5.22405e+01
2025-07-26 15:23:51,495 - step: 1204, training_loss: 5.44793e+01
2025-07-26 15:24:02,115 - step: 1205, training_loss: 5.25124e+01
2025-07-26 15:24:12,712 - step: 1206, training_loss: 5.23844e+01
2025-07-26 15:24:23,381 - step: 1207, training_loss: 5.33101e+01
2025-07-26 15:24:34,016 - step: 1208, training_loss: 5.46383e+01
2025-07-26 15:24:44,657 - step: 1209, training_loss: 5.31242e+01
2025-07-26 15:24:55,352 - step: 1210, training_loss: 5.31944e+01
2025-07-26 15:25:05,993 - step: 1211, training_loss: 5.27001e+01
2025-07-26 15:25:16,648 - step: 1212, training_loss: 5.32288e+01
2025-07-26 15:25:27,319 - step: 1213, training_loss: 5.28168e+01
2025-07-26 15:25:37,987 - step: 1214, training_loss: 5.17412e+01
2025-07-26 15:25:48,665 - step: 1215, training_loss: 5.36526e+01
2025-07-26 15:25:59,378 - step: 1216, training_loss: 5.20868e+01
2025-07-26 15:26:10,119 - step: 1217, training_loss: 5.39927e+01
2025-07-26 15:26:20,819 - step: 1218, training_loss: 5.19657e+01
2025-07-26 15:26:31,527 - step: 1219, training_loss: 5.16050e+01
2025-07-26 15:26:42,272 - step: 1220, training_loss: 5.41518e+01
2025-07-26 15:26:53,018 - step: 1221, training_loss: 5.14478e+01
2025-07-26 15:27:03,775 - step: 1222, training_loss: 5.41022e+01
2025-07-26 15:27:14,522 - step: 1223, training_loss: 5.41870e+01
2025-07-26 15:27:25,242 - step: 1224, training_loss: 5.37396e+01
2025-07-26 15:27:36,085 - step: 1225, training_loss: 5.36945e+01
2025-07-26 15:27:46,907 - step: 1226, training_loss: 5.33964e+01
2025-07-26 15:27:57,747 - step: 1227, training_loss: 5.32708e+01
2025-07-26 15:28:08,571 - step: 1228, training_loss: 5.02681e+01
2025-07-26 15:28:19,421 - step: 1229, training_loss: 5.24733e+01
2025-07-26 15:28:30,278 - step: 1230, training_loss: 5.38668e+01
2025-07-26 15:28:41,113 - step: 1231, training_loss: 5.06102e+01
2025-07-26 15:28:51,981 - step: 1232, training_loss: 5.06135e+01
2025-07-26 15:29:02,829 - step: 1233, training_loss: 5.36983e+01
2025-07-26 15:29:13,658 - step: 1234, training_loss: 5.11823e+01
2025-07-26 15:29:24,585 - step: 1235, training_loss: 5.26133e+01
2025-07-26 15:29:35,469 - step: 1236, training_loss: 5.34425e+01
2025-07-26 15:29:46,365 - step: 1237, training_loss: 5.08337e+01
2025-07-26 15:29:57,322 - step: 1238, training_loss: 5.25072e+01
2025-07-26 15:30:08,236 - step: 1239, training_loss: 5.24752e+01
2025-07-26 15:30:19,169 - step: 1240, training_loss: 5.39782e+01
2025-07-26 15:30:30,073 - step: 1241, training_loss: 5.18896e+01
2025-07-26 15:30:40,993 - step: 1242, training_loss: 5.15063e+01
2025-07-26 15:30:51,924 - step: 1243, training_loss: 5.16578e+01
2025-07-26 15:31:02,909 - step: 1244, training_loss: 5.15452e+01
2025-07-26 15:31:13,873 - step: 1245, training_loss: 5.30316e+01
2025-07-26 15:31:24,893 - step: 1246, training_loss: 5.36087e+01
2025-07-26 15:31:35,857 - step: 1247, training_loss: 5.28625e+01
2025-07-26 15:31:46,814 - step: 1248, training_loss: 5.11792e+01
2025-07-26 15:31:57,788 - step: 1249, training_loss: 5.11945e+01
2025-07-26 15:32:08,822 - step: 1250, training_loss: 5.20937e+01
2025-07-26 15:32:19,814 - step: 1251, training_loss: 5.35447e+01
2025-07-26 15:32:30,867 - step: 1252, training_loss: 5.32998e+01
2025-07-26 15:32:41,945 - step: 1253, training_loss: 5.32628e+01
2025-07-26 15:32:52,989 - step: 1254, training_loss: 5.24898e+01
2025-07-26 15:33:04,043 - step: 1255, training_loss: 5.30684e+01
2025-07-26 15:33:15,098 - step: 1256, training_loss: 5.19710e+01
2025-07-26 15:33:26,169 - step: 1257, training_loss: 5.32494e+01
2025-07-26 15:33:37,239 - step: 1258, training_loss: 5.25918e+01
2025-07-26 15:33:48,332 - step: 1259, training_loss: 5.22540e+01
2025-07-26 15:33:59,453 - step: 1260, training_loss: 5.15348e+01
2025-07-26 15:34:10,571 - step: 1261, training_loss: 5.55724e+01
2025-07-26 15:34:21,724 - step: 1262, training_loss: 5.11448e+01
2025-07-26 15:34:32,848 - step: 1263, training_loss: 5.45333e+01
2025-07-26 15:34:44,041 - step: 1264, training_loss: 5.20877e+01
2025-07-26 15:34:55,199 - step: 1265, training_loss: 5.27738e+01
2025-07-26 15:35:06,341 - step: 1266, training_loss: 5.39069e+01
2025-07-26 15:35:17,502 - step: 1267, training_loss: 5.28291e+01
2025-07-26 15:35:28,699 - step: 1268, training_loss: 5.35911e+01
2025-07-26 15:35:39,894 - step: 1269, training_loss: 5.26434e+01
2025-07-26 15:35:51,079 - step: 1270, training_loss: 5.28999e+01
2025-07-26 15:36:02,236 - step: 1271, training_loss: 5.41911e+01
2025-07-26 15:36:13,446 - step: 1272, training_loss: 5.24277e+01
2025-07-26 15:36:24,617 - step: 1273, training_loss: 5.35127e+01
2025-07-26 15:36:35,875 - step: 1274, training_loss: 5.17075e+01
2025-07-26 15:36:47,154 - step: 1275, training_loss: 5.18854e+01
2025-07-26 15:36:58,359 - step: 1276, training_loss: 5.10314e+01
2025-07-26 15:37:09,633 - step: 1277, training_loss: 5.47583e+01
2025-07-26 15:37:20,935 - step: 1278, training_loss: 5.27920e+01
2025-07-26 15:37:32,218 - step: 1279, training_loss: 5.10015e+01
2025-07-26 15:37:43,451 - step: 1280, training_loss: 5.15438e+01
2025-07-26 15:37:54,741 - step: 1281, training_loss: 5.23768e+01
2025-07-26 15:38:05,977 - step: 1282, training_loss: 5.31200e+01
2025-07-26 15:38:17,266 - step: 1283, training_loss: 5.27433e+01
2025-07-26 15:38:28,558 - step: 1284, training_loss: 5.21101e+01
2025-07-26 15:38:39,890 - step: 1285, training_loss: 5.32714e+01
2025-07-26 15:38:51,232 - step: 1286, training_loss: 5.15422e+01
2025-07-26 15:39:02,533 - step: 1287, training_loss: 5.28028e+01
2025-07-26 15:39:13,890 - step: 1288, training_loss: 5.22191e+01
2025-07-26 15:39:25,245 - step: 1289, training_loss: 5.25958e+01
2025-07-26 15:39:36,603 - step: 1290, training_loss: 5.35771e+01
2025-07-26 15:39:47,971 - step: 1291, training_loss: 5.03726e+01
2025-07-26 15:39:59,356 - step: 1292, training_loss: 5.22519e+01
2025-07-26 15:40:10,742 - step: 1293, training_loss: 5.12061e+01
2025-07-26 15:40:22,134 - step: 1294, training_loss: 5.21586e+01
2025-07-26 15:40:33,529 - step: 1295, training_loss: 5.28019e+01
2025-07-26 15:40:44,936 - step: 1296, training_loss: 5.18270e+01
2025-07-26 15:40:56,369 - step: 1297, training_loss: 5.14569e+01
2025-07-26 15:41:07,815 - step: 1298, training_loss: 5.15378e+01
2025-07-26 15:41:19,288 - step: 1299, training_loss: 5.18832e+01
2025-07-26 15:41:30,777 - step: 1300, training_loss: 5.35968e+01
2025-07-26 15:41:42,214 - step: 1301, training_loss: 5.25483e+01
2025-07-26 15:41:53,710 - step: 1302, training_loss: 5.26782e+01
2025-07-26 15:42:05,137 - step: 1303, training_loss: 5.29967e+01
2025-07-26 15:42:16,641 - step: 1304, training_loss: 5.19288e+01
2025-07-26 15:42:28,117 - step: 1305, training_loss: 5.14060e+01
2025-07-26 15:42:39,605 - step: 1306, training_loss: 5.21567e+01
2025-07-26 15:42:51,101 - step: 1307, training_loss: 5.20721e+01
2025-07-26 15:43:02,604 - step: 1308, training_loss: 5.08676e+01
2025-07-26 15:43:14,140 - step: 1309, training_loss: 5.12492e+01
2025-07-26 15:43:25,629 - step: 1310, training_loss: 5.21419e+01
2025-07-26 15:43:37,155 - step: 1311, training_loss: 5.24211e+01
2025-07-26 15:43:48,720 - step: 1312, training_loss: 5.22220e+01
2025-07-26 15:44:00,262 - step: 1313, training_loss: 5.27223e+01
2025-07-26 15:44:11,869 - step: 1314, training_loss: 5.04539e+01
2025-07-26 15:44:23,418 - step: 1315, training_loss: 5.15874e+01
2025-07-26 15:44:34,984 - step: 1316, training_loss: 5.25405e+01
2025-07-26 15:44:46,550 - step: 1317, training_loss: 4.86866e+01
2025-07-26 15:44:58,137 - step: 1318, training_loss: 5.03891e+01
2025-07-26 15:45:09,753 - step: 1319, training_loss: 5.14100e+01
2025-07-26 15:45:21,366 - step: 1320, training_loss: 5.16051e+01
2025-07-26 15:45:32,965 - step: 1321, training_loss: 5.22106e+01
2025-07-26 15:45:44,585 - step: 1322, training_loss: 5.22140e+01
2025-07-26 15:45:56,245 - step: 1323, training_loss: 5.39529e+01
2025-07-26 15:46:07,917 - step: 1324, training_loss: 5.31224e+01
2025-07-26 15:46:19,570 - step: 1325, training_loss: 5.02884e+01
2025-07-26 15:46:31,221 - step: 1326, training_loss: 5.11905e+01
2025-07-26 15:46:42,884 - step: 1327, training_loss: 5.12098e+01
2025-07-26 15:46:54,551 - step: 1328, training_loss: 5.18838e+01
2025-07-26 15:47:06,221 - step: 1329, training_loss: 5.08445e+01
2025-07-26 15:47:17,878 - step: 1330, training_loss: 5.15086e+01
2025-07-26 15:47:29,577 - step: 1331, training_loss: 4.94227e+01
2025-07-26 15:47:41,261 - step: 1332, training_loss: 5.20830e+01
2025-07-26 15:47:52,972 - step: 1333, training_loss: 5.04925e+01
2025-07-26 15:48:04,673 - step: 1334, training_loss: 4.98302e+01
2025-07-26 15:48:16,410 - step: 1335, training_loss: 5.15437e+01
2025-07-26 15:48:28,159 - step: 1336, training_loss: 5.22970e+01
2025-07-26 15:48:39,890 - step: 1337, training_loss: 5.21299e+01
2025-07-26 15:48:51,666 - step: 1338, training_loss: 5.12717e+01
2025-07-26 15:49:03,407 - step: 1339, training_loss: 5.02382e+01
2025-07-26 15:49:15,201 - step: 1340, training_loss: 5.08670e+01
2025-07-26 15:49:26,987 - step: 1341, training_loss: 5.11878e+01
2025-07-26 15:49:38,740 - step: 1342, training_loss: 5.12252e+01
2025-07-26 15:49:50,520 - step: 1343, training_loss: 5.31861e+01
2025-07-26 15:50:02,319 - step: 1344, training_loss: 5.27103e+01
2025-07-26 15:50:14,136 - step: 1345, training_loss: 4.93446e+01
2025-07-26 15:50:25,991 - step: 1346, training_loss: 5.11537e+01
2025-07-26 15:50:37,837 - step: 1347, training_loss: 5.10719e+01
2025-07-26 15:50:49,699 - step: 1348, training_loss: 5.14761e+01
2025-07-26 15:51:01,579 - step: 1349, training_loss: 5.25174e+01
2025-07-26 15:51:13,444 - step: 1350, training_loss: 4.98976e+01
2025-07-26 15:51:25,325 - step: 1351, training_loss: 5.16036e+01
2025-07-26 15:51:37,202 - step: 1352, training_loss: 5.29809e+01
2025-07-26 15:51:49,073 - step: 1353, training_loss: 5.13021e+01
2025-07-26 15:52:00,949 - step: 1354, training_loss: 5.07033e+01
2025-07-26 15:52:12,804 - step: 1355, training_loss: 5.25168e+01
2025-07-26 15:52:24,682 - step: 1356, training_loss: 5.25531e+01
2025-07-26 15:52:36,587 - step: 1357, training_loss: 5.34686e+01
2025-07-26 15:52:48,482 - step: 1358, training_loss: 5.10875e+01
2025-07-26 15:53:00,423 - step: 1359, training_loss: 5.32940e+01
2025-07-26 15:53:12,345 - step: 1360, training_loss: 5.02325e+01
2025-07-26 15:53:24,325 - step: 1361, training_loss: 4.85361e+01
2025-07-26 15:53:36,254 - step: 1362, training_loss: 5.02708e+01
2025-07-26 15:53:48,199 - step: 1363, training_loss: 5.23528e+01
2025-07-26 15:54:00,171 - step: 1364, training_loss: 5.19117e+01
2025-07-26 15:54:12,113 - step: 1365, training_loss: 5.10062e+01
2025-07-26 15:54:24,100 - step: 1366, training_loss: 5.20732e+01
2025-07-26 15:54:36,093 - step: 1367, training_loss: 5.11227e+01
2025-07-26 15:54:48,092 - step: 1368, training_loss: 5.16903e+01
2025-07-26 15:55:00,104 - step: 1369, training_loss: 5.11718e+01
2025-07-26 15:55:12,122 - step: 1370, training_loss: 5.14346e+01
2025-07-26 15:55:24,122 - step: 1371, training_loss: 4.96055e+01
2025-07-26 15:55:36,154 - step: 1372, training_loss: 5.11741e+01
2025-07-26 15:55:48,198 - step: 1373, training_loss: 5.24033e+01
2025-07-26 15:56:00,251 - step: 1374, training_loss: 5.13707e+01
2025-07-26 15:56:12,297 - step: 1375, training_loss: 5.22461e+01
2025-07-26 15:56:24,370 - step: 1376, training_loss: 5.00059e+01
2025-07-26 15:56:36,435 - step: 1377, training_loss: 5.20780e+01
2025-07-26 15:56:48,495 - step: 1378, training_loss: 5.18913e+01
2025-07-26 15:57:00,608 - step: 1379, training_loss: 4.91452e+01
2025-07-26 15:57:12,734 - step: 1380, training_loss: 5.24654e+01
2025-07-26 15:57:24,824 - step: 1381, training_loss: 5.26991e+01
2025-07-26 15:57:36,948 - step: 1382, training_loss: 5.11121e+01
2025-07-26 15:57:49,089 - step: 1383, training_loss: 4.88433e+01
2025-07-26 15:58:01,235 - step: 1384, training_loss: 5.30872e+01
2025-07-26 15:58:13,385 - step: 1385, training_loss: 5.04004e+01
2025-07-26 15:58:25,559 - step: 1386, training_loss: 5.20795e+01
2025-07-26 15:58:37,731 - step: 1387, training_loss: 5.19591e+01
2025-07-26 15:58:49,901 - step: 1388, training_loss: 5.07770e+01
2025-07-26 15:59:02,093 - step: 1389, training_loss: 5.07362e+01
2025-07-26 15:59:14,263 - step: 1390, training_loss: 5.06593e+01
2025-07-26 15:59:26,456 - step: 1391, training_loss: 4.99794e+01
2025-07-26 15:59:38,682 - step: 1392, training_loss: 5.02278e+01
2025-07-26 15:59:50,900 - step: 1393, training_loss: 5.05136e+01
2025-07-26 16:00:03,114 - step: 1394, training_loss: 5.11100e+01
2025-07-26 16:00:15,335 - step: 1395, training_loss: 5.02980e+01
2025-07-26 16:00:27,585 - step: 1396, training_loss: 4.98409e+01
2025-07-26 16:00:39,830 - step: 1397, training_loss: 5.01693e+01
2025-07-26 16:00:52,099 - step: 1398, training_loss: 5.03257e+01
2025-07-26 16:01:04,364 - step: 1399, training_loss: 4.85530e+01
2025-07-26 16:01:16,631 - step: 1400, training_loss: 5.00169e+01
2025-07-26 16:01:28,920 - step: 1401, training_loss: 4.95211e+01
2025-07-26 16:01:41,202 - step: 1402, training_loss: 5.19731e+01
2025-07-26 16:01:53,509 - step: 1403, training_loss: 4.98191e+01
2025-07-26 16:02:05,796 - step: 1404, training_loss: 5.00951e+01
2025-07-26 16:02:18,107 - step: 1405, training_loss: 4.79058e+01
2025-07-26 16:02:30,440 - step: 1406, training_loss: 5.04817e+01
2025-07-26 16:02:42,751 - step: 1407, training_loss: 4.96952e+01
2025-07-26 16:02:55,119 - step: 1408, training_loss: 5.04036e+01
2025-07-26 16:03:07,437 - step: 1409, training_loss: 5.08485e+01
2025-07-26 16:03:19,782 - step: 1410, training_loss: 5.04164e+01
2025-07-26 16:03:32,179 - step: 1411, training_loss: 4.89726e+01
2025-07-26 16:03:44,587 - step: 1412, training_loss: 5.13165e+01
2025-07-26 16:03:56,957 - step: 1413, training_loss: 5.03060e+01
2025-07-26 16:04:09,362 - step: 1414, training_loss: 4.99653e+01
2025-07-26 16:04:21,800 - step: 1415, training_loss: 4.97721e+01
2025-07-26 16:04:34,217 - step: 1416, training_loss: 4.85265e+01
2025-07-26 16:04:46,636 - step: 1417, training_loss: 5.04402e+01
2025-07-26 16:04:59,064 - step: 1418, training_loss: 5.19149e+01
2025-07-26 16:05:11,488 - step: 1419, training_loss: 4.74822e+01
2025-07-26 16:05:23,899 - step: 1420, training_loss: 5.13905e+01
2025-07-26 16:05:36,352 - step: 1421, training_loss: 4.93526e+01
2025-07-26 16:05:48,810 - step: 1422, training_loss: 5.17050e+01
2025-07-26 16:06:01,272 - step: 1423, training_loss: 4.86806e+01
2025-07-26 16:06:13,730 - step: 1424, training_loss: 5.10126e+01
2025-07-26 16:06:26,223 - step: 1425, training_loss: 4.96995e+01
2025-07-26 16:06:38,698 - step: 1426, training_loss: 5.04912e+01
2025-07-26 16:06:51,200 - step: 1427, training_loss: 5.08044e+01
2025-07-26 16:07:03,717 - step: 1428, training_loss: 5.13757e+01
2025-07-26 16:07:16,235 - step: 1429, training_loss: 5.05411e+01
2025-07-26 16:07:28,771 - step: 1430, training_loss: 4.96880e+01
2025-07-26 16:07:41,297 - step: 1431, training_loss: 4.97157e+01
2025-07-26 16:07:53,869 - step: 1432, training_loss: 5.04197e+01
2025-07-26 16:08:06,389 - step: 1433, training_loss: 5.06771e+01
2025-07-26 16:08:19,010 - step: 1434, training_loss: 5.10329e+01
2025-07-26 16:08:31,563 - step: 1435, training_loss: 4.96576e+01
2025-07-26 16:08:44,143 - step: 1436, training_loss: 5.11334e+01
2025-07-26 16:08:56,725 - step: 1437, training_loss: 4.96393e+01
2025-07-26 16:09:09,304 - step: 1438, training_loss: 5.14170e+01
2025-07-26 16:09:21,968 - step: 1439, training_loss: 5.02738e+01
2025-07-26 16:09:34,626 - step: 1440, training_loss: 5.13561e+01
2025-07-26 16:09:47,291 - step: 1441, training_loss: 4.95077e+01
2025-07-26 16:09:59,947 - step: 1442, training_loss: 4.93304e+01
2025-07-26 16:10:12,618 - step: 1443, training_loss: 5.10618e+01
2025-07-26 16:10:25,299 - step: 1444, training_loss: 4.95472e+01
2025-07-26 16:10:37,958 - step: 1445, training_loss: 4.91474e+01
2025-07-26 16:10:50,636 - step: 1446, training_loss: 5.07497e+01
2025-07-26 16:11:03,291 - step: 1447, training_loss: 4.99693e+01
2025-07-26 16:11:15,966 - step: 1448, training_loss: 4.95351e+01
2025-07-26 16:11:28,650 - step: 1449, training_loss: 4.95526e+01
2025-07-26 16:11:41,306 - step: 1450, training_loss: 5.08066e+01
2025-07-26 16:11:53,989 - step: 1451, training_loss: 4.91957e+01
2025-07-26 16:12:06,661 - step: 1452, training_loss: 5.12323e+01
2025-07-26 16:12:19,364 - step: 1453, training_loss: 5.18472e+01
2025-07-26 16:12:32,066 - step: 1454, training_loss: 4.80864e+01
2025-07-26 16:12:44,821 - step: 1455, training_loss: 4.83909e+01
2025-07-26 16:12:57,547 - step: 1456, training_loss: 5.07004e+01
2025-07-26 16:13:10,276 - step: 1457, training_loss: 5.09436e+01
2025-07-26 16:13:23,059 - step: 1458, training_loss: 5.07823e+01
2025-07-26 16:13:35,807 - step: 1459, training_loss: 5.10260e+01
2025-07-26 16:13:48,593 - step: 1460, training_loss: 4.92439e+01
2025-07-26 16:14:01,369 - step: 1461, training_loss: 4.96786e+01
2025-07-26 16:14:14,167 - step: 1462, training_loss: 5.15053e+01
2025-07-26 16:14:26,962 - step: 1463, training_loss: 5.02943e+01
2025-07-26 16:14:39,729 - step: 1464, training_loss: 4.88516e+01
2025-07-26 16:14:52,570 - step: 1465, training_loss: 4.94469e+01
2025-07-26 16:15:05,382 - step: 1466, training_loss: 4.84886e+01
2025-07-26 16:15:18,216 - step: 1467, training_loss: 5.00897e+01
2025-07-26 16:15:31,067 - step: 1468, training_loss: 5.02904e+01
2025-07-26 16:15:43,871 - step: 1469, training_loss: 4.96668e+01
2025-07-26 16:15:56,772 - step: 1470, training_loss: 4.96189e+01
2025-07-26 16:16:09,627 - step: 1471, training_loss: 4.97116e+01
2025-07-26 16:16:22,543 - step: 1472, training_loss: 4.89688e+01
2025-07-26 16:16:35,427 - step: 1473, training_loss: 4.84749e+01
2025-07-26 16:16:48,294 - step: 1474, training_loss: 4.99052e+01
2025-07-26 16:17:01,193 - step: 1475, training_loss: 5.01608e+01
2025-07-26 16:17:14,044 - step: 1476, training_loss: 4.84944e+01
2025-07-26 16:17:26,930 - step: 1477, training_loss: 4.90091e+01
2025-07-26 16:17:39,827 - step: 1478, training_loss: 4.95017e+01
2025-07-26 16:17:52,821 - step: 1479, training_loss: 4.88515e+01
2025-07-26 16:18:05,717 - step: 1480, training_loss: 5.03583e+01
2025-07-26 16:18:18,652 - step: 1481, training_loss: 5.02592e+01
2025-07-26 16:18:31,642 - step: 1482, training_loss: 4.96410e+01
2025-07-26 16:18:44,587 - step: 1483, training_loss: 5.14384e+01
2025-07-26 16:18:57,586 - step: 1484, training_loss: 5.07686e+01
2025-07-26 16:19:10,582 - step: 1485, training_loss: 5.00064e+01
2025-07-26 16:19:23,540 - step: 1486, training_loss: 5.02110e+01
2025-07-26 16:19:36,569 - step: 1487, training_loss: 4.87257e+01
2025-07-26 16:19:49,595 - step: 1488, training_loss: 4.96872e+01
2025-07-26 16:20:02,583 - step: 1489, training_loss: 5.01551e+01
2025-07-26 16:20:15,596 - step: 1490, training_loss: 4.83566e+01
2025-07-26 16:20:28,654 - step: 1491, training_loss: 5.15007e+01
2025-07-26 16:20:41,709 - step: 1492, training_loss: 4.92067e+01
2025-07-26 16:20:54,782 - step: 1493, training_loss: 4.86217e+01
2025-07-26 16:21:07,865 - step: 1494, training_loss: 4.97793e+01
2025-07-26 16:21:20,951 - step: 1495, training_loss: 4.91820e+01
2025-07-26 16:21:34,023 - step: 1496, training_loss: 4.82068e+01
2025-07-26 16:21:47,100 - step: 1497, training_loss: 4.80894e+01
2025-07-26 16:22:00,214 - step: 1498, training_loss: 4.93105e+01
2025-07-26 16:22:13,275 - step: 1499, training_loss: 4.88036e+01
2025-07-26 16:22:26,406 - step: 1500, training_loss: 4.97811e+01
2025-07-26 16:22:26,606 - Generating samples at step: 1500
2025-07-26 16:23:42,377 - step: 1501, training_loss: 5.15709e+01
2025-07-26 16:23:55,508 - step: 1502, training_loss: 4.75154e+01
2025-07-26 16:24:08,619 - step: 1503, training_loss: 4.96563e+01
2025-07-26 16:24:21,789 - step: 1504, training_loss: 5.09746e+01
2025-07-26 16:24:34,932 - step: 1505, training_loss: 4.81685e+01
2025-07-26 16:24:48,117 - step: 1506, training_loss: 4.79027e+01
2025-07-26 16:25:01,298 - step: 1507, training_loss: 4.63483e+01
2025-07-26 16:25:14,484 - step: 1508, training_loss: 4.88942e+01
2025-07-26 16:25:27,663 - step: 1509, training_loss: 5.07530e+01
2025-07-26 16:25:40,858 - step: 1510, training_loss: 4.94440e+01
2025-07-26 16:25:54,059 - step: 1511, training_loss: 4.99790e+01
2025-07-26 16:26:07,253 - step: 1512, training_loss: 4.85591e+01
2025-07-26 16:26:20,487 - step: 1513, training_loss: 4.98528e+01
2025-07-26 16:26:33,714 - step: 1514, training_loss: 4.94391e+01
2025-07-26 16:26:46,906 - step: 1515, training_loss: 4.83708e+01
2025-07-26 16:27:00,161 - step: 1516, training_loss: 5.00200e+01
2025-07-26 16:27:13,438 - step: 1517, training_loss: 4.82959e+01
2025-07-26 16:27:26,684 - step: 1518, training_loss: 4.95789e+01
2025-07-26 16:27:39,973 - step: 1519, training_loss: 4.98837e+01
2025-07-26 16:27:53,260 - step: 1520, training_loss: 4.89046e+01
2025-07-26 16:28:06,509 - step: 1521, training_loss: 4.91667e+01
2025-07-26 16:28:19,801 - step: 1522, training_loss: 4.86855e+01
2025-07-26 16:28:33,090 - step: 1523, training_loss: 4.82134e+01
2025-07-26 16:28:46,381 - step: 1524, training_loss: 4.87492e+01
2025-07-26 16:28:59,728 - step: 1525, training_loss: 4.93298e+01
2025-07-26 16:29:13,047 - step: 1526, training_loss: 4.71121e+01
2025-07-26 16:29:26,404 - step: 1527, training_loss: 4.85236e+01
2025-07-26 16:29:39,774 - step: 1528, training_loss: 4.94729e+01
2025-07-26 16:29:53,106 - step: 1529, training_loss: 4.86027e+01
2025-07-26 16:30:06,449 - step: 1530, training_loss: 4.77452e+01
2025-07-26 16:30:19,803 - step: 1531, training_loss: 4.85375e+01
2025-07-26 16:30:33,161 - step: 1532, training_loss: 4.70925e+01
2025-07-26 16:30:46,557 - step: 1533, training_loss: 5.11138e+01
2025-07-26 16:30:59,828 - step: 1534, training_loss: 4.91815e+01
2025-07-26 16:31:13,228 - step: 1535, training_loss: 4.92382e+01
2025-07-26 16:31:26,667 - step: 1536, training_loss: 4.86902e+01
2025-07-26 16:31:40,068 - step: 1537, training_loss: 4.75992e+01
2025-07-26 16:31:53,521 - step: 1538, training_loss: 4.98698e+01
2025-07-26 16:32:06,968 - step: 1539, training_loss: 4.89928e+01
2025-07-26 16:32:20,266 - step: 1540, training_loss: 4.89862e+01
2025-07-26 16:32:33,736 - step: 1541, training_loss: 4.90470e+01
2025-07-26 16:32:47,203 - step: 1542, training_loss: 4.87806e+01
2025-07-26 16:33:00,675 - step: 1543, training_loss: 4.78113e+01
2025-07-26 16:33:14,166 - step: 1544, training_loss: 4.80705e+01
2025-07-26 16:33:27,659 - step: 1545, training_loss: 4.91955e+01
2025-07-26 16:33:41,138 - step: 1546, training_loss: 4.79425e+01
2025-07-26 16:33:54,644 - step: 1547, training_loss: 5.01470e+01
2025-07-26 16:34:08,193 - step: 1548, training_loss: 4.72749e+01
2025-07-26 16:34:21,739 - step: 1549, training_loss: 4.77953e+01
2025-07-26 16:34:35,264 - step: 1550, training_loss: 4.95286e+01
2025-07-26 16:34:48,823 - step: 1551, training_loss: 4.81958e+01
2025-07-26 16:35:02,376 - step: 1552, training_loss: 5.03379e+01
2025-07-26 16:35:15,955 - step: 1553, training_loss: 4.83128e+01
2025-07-26 16:35:29,573 - step: 1554, training_loss: 4.87115e+01
2025-07-26 16:35:43,006 - step: 1555, training_loss: 4.86991e+01
2025-07-26 16:35:56,578 - step: 1556, training_loss: 4.75083e+01
2025-07-26 16:36:10,168 - step: 1557, training_loss: 4.83301e+01
2025-07-26 16:36:23,695 - step: 1558, training_loss: 4.64699e+01
2025-07-26 16:36:37,301 - step: 1559, training_loss: 4.88735e+01
2025-07-26 16:36:50,919 - step: 1560, training_loss: 4.86341e+01
2025-07-26 16:37:04,533 - step: 1561, training_loss: 4.79182e+01
2025-07-26 16:37:18,170 - step: 1562, training_loss: 4.78001e+01
2025-07-26 16:37:31,869 - step: 1563, training_loss: 4.68407e+01
2025-07-26 16:37:45,543 - step: 1564, training_loss: 4.86640e+01
2025-07-26 16:37:59,223 - step: 1565, training_loss: 4.80850e+01
2025-07-26 16:38:12,891 - step: 1566, training_loss: 4.89196e+01
2025-07-26 16:38:26,558 - step: 1567, training_loss: 4.95069e+01
2025-07-26 16:38:40,249 - step: 1568, training_loss: 4.91593e+01
2025-07-26 16:38:53,926 - step: 1569, training_loss: 4.83023e+01
2025-07-26 16:39:07,598 - step: 1570, training_loss: 4.92448e+01
2025-07-26 16:39:21,279 - step: 1571, training_loss: 4.91714e+01
2025-07-26 16:39:34,963 - step: 1572, training_loss: 4.82243e+01
2025-07-26 16:39:48,659 - step: 1573, training_loss: 4.91235e+01
2025-07-26 16:40:02,307 - step: 1574, training_loss: 4.86893e+01
2025-07-26 16:40:16,035 - step: 1575, training_loss: 4.76703e+01
2025-07-26 16:40:29,681 - step: 1576, training_loss: 4.71094e+01
2025-07-26 16:40:43,325 - step: 1577, training_loss: 4.80958e+01
2025-07-26 16:40:57,008 - step: 1578, training_loss: 4.64574e+01
2025-07-26 16:41:10,802 - step: 1579, training_loss: 4.82615e+01
2025-07-26 16:41:24,560 - step: 1580, training_loss: 4.97737e+01
2025-07-26 16:41:38,339 - step: 1581, training_loss: 4.81695e+01
2025-07-26 16:41:52,117 - step: 1582, training_loss: 4.75797e+01
2025-07-26 16:42:05,804 - step: 1583, training_loss: 4.80314e+01
2025-07-26 16:42:19,589 - step: 1584, training_loss: 4.80383e+01
2025-07-26 16:42:33,432 - step: 1585, training_loss: 4.71990e+01
2025-07-26 16:42:47,224 - step: 1586, training_loss: 4.69354e+01
2025-07-26 16:43:01,049 - step: 1587, training_loss: 4.91731e+01
2025-07-26 16:43:14,906 - step: 1588, training_loss: 4.85271e+01
2025-07-26 16:43:28,762 - step: 1589, training_loss: 4.73224e+01
2025-07-26 16:43:42,641 - step: 1590, training_loss: 4.85928e+01
2025-07-26 16:43:56,531 - step: 1591, training_loss: 4.74858e+01
2025-07-26 16:44:10,417 - step: 1592, training_loss: 4.75275e+01
2025-07-26 16:44:24,300 - step: 1593, training_loss: 4.92960e+01
