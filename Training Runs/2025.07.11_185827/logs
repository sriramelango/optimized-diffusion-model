2025-07-11 18:58:27,120 - Training run started at: 2025.07.11_185827
2025-07-11 18:58:27,120 - Run directory: Training Runs/2025.07.11_185827
2025-07-11 18:58:27,882 - NCSNpp(
  (act): SiLU()
  (time_embed): GaussianFourierProjection()
  (time_mlp): Sequential(
    (0): Linear(in_features=128, out_features=256, bias=True)
    (1): SiLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
  )
  (label_emb): Linear(in_features=1, out_features=256, bias=True)
  (input_conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (down_blocks): ModuleList(
    (0-1): 2 x ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Conv_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=64, bias=True)
      (GroupNorm_1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.1, inplace=False)
      (Conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): SiLU()
    )
    (2): ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Conv_0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=128, bias=True)
      (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.1, inplace=False)
      (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (NIN_0): NIN()
      (act): SiLU()
    )
    (3-5): 3 x ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=128, bias=True)
      (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.1, inplace=False)
      (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): SiLU()
    )
  )
  (down_attn): ModuleList(
    (0-1): 2 x AttnBlockpp(
      (GroupNorm_0): GroupNorm(16, 64, eps=1e-06, affine=True)
      (NIN_0): NIN()
      (NIN_1): NIN()
      (NIN_2): NIN()
      (NIN_3): NIN()
    )
    (2-5): 4 x None
  )
  (downsample): ModuleList(
    (0): Downsample(
      (Conv_0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))
    )
    (1): Downsample(
      (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
    )
    (2): None
  )
  (mid_block1): ResnetBlockDDPMpp(
    (GroupNorm_0): GroupNorm(32, 128, eps=1e-06, affine=True)
    (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (Dense_0): Linear(in_features=256, out_features=128, bias=True)
    (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
    (Dropout_0): Dropout(p=0.1, inplace=False)
    (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (act): SiLU()
  )
  (mid_block2): ResnetBlockDDPMpp(
    (GroupNorm_0): GroupNorm(32, 128, eps=1e-06, affine=True)
    (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (Dense_0): Linear(in_features=256, out_features=128, bias=True)
    (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
    (Dropout_0): Dropout(p=0.1, inplace=False)
    (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (act): SiLU()
  )
  (up_blocks): ModuleList(
    (0-5): 6 x ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(32, 256, eps=1e-06, affine=True)
      (Conv_0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=128, bias=True)
      (GroupNorm_1): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.1, inplace=False)
      (Conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (NIN_0): NIN()
      (act): SiLU()
    )
    (6): ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(32, 192, eps=1e-06, affine=True)
      (Conv_0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=64, bias=True)
      (GroupNorm_1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.1, inplace=False)
      (Conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (NIN_0): NIN()
      (act): SiLU()
    )
    (7-8): 2 x ResnetBlockDDPMpp(
      (GroupNorm_0): GroupNorm(32, 128, eps=1e-06, affine=True)
      (Conv_0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (Dense_0): Linear(in_features=256, out_features=64, bias=True)
      (GroupNorm_1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (Dropout_0): Dropout(p=0.1, inplace=False)
      (Conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (NIN_0): NIN()
      (act): SiLU()
    )
  )
  (up_attn): ModuleList(
    (0-5): 6 x None
    (6-8): 3 x AttnBlockpp(
      (GroupNorm_0): GroupNorm(16, 64, eps=1e-06, affine=True)
      (NIN_0): NIN()
      (NIN_1): NIN()
      (NIN_2): NIN()
      (NIN_3): NIN()
    )
  )
  (upsample): ModuleList(
    (0-1): 2 x Upsample(
      (Conv_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): None
  )
  (out_norm): GroupNorm(16, 64, eps=1e-06, affine=True)
  (out_act): SiLU()
  (out_conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2025-07-11 18:58:27,883 - EMA: <models.ema.ExponentialMovingAverage object at 0x14f97f0a03a0>
2025-07-11 18:58:27,883 - Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0
)
2025-07-11 18:58:27,883 - Scaler: None.
2025-07-11 18:58:27,884 - No checkpoint found at Training Runs/2025.07.11_185827/checkpoints-meta/checkpoint.pth. Returned the same state as input
2025-07-11 18:58:27,929 - Starting training loop at step 0.
2025-07-11 18:58:32,721 - step: 0, training_loss: 2.04877e+01
2025-07-11 18:58:33,014 - step: 0, evaluation_loss: 2.04158e+01
2025-07-11 18:58:33,830 - step: 1, training_loss: 2.01687e+01
2025-07-11 18:58:34,714 - step: 2, training_loss: 2.09378e+01
2025-07-11 18:58:35,628 - step: 3, training_loss: 2.07493e+01
2025-07-11 18:58:36,597 - step: 4, training_loss: 2.12344e+01
2025-07-11 18:58:38,019 - step: 5, training_loss: 2.06044e+01
2025-07-11 18:58:38,921 - step: 6, training_loss: 2.05758e+01
2025-07-11 18:58:39,842 - step: 7, training_loss: 2.08943e+01
2025-07-11 18:58:40,762 - step: 8, training_loss: 2.09154e+01
2025-07-11 18:58:41,738 - step: 9, training_loss: 2.00119e+01
2025-07-11 18:58:42,866 - step: 10, training_loss: 2.05525e+01
2025-07-11 18:58:43,834 - step: 11, training_loss: 2.06698e+01
2025-07-11 18:58:44,787 - step: 12, training_loss: 2.01433e+01
2025-07-11 18:58:45,751 - step: 13, training_loss: 2.08664e+01
2025-07-11 18:58:46,711 - step: 14, training_loss: 2.11337e+01
2025-07-11 18:58:47,670 - step: 15, training_loss: 2.05909e+01
2025-07-11 18:58:48,668 - step: 16, training_loss: 2.07217e+01
2025-07-11 18:58:49,649 - step: 17, training_loss: 2.10233e+01
2025-07-11 18:58:50,648 - step: 18, training_loss: 2.10069e+01
2025-07-11 18:58:51,652 - step: 19, training_loss: 2.09354e+01
2025-07-11 18:58:52,657 - step: 20, training_loss: 2.02935e+01
2025-07-11 18:58:53,673 - step: 21, training_loss: 2.10731e+01
2025-07-11 18:58:54,723 - step: 22, training_loss: 2.03906e+01
2025-07-11 18:58:56,183 - step: 23, training_loss: 2.09854e+01
2025-07-11 18:58:57,226 - step: 24, training_loss: 2.10972e+01
2025-07-11 18:58:58,289 - step: 25, training_loss: 2.08187e+01
2025-07-11 18:58:59,821 - step: 26, training_loss: 2.09194e+01
2025-07-11 18:59:00,885 - step: 27, training_loss: 2.06855e+01
2025-07-11 18:59:01,975 - step: 28, training_loss: 2.13191e+01
2025-07-11 18:59:03,050 - step: 29, training_loss: 2.08680e+01
2025-07-11 18:59:04,201 - step: 30, training_loss: 2.11060e+01
2025-07-11 18:59:05,264 - step: 31, training_loss: 2.04537e+01
2025-07-11 18:59:06,348 - step: 32, training_loss: 2.05900e+01
2025-07-11 18:59:07,682 - step: 33, training_loss: 2.05522e+01
2025-07-11 18:59:08,853 - step: 34, training_loss: 2.07465e+01
2025-07-11 18:59:09,943 - step: 35, training_loss: 2.05337e+01
2025-07-11 18:59:11,038 - step: 36, training_loss: 2.12095e+01
2025-07-11 18:59:12,139 - step: 37, training_loss: 2.09412e+01
2025-07-11 18:59:13,249 - step: 38, training_loss: 1.99674e+01
2025-07-11 18:59:14,372 - step: 39, training_loss: 2.04935e+01
2025-07-11 18:59:15,501 - step: 40, training_loss: 2.03100e+01
2025-07-11 18:59:16,637 - step: 41, training_loss: 2.09731e+01
2025-07-11 18:59:17,773 - step: 42, training_loss: 2.07497e+01
2025-07-11 18:59:18,916 - step: 43, training_loss: 2.10718e+01
2025-07-11 18:59:20,067 - step: 44, training_loss: 2.09638e+01
2025-07-11 18:59:21,223 - step: 45, training_loss: 2.06615e+01
2025-07-11 18:59:22,386 - step: 46, training_loss: 2.09625e+01
2025-07-11 18:59:23,556 - step: 47, training_loss: 2.06146e+01
2025-07-11 18:59:27,743 - step: 48, training_loss: 2.04826e+01
2025-07-11 18:59:28,873 - step: 49, training_loss: 2.11655e+01
2025-07-11 18:59:30,344 - step: 50, training_loss: 2.04796e+01
2025-07-11 18:59:31,545 - step: 51, training_loss: 2.13574e+01
2025-07-11 18:59:32,810 - step: 52, training_loss: 2.09202e+01
2025-07-11 18:59:34,223 - step: 53, training_loss: 2.09208e+01
2025-07-11 18:59:35,468 - step: 54, training_loss: 2.04846e+01
2025-07-11 18:59:36,736 - step: 55, training_loss: 2.07980e+01
2025-07-11 18:59:38,480 - step: 56, training_loss: 1.99771e+01
2025-07-11 18:59:39,743 - step: 57, training_loss: 2.11445e+01
2025-07-11 18:59:40,996 - step: 58, training_loss: 2.01535e+01
2025-07-11 18:59:42,289 - step: 59, training_loss: 2.01935e+01
2025-07-11 18:59:43,696 - step: 60, training_loss: 2.04131e+01
2025-07-11 18:59:44,961 - step: 61, training_loss: 2.03227e+01
2025-07-11 18:59:46,232 - step: 62, training_loss: 2.08297e+01
2025-07-11 18:59:47,540 - step: 63, training_loss: 2.06923e+01
2025-07-11 18:59:48,825 - step: 64, training_loss: 2.10859e+01
2025-07-11 18:59:50,145 - step: 65, training_loss: 1.99859e+01
2025-07-11 18:59:51,443 - step: 66, training_loss: 2.03202e+01
2025-07-11 18:59:52,767 - step: 67, training_loss: 2.06270e+01
2025-07-11 18:59:54,079 - step: 68, training_loss: 2.06846e+01
2025-07-11 18:59:55,481 - step: 69, training_loss: 2.03609e+01
2025-07-11 18:59:57,153 - step: 70, training_loss: 2.12703e+01
2025-07-11 18:59:58,550 - step: 71, training_loss: 2.02527e+01
2025-07-11 19:00:00,304 - step: 72, training_loss: 2.05576e+01
2025-07-11 19:00:01,669 - step: 73, training_loss: 2.04526e+01
2025-07-11 19:00:03,060 - step: 74, training_loss: 2.09624e+01
2025-07-11 19:00:04,587 - step: 75, training_loss: 2.10178e+01
2025-07-11 19:00:05,981 - step: 76, training_loss: 2.06319e+01
2025-07-11 19:00:07,625 - step: 77, training_loss: 2.12330e+01
2025-07-11 19:00:09,235 - step: 78, training_loss: 2.02469e+01
2025-07-11 19:00:10,646 - step: 79, training_loss: 2.11413e+01
2025-07-11 19:00:12,091 - step: 80, training_loss: 2.04459e+01
2025-07-11 19:00:13,722 - step: 81, training_loss: 2.05355e+01
2025-07-11 19:00:15,139 - step: 82, training_loss: 2.00833e+01
2025-07-11 19:00:16,561 - step: 83, training_loss: 2.03728e+01
2025-07-11 19:00:18,002 - step: 84, training_loss: 2.08958e+01
2025-07-11 19:00:19,439 - step: 85, training_loss: 2.06373e+01
2025-07-11 19:00:20,871 - step: 86, training_loss: 2.05535e+01
2025-07-11 19:00:22,308 - step: 87, training_loss: 2.11484e+01
2025-07-11 19:00:23,763 - step: 88, training_loss: 2.12225e+01
2025-07-11 19:00:25,258 - step: 89, training_loss: 2.02892e+01
2025-07-11 19:00:27,146 - step: 90, training_loss: 2.10501e+01
2025-07-11 19:00:28,658 - step: 91, training_loss: 1.97519e+01
2025-07-11 19:00:30,491 - step: 92, training_loss: 1.99925e+01
2025-07-11 19:00:31,968 - step: 93, training_loss: 1.98952e+01
2025-07-11 19:00:33,460 - step: 94, training_loss: 2.02872e+01
2025-07-11 19:00:34,962 - step: 95, training_loss: 2.10625e+01
2025-07-11 19:00:36,464 - step: 96, training_loss: 2.00418e+01
2025-07-11 19:00:38,285 - step: 97, training_loss: 2.02551e+01
2025-07-11 19:00:39,810 - step: 98, training_loss: 2.04423e+01
2025-07-11 19:00:41,324 - step: 99, training_loss: 2.09251e+01
2025-07-11 19:00:42,946 - step: 100, training_loss: 2.05113e+01
2025-07-11 19:00:43,229 - step: 100, evaluation_loss: 2.03187e+01
2025-07-11 19:00:44,797 - step: 101, training_loss: 2.01122e+01
2025-07-11 19:00:46,340 - step: 102, training_loss: 2.10557e+01
2025-07-11 19:00:47,894 - step: 103, training_loss: 2.02509e+01
2025-07-11 19:00:49,448 - step: 104, training_loss: 2.02581e+01
2025-07-11 19:00:51,010 - step: 105, training_loss: 2.05560e+01
2025-07-11 19:00:52,611 - step: 106, training_loss: 1.99934e+01
2025-07-11 19:00:54,209 - step: 107, training_loss: 2.01401e+01
2025-07-11 19:00:55,911 - step: 108, training_loss: 2.03701e+01
2025-07-11 19:00:57,553 - step: 109, training_loss: 2.05129e+01
2025-07-11 19:00:59,189 - step: 110, training_loss: 2.05760e+01
2025-07-11 19:01:01,016 - step: 111, training_loss: 1.99753e+01
2025-07-11 19:01:02,677 - step: 112, training_loss: 2.02403e+01
2025-07-11 19:01:04,457 - step: 113, training_loss: 1.98464e+01
2025-07-11 19:01:06,098 - step: 114, training_loss: 2.01976e+01
2025-07-11 19:01:08,143 - step: 115, training_loss: 2.07206e+01
2025-07-11 19:01:09,803 - step: 116, training_loss: 1.99990e+01
2025-07-11 19:01:11,447 - step: 117, training_loss: 2.04543e+01
2025-07-11 19:01:13,351 - step: 118, training_loss: 2.01381e+01
2025-07-11 19:01:15,006 - step: 119, training_loss: 2.05272e+01
2025-07-11 19:01:16,688 - step: 120, training_loss: 2.08320e+01
2025-07-11 19:01:18,354 - step: 121, training_loss: 2.11036e+01
2025-07-11 19:01:20,050 - step: 122, training_loss: 2.04554e+01
2025-07-11 19:01:21,730 - step: 123, training_loss: 1.99548e+01
2025-07-11 19:01:23,428 - step: 124, training_loss: 2.00916e+01
2025-07-11 19:01:25,143 - step: 125, training_loss: 2.05187e+01
2025-07-11 19:01:27,265 - step: 126, training_loss: 1.96836e+01
2025-07-11 19:01:29,025 - step: 127, training_loss: 2.06605e+01
2025-07-11 19:01:31,019 - step: 128, training_loss: 1.98339e+01
2025-07-11 19:01:32,767 - step: 129, training_loss: 2.01950e+01
2025-07-11 19:01:34,716 - step: 130, training_loss: 2.01117e+01
2025-07-11 19:01:36,478 - step: 131, training_loss: 1.98919e+01
2025-07-11 19:01:38,735 - step: 132, training_loss: 2.03740e+01
2025-07-11 19:01:40,480 - step: 133, training_loss: 2.01854e+01
2025-07-11 19:01:42,267 - step: 134, training_loss: 2.03470e+01
2025-07-11 19:01:44,129 - step: 135, training_loss: 2.10535e+01
2025-07-11 19:01:45,913 - step: 136, training_loss: 2.07047e+01
2025-07-11 19:01:47,699 - step: 137, training_loss: 2.01122e+01
2025-07-11 19:01:49,504 - step: 138, training_loss: 1.99243e+01
2025-07-11 19:01:51,297 - step: 139, training_loss: 2.07022e+01
2025-07-11 19:01:53,087 - step: 140, training_loss: 2.06419e+01
2025-07-11 19:01:54,887 - step: 141, training_loss: 2.06304e+01
2025-07-11 19:01:57,234 - step: 142, training_loss: 1.99220e+01
2025-07-11 19:01:59,075 - step: 143, training_loss: 2.02142e+01
2025-07-11 19:02:01,192 - step: 144, training_loss: 2.05317e+01
2025-07-11 19:02:03,060 - step: 145, training_loss: 2.05207e+01
2025-07-11 19:02:04,916 - step: 146, training_loss: 2.05908e+01
2025-07-11 19:02:06,798 - step: 147, training_loss: 2.07352e+01
2025-07-11 19:02:09,036 - step: 148, training_loss: 2.00640e+01
2025-07-11 19:02:10,894 - step: 149, training_loss: 2.03516e+01
2025-07-11 19:02:12,756 - step: 150, training_loss: 2.05843e+01
2025-07-11 19:02:14,632 - step: 151, training_loss: 2.03364e+01
2025-07-11 19:02:16,516 - step: 152, training_loss: 2.04495e+01
2025-07-11 19:02:18,398 - step: 153, training_loss: 1.98779e+01
2025-07-11 19:02:20,284 - step: 154, training_loss: 1.94113e+01
2025-07-11 19:02:22,175 - step: 155, training_loss: 1.97795e+01
2025-07-11 19:02:24,072 - step: 156, training_loss: 1.99663e+01
2025-07-11 19:02:26,013 - step: 157, training_loss: 1.98910e+01
2025-07-11 19:02:27,926 - step: 158, training_loss: 2.05651e+01
2025-07-11 19:02:30,028 - step: 159, training_loss: 2.07435e+01
2025-07-11 19:02:31,950 - step: 160, training_loss: 2.03456e+01
2025-07-11 19:02:33,925 - step: 161, training_loss: 2.04190e+01
2025-07-11 19:02:35,860 - step: 162, training_loss: 2.05585e+01
2025-07-11 19:02:37,924 - step: 163, training_loss: 1.97178e+01
2025-07-11 19:02:39,879 - step: 164, training_loss: 2.08559e+01
2025-07-11 19:02:41,855 - step: 165, training_loss: 1.96255e+01
2025-07-11 19:02:44,151 - step: 166, training_loss: 2.02056e+01
2025-07-11 19:02:46,129 - step: 167, training_loss: 1.91280e+01
2025-07-11 19:02:48,153 - step: 168, training_loss: 2.01379e+01
2025-07-11 19:02:50,157 - step: 169, training_loss: 2.05610e+01
2025-07-11 19:02:52,152 - step: 170, training_loss: 2.10133e+01
2025-07-11 19:02:54,173 - step: 171, training_loss: 1.99030e+01
2025-07-11 19:02:56,187 - step: 172, training_loss: 2.02182e+01
2025-07-11 19:02:58,237 - step: 173, training_loss: 2.00442e+01
2025-07-11 19:03:00,717 - step: 174, training_loss: 1.96993e+01
2025-07-11 19:03:02,811 - step: 175, training_loss: 2.05386e+01
2025-07-11 19:03:05,100 - step: 176, training_loss: 2.02611e+01
2025-07-11 19:03:07,180 - step: 177, training_loss: 2.04941e+01
2025-07-11 19:03:09,643 - step: 178, training_loss: 1.99237e+01
2025-07-11 19:03:11,725 - step: 179, training_loss: 2.05183e+01
2025-07-11 19:03:14,098 - step: 180, training_loss: 2.04916e+01
2025-07-11 19:03:16,164 - step: 181, training_loss: 2.02296e+01
2025-07-11 19:03:18,257 - step: 182, training_loss: 2.01062e+01
2025-07-11 19:03:20,351 - step: 183, training_loss: 2.05661e+01
2025-07-11 19:03:22,459 - step: 184, training_loss: 1.96301e+01
2025-07-11 19:03:24,608 - step: 185, training_loss: 1.99128e+01
2025-07-11 19:03:27,189 - step: 186, training_loss: 2.02384e+01
2025-07-11 19:03:29,340 - step: 187, training_loss: 1.97196e+01
2025-07-11 19:03:31,605 - step: 188, training_loss: 1.95830e+01
2025-07-11 19:03:33,725 - step: 189, training_loss: 2.03668e+01
2025-07-11 19:03:35,878 - step: 190, training_loss: 2.00989e+01
2025-07-11 19:03:38,152 - step: 191, training_loss: 2.01556e+01
2025-07-11 19:03:40,324 - step: 192, training_loss: 1.98323e+01
2025-07-11 19:03:42,471 - step: 193, training_loss: 1.99112e+01
2025-07-11 19:03:44,619 - step: 194, training_loss: 2.03536e+01
2025-07-11 19:03:46,700 - step: 195, training_loss: 2.01755e+01
2025-07-11 19:03:48,862 - step: 196, training_loss: 2.01456e+01
2025-07-11 19:03:51,027 - step: 197, training_loss: 2.03413e+01
2025-07-11 19:03:53,222 - step: 198, training_loss: 1.98916e+01
2025-07-11 19:03:55,460 - step: 199, training_loss: 1.98373e+01
2025-07-11 19:03:58,010 - step: 200, training_loss: 2.00739e+01
2025-07-11 19:03:58,294 - step: 200, evaluation_loss: 2.06926e+01
2025-07-11 19:04:00,965 - step: 201, training_loss: 2.04840e+01
2025-07-11 19:04:03,211 - step: 202, training_loss: 2.04869e+01
2025-07-11 19:04:05,454 - step: 203, training_loss: 2.05244e+01
2025-07-11 19:04:07,701 - step: 204, training_loss: 1.98118e+01
2025-07-11 19:04:10,071 - step: 205, training_loss: 1.95018e+01
2025-07-11 19:04:12,347 - step: 206, training_loss: 2.03237e+01
2025-07-11 19:04:14,682 - step: 207, training_loss: 2.02127e+01
2025-07-11 19:04:16,949 - step: 208, training_loss: 1.93881e+01
2025-07-11 19:04:19,236 - step: 209, training_loss: 1.92905e+01
2025-07-11 19:04:21,518 - step: 210, training_loss: 2.06426e+01
2025-07-11 19:04:23,781 - step: 211, training_loss: 1.97681e+01
2025-07-11 19:04:26,053 - step: 212, training_loss: 1.99731e+01
2025-07-11 19:04:28,355 - step: 213, training_loss: 2.00229e+01
2025-07-11 19:04:31,150 - step: 214, training_loss: 2.00841e+01
2025-07-11 19:04:33,447 - step: 215, training_loss: 1.94683e+01
2025-07-11 19:04:35,744 - step: 216, training_loss: 1.95176e+01
2025-07-11 19:04:38,102 - step: 217, training_loss: 1.93220e+01
2025-07-11 19:04:40,413 - step: 218, training_loss: 1.98581e+01
2025-07-11 19:04:42,742 - step: 219, training_loss: 1.97676e+01
2025-07-11 19:04:45,070 - step: 220, training_loss: 2.03041e+01
2025-07-11 19:04:47,435 - step: 221, training_loss: 1.94349e+01
2025-07-11 19:04:49,782 - step: 222, training_loss: 1.96512e+01
2025-07-11 19:04:52,125 - step: 223, training_loss: 1.94627e+01
2025-07-11 19:04:54,490 - step: 224, training_loss: 1.93770e+01
2025-07-11 19:04:57,421 - step: 225, training_loss: 1.89036e+01
2025-07-11 19:04:59,795 - step: 226, training_loss: 1.93472e+01
2025-07-11 19:05:02,163 - step: 227, training_loss: 1.95885e+01
2025-07-11 19:05:04,558 - step: 228, training_loss: 1.93659e+01
2025-07-11 19:05:06,956 - step: 229, training_loss: 2.03724e+01
2025-07-11 19:05:09,604 - step: 230, training_loss: 1.92844e+01
2025-07-11 19:05:12,004 - step: 231, training_loss: 1.96654e+01
2025-07-11 19:05:14,501 - step: 232, training_loss: 1.97380e+01
2025-07-11 19:05:16,924 - step: 233, training_loss: 1.96395e+01
2025-07-11 19:05:19,362 - step: 234, training_loss: 1.91064e+01
2025-07-11 19:05:21,784 - step: 235, training_loss: 1.96833e+01
2025-07-11 19:05:24,237 - step: 236, training_loss: 1.98225e+01
2025-07-11 19:05:26,702 - step: 237, training_loss: 1.92217e+01
2025-07-11 19:05:29,201 - step: 238, training_loss: 1.95701e+01
2025-07-11 19:05:31,831 - step: 239, training_loss: 2.00487e+01
2025-07-11 19:05:34,298 - step: 240, training_loss: 2.09680e+01
2025-07-11 19:05:36,785 - step: 241, training_loss: 2.07034e+01
2025-07-11 19:05:39,803 - step: 242, training_loss: 2.02146e+01
2025-07-11 19:05:42,343 - step: 243, training_loss: 1.94908e+01
2025-07-11 19:05:44,783 - step: 244, training_loss: 1.90604e+01
2025-07-11 19:05:47,270 - step: 245, training_loss: 1.92234e+01
2025-07-11 19:05:49,775 - step: 246, training_loss: 1.98771e+01
2025-07-11 19:05:52,294 - step: 247, training_loss: 2.00143e+01
2025-07-11 19:05:54,863 - step: 248, training_loss: 1.98217e+01
2025-07-11 19:05:57,891 - step: 249, training_loss: 1.94751e+01
2025-07-11 19:06:00,647 - step: 250, training_loss: 2.05864e+01
2025-07-11 19:06:03,201 - step: 251, training_loss: 1.95269e+01
2025-07-11 19:06:05,749 - step: 252, training_loss: 2.00409e+01
2025-07-11 19:06:08,337 - step: 253, training_loss: 1.98976e+01
2025-07-11 19:06:10,888 - step: 254, training_loss: 1.92585e+01
2025-07-11 19:06:13,440 - step: 255, training_loss: 1.93791e+01
2025-07-11 19:06:16,017 - step: 256, training_loss: 1.93738e+01
2025-07-11 19:06:18,582 - step: 257, training_loss: 1.96359e+01
2025-07-11 19:06:21,156 - step: 258, training_loss: 2.02194e+01
2025-07-11 19:06:23,735 - step: 259, training_loss: 2.00915e+01
2025-07-11 19:06:26,323 - step: 260, training_loss: 1.98250e+01
2025-07-11 19:06:28,956 - step: 261, training_loss: 2.00094e+01
2025-07-11 19:06:31,864 - step: 262, training_loss: 1.93113e+01
2025-07-11 19:06:34,478 - step: 263, training_loss: 1.91528e+01
2025-07-11 19:06:37,119 - step: 264, training_loss: 1.93823e+01
2025-07-11 19:06:39,976 - step: 265, training_loss: 1.92998e+01
2025-07-11 19:06:42,611 - step: 266, training_loss: 1.97188e+01
2025-07-11 19:06:45,243 - step: 267, training_loss: 1.96424e+01
2025-07-11 19:06:47,904 - step: 268, training_loss: 1.94472e+01
2025-07-11 19:06:50,567 - step: 269, training_loss: 1.95173e+01
2025-07-11 19:06:53,252 - step: 270, training_loss: 1.89507e+01
2025-07-11 19:06:55,913 - step: 271, training_loss: 1.98248e+01
2025-07-11 19:06:58,673 - step: 272, training_loss: 1.94943e+01
2025-07-11 19:07:01,640 - step: 273, training_loss: 2.00050e+01
2025-07-11 19:07:04,319 - step: 274, training_loss: 1.94110e+01
2025-07-11 19:07:07,050 - step: 275, training_loss: 1.97762e+01
2025-07-11 19:07:10,133 - step: 276, training_loss: 1.93018e+01
2025-07-11 19:07:12,840 - step: 277, training_loss: 1.89463e+01
2025-07-11 19:07:15,559 - step: 278, training_loss: 1.97884e+01
2025-07-11 19:07:18,271 - step: 279, training_loss: 1.91264e+01
2025-07-11 19:07:20,991 - step: 280, training_loss: 2.00859e+01
2025-07-11 19:07:23,734 - step: 281, training_loss: 1.97185e+01
2025-07-11 19:07:26,461 - step: 282, training_loss: 1.93445e+01
2025-07-11 19:07:29,235 - step: 283, training_loss: 1.98575e+01
2025-07-11 19:07:32,183 - step: 284, training_loss: 1.94232e+01
2025-07-11 19:07:34,972 - step: 285, training_loss: 1.92284e+01
2025-07-11 19:07:37,779 - step: 286, training_loss: 1.94869e+01
2025-07-11 19:07:40,583 - step: 287, training_loss: 1.95342e+01
2025-07-11 19:07:43,358 - step: 288, training_loss: 1.97797e+01
2025-07-11 19:07:46,136 - step: 289, training_loss: 1.96087e+01
2025-07-11 19:07:48,947 - step: 290, training_loss: 1.97131e+01
2025-07-11 19:07:51,737 - step: 291, training_loss: 1.90436e+01
2025-07-11 19:07:54,595 - step: 292, training_loss: 1.96473e+01
2025-07-11 19:07:57,722 - step: 293, training_loss: 1.88690e+01
2025-07-11 19:08:00,556 - step: 294, training_loss: 1.97914e+01
2025-07-11 19:08:03,364 - step: 295, training_loss: 1.90639e+01
2025-07-11 19:08:06,205 - step: 296, training_loss: 1.91442e+01
2025-07-11 19:08:09,563 - step: 297, training_loss: 1.91947e+01
2025-07-11 19:08:12,401 - step: 298, training_loss: 1.93654e+01
2025-07-11 19:08:15,273 - step: 299, training_loss: 1.85583e+01
2025-07-11 19:08:18,129 - step: 300, training_loss: 1.92569e+01
2025-07-11 19:08:18,413 - step: 300, evaluation_loss: 1.97581e+01
2025-07-11 19:08:21,298 - step: 301, training_loss: 1.86486e+01
2025-07-11 19:08:24,160 - step: 302, training_loss: 1.94640e+01
2025-07-11 19:08:27,066 - step: 303, training_loss: 1.94964e+01
2025-07-11 19:08:29,945 - step: 304, training_loss: 1.92450e+01
2025-07-11 19:08:32,869 - step: 305, training_loss: 1.97844e+01
2025-07-11 19:08:35,977 - step: 306, training_loss: 1.95910e+01
2025-07-11 19:08:39,036 - step: 307, training_loss: 1.95366e+01
2025-07-11 19:08:41,999 - step: 308, training_loss: 1.90035e+01
2025-07-11 19:08:45,198 - step: 309, training_loss: 1.89519e+01
2025-07-11 19:08:48,138 - step: 310, training_loss: 1.94787e+01
2025-07-11 19:08:51,086 - step: 311, training_loss: 1.91976e+01
2025-07-11 19:08:54,042 - step: 312, training_loss: 1.92277e+01
2025-07-11 19:08:57,002 - step: 313, training_loss: 1.87122e+01
2025-07-11 19:08:59,991 - step: 314, training_loss: 1.94013e+01
2025-07-11 19:09:02,974 - step: 315, training_loss: 1.97384e+01
2025-07-11 19:09:06,079 - step: 316, training_loss: 1.92977e+01
2025-07-11 19:09:09,278 - step: 317, training_loss: 1.88480e+01
2025-07-11 19:09:12,268 - step: 318, training_loss: 1.97834e+01
2025-07-11 19:09:15,413 - step: 319, training_loss: 1.91310e+01
2025-07-11 19:09:18,406 - step: 320, training_loss: 1.93160e+01
2025-07-11 19:09:21,400 - step: 321, training_loss: 1.86766e+01
2025-07-11 19:09:24,398 - step: 322, training_loss: 1.91808e+01
2025-07-11 19:09:27,645 - step: 323, training_loss: 1.92268e+01
2025-07-11 19:09:30,678 - step: 324, training_loss: 1.86157e+01
2025-07-11 19:09:33,702 - step: 325, training_loss: 1.87824e+01
2025-07-11 19:09:36,933 - step: 326, training_loss: 1.87567e+01
2025-07-11 19:09:40,485 - step: 327, training_loss: 1.93409e+01
2025-07-11 19:09:43,526 - step: 328, training_loss: 1.89015e+01
2025-07-11 19:09:46,571 - step: 329, training_loss: 1.90364e+01
2025-07-11 19:09:49,624 - step: 330, training_loss: 1.95710e+01
2025-07-11 19:09:52,680 - step: 331, training_loss: 1.91093e+01
2025-07-11 19:09:55,780 - step: 332, training_loss: 1.86132e+01
2025-07-11 19:09:58,936 - step: 333, training_loss: 1.92024e+01
2025-07-11 19:10:02,310 - step: 334, training_loss: 1.94697e+01
2025-07-11 19:10:05,421 - step: 335, training_loss: 1.87750e+01
2025-07-11 19:10:08,517 - step: 336, training_loss: 1.92880e+01
2025-07-11 19:10:11,704 - step: 337, training_loss: 1.88821e+01
2025-07-11 19:10:15,052 - step: 338, training_loss: 1.80535e+01
2025-07-11 19:10:18,185 - step: 339, training_loss: 1.92394e+01
2025-07-11 19:10:21,301 - step: 340, training_loss: 1.93728e+01
2025-07-11 19:10:24,426 - step: 341, training_loss: 1.83838e+01
2025-07-11 19:10:27,854 - step: 342, training_loss: 1.93665e+01
2025-07-11 19:10:31,215 - step: 343, training_loss: 1.81154e+01
2025-07-11 19:10:34,365 - step: 344, training_loss: 1.92356e+01
2025-07-11 19:10:37,542 - step: 345, training_loss: 1.85392e+01
2025-07-11 19:10:40,894 - step: 346, training_loss: 1.94256e+01
2025-07-11 19:10:44,066 - step: 347, training_loss: 1.93940e+01
2025-07-11 19:10:47,236 - step: 348, training_loss: 1.87332e+01
2025-07-11 19:10:50,443 - step: 349, training_loss: 1.96423e+01
2025-07-11 19:10:53,630 - step: 350, training_loss: 1.84843e+01
2025-07-11 19:10:56,841 - step: 351, training_loss: 1.83697e+01
2025-07-11 19:11:00,033 - step: 352, training_loss: 1.92232e+01
2025-07-11 19:11:03,238 - step: 353, training_loss: 1.91484e+01
2025-07-11 19:11:06,458 - step: 354, training_loss: 1.91792e+01
2025-07-11 19:11:10,083 - step: 355, training_loss: 1.84696e+01
2025-07-11 19:11:13,318 - step: 356, training_loss: 1.81547e+01
2025-07-11 19:11:16,549 - step: 357, training_loss: 1.87765e+01
2025-07-11 19:11:19,808 - step: 358, training_loss: 1.86785e+01
2025-07-11 19:11:23,052 - step: 359, training_loss: 1.94497e+01
2025-07-11 19:11:26,302 - step: 360, training_loss: 1.94588e+01
2025-07-11 19:11:29,593 - step: 361, training_loss: 1.90197e+01
2025-07-11 19:11:32,954 - step: 362, training_loss: 1.94723e+01
2025-07-11 19:11:36,364 - step: 363, training_loss: 1.84660e+01
2025-07-11 19:11:40,202 - step: 364, training_loss: 1.92927e+01
2025-07-11 19:11:43,501 - step: 365, training_loss: 1.90707e+01
2025-07-11 19:11:46,787 - step: 366, training_loss: 1.91338e+01
2025-07-11 19:11:50,116 - step: 367, training_loss: 1.88287e+01
2025-07-11 19:11:53,451 - step: 368, training_loss: 1.91568e+01
2025-07-11 19:11:56,785 - step: 369, training_loss: 1.87692e+01
2025-07-11 19:12:00,086 - step: 370, training_loss: 1.84086e+01
2025-07-11 19:12:03,422 - step: 371, training_loss: 1.86966e+01
2025-07-11 19:12:06,798 - step: 372, training_loss: 1.89717e+01
2025-07-11 19:12:10,628 - step: 373, training_loss: 1.87475e+01
2025-07-11 19:12:13,993 - step: 374, training_loss: 1.79872e+01
2025-07-11 19:12:17,342 - step: 375, training_loss: 1.90613e+01
2025-07-11 19:12:20,696 - step: 376, training_loss: 1.88836e+01
2025-07-11 19:12:24,058 - step: 377, training_loss: 1.87484e+01
2025-07-11 19:12:27,443 - step: 378, training_loss: 1.89913e+01
2025-07-11 19:12:30,850 - step: 379, training_loss: 1.82075e+01
2025-07-11 19:12:34,233 - step: 380, training_loss: 1.88084e+01
2025-07-11 19:12:37,678 - step: 381, training_loss: 1.82467e+01
2025-07-11 19:12:41,270 - step: 382, training_loss: 1.84337e+01
2025-07-11 19:12:44,748 - step: 383, training_loss: 1.82291e+01
2025-07-11 19:12:48,158 - step: 384, training_loss: 1.93107e+01
2025-07-11 19:12:51,571 - step: 385, training_loss: 1.88580e+01
2025-07-11 19:12:55,026 - step: 386, training_loss: 1.86723e+01
2025-07-11 19:12:58,960 - step: 387, training_loss: 1.85159e+01
2025-07-11 19:13:02,693 - step: 388, training_loss: 1.91330e+01
2025-07-11 19:13:06,302 - step: 389, training_loss: 1.84363e+01
2025-07-11 19:13:10,230 - step: 390, training_loss: 1.83744e+01
2025-07-11 19:13:13,599 - step: 391, training_loss: 1.84142e+01
2025-07-11 19:13:17,054 - step: 392, training_loss: 1.88357e+01
2025-07-11 19:13:20,530 - step: 393, training_loss: 1.88436e+01
2025-07-11 19:13:24,002 - step: 394, training_loss: 1.85489e+01
2025-07-11 19:13:27,540 - step: 395, training_loss: 1.78435e+01
2025-07-11 19:13:31,061 - step: 396, training_loss: 1.90148e+01
2025-07-11 19:13:34,579 - step: 397, training_loss: 1.83827e+01
2025-07-11 19:13:38,099 - step: 398, training_loss: 1.78999e+01
2025-07-11 19:13:41,665 - step: 399, training_loss: 1.84147e+01
2025-07-11 19:13:45,507 - step: 400, training_loss: 1.84970e+01
2025-07-11 19:13:45,791 - step: 400, evaluation_loss: 1.87686e+01
2025-07-11 19:13:49,341 - step: 401, training_loss: 1.84315e+01
2025-07-11 19:13:52,874 - step: 402, training_loss: 1.86505e+01
2025-07-11 19:13:56,434 - step: 403, training_loss: 1.89345e+01
2025-07-11 19:13:59,993 - step: 404, training_loss: 1.91494e+01
2025-07-11 19:14:03,546 - step: 405, training_loss: 1.90725e+01
2025-07-11 19:14:07,152 - step: 406, training_loss: 1.84905e+01
2025-07-11 19:14:11,118 - step: 407, training_loss: 1.86121e+01
2025-07-11 19:14:14,728 - step: 408, training_loss: 1.79536e+01
2025-07-11 19:14:18,330 - step: 409, training_loss: 1.86006e+01
2025-07-11 19:14:21,920 - step: 410, training_loss: 1.83142e+01
2025-07-11 19:14:25,520 - step: 411, training_loss: 1.89795e+01
2025-07-11 19:14:29,488 - step: 412, training_loss: 1.82286e+01
2025-07-11 19:14:33,198 - step: 413, training_loss: 1.82095e+01
2025-07-11 19:14:36,866 - step: 414, training_loss: 1.85945e+01
2025-07-11 19:14:40,982 - step: 415, training_loss: 1.83602e+01
2025-07-11 19:14:44,610 - step: 416, training_loss: 1.91188e+01
2025-07-11 19:14:48,240 - step: 417, training_loss: 1.83878e+01
2025-07-11 19:14:51,892 - step: 418, training_loss: 1.80824e+01
2025-07-11 19:14:55,572 - step: 419, training_loss: 1.88833e+01
2025-07-11 19:14:59,519 - step: 420, training_loss: 1.83261e+01
2025-07-11 19:15:03,236 - step: 421, training_loss: 1.85216e+01
2025-07-11 19:15:06,941 - step: 422, training_loss: 1.87041e+01
2025-07-11 19:15:11,049 - step: 423, training_loss: 1.87437e+01
2025-07-11 19:15:14,757 - step: 424, training_loss: 1.85098e+01
2025-07-11 19:15:18,454 - step: 425, training_loss: 1.83517e+01
2025-07-11 19:15:22,170 - step: 426, training_loss: 1.85485e+01
2025-07-11 19:15:25,911 - step: 427, training_loss: 1.90687e+01
2025-07-11 19:15:29,654 - step: 428, training_loss: 1.85831e+01
2025-07-11 19:15:33,375 - step: 429, training_loss: 1.92413e+01
2025-07-11 19:15:37,124 - step: 430, training_loss: 1.84001e+01
2025-07-11 19:15:41,153 - step: 431, training_loss: 1.86205e+01
2025-07-11 19:15:44,931 - step: 432, training_loss: 1.85004e+01
2025-07-11 19:15:48,668 - step: 433, training_loss: 1.77572e+01
2025-07-11 19:15:52,421 - step: 434, training_loss: 1.81087e+01
2025-07-11 19:15:56,173 - step: 435, training_loss: 1.81608e+01
2025-07-11 19:15:59,931 - step: 436, training_loss: 1.81168e+01
2025-07-11 19:16:03,726 - step: 437, training_loss: 1.86711e+01
2025-07-11 19:16:07,678 - step: 438, training_loss: 1.93397e+01
2025-07-11 19:16:11,704 - step: 439, training_loss: 1.88138e+01
2025-07-11 19:16:15,676 - step: 440, training_loss: 1.81924e+01
2025-07-11 19:16:19,452 - step: 441, training_loss: 1.79905e+01
2025-07-11 19:16:23,252 - step: 442, training_loss: 1.88132e+01
2025-07-11 19:16:27,072 - step: 443, training_loss: 1.77371e+01
2025-07-11 19:16:30,897 - step: 444, training_loss: 1.83700e+01
2025-07-11 19:16:34,708 - step: 445, training_loss: 1.90013e+01
2025-07-11 19:16:38,536 - step: 446, training_loss: 1.88982e+01
2025-07-11 19:16:42,433 - step: 447, training_loss: 1.84588e+01
2025-07-11 19:16:46,331 - step: 448, training_loss: 1.82057e+01
2025-07-11 19:16:50,175 - step: 449, training_loss: 1.89656e+01
2025-07-11 19:16:54,024 - step: 450, training_loss: 1.87458e+01
2025-07-11 19:16:57,925 - step: 451, training_loss: 1.79188e+01
2025-07-11 19:17:02,040 - step: 452, training_loss: 1.87563e+01
2025-07-11 19:17:05,936 - step: 453, training_loss: 1.84564e+01
2025-07-11 19:17:09,825 - step: 454, training_loss: 1.84778e+01
2025-07-11 19:17:13,704 - step: 455, training_loss: 1.85990e+01
2025-07-11 19:17:17,586 - step: 456, training_loss: 1.81677e+01
2025-07-11 19:17:21,500 - step: 457, training_loss: 1.79664e+01
2025-07-11 19:17:25,402 - step: 458, training_loss: 1.79159e+01
2025-07-11 19:17:29,622 - step: 459, training_loss: 1.80495e+01
2025-07-11 19:17:33,535 - step: 460, training_loss: 1.84011e+01
2025-07-11 19:17:37,505 - step: 461, training_loss: 1.83187e+01
2025-07-11 19:17:41,749 - step: 462, training_loss: 1.78810e+01
2025-07-11 19:17:46,020 - step: 463, training_loss: 1.80314e+01
2025-07-11 19:17:49,976 - step: 464, training_loss: 1.84837e+01
2025-07-11 19:17:53,950 - step: 465, training_loss: 1.91092e+01
2025-07-11 19:17:57,918 - step: 466, training_loss: 1.88275e+01
2025-07-11 19:18:02,096 - step: 467, training_loss: 1.85971e+01
2025-07-11 19:18:06,145 - step: 468, training_loss: 1.89387e+01
2025-07-11 19:18:10,422 - step: 469, training_loss: 1.85560e+01
2025-07-11 19:18:14,446 - step: 470, training_loss: 1.88054e+01
2025-07-11 19:18:18,438 - step: 471, training_loss: 1.81621e+01
2025-07-11 19:18:22,464 - step: 472, training_loss: 1.84911e+01
2025-07-11 19:18:26,468 - step: 473, training_loss: 1.87586e+01
2025-07-11 19:18:30,496 - step: 474, training_loss: 1.76220e+01
2025-07-11 19:18:34,516 - step: 475, training_loss: 1.80345e+01
2025-07-11 19:18:38,535 - step: 476, training_loss: 1.78282e+01
2025-07-11 19:18:42,565 - step: 477, training_loss: 1.89076e+01
2025-07-11 19:18:46,596 - step: 478, training_loss: 1.82754e+01
2025-07-11 19:18:50,656 - step: 479, training_loss: 1.73473e+01
2025-07-11 19:18:54,753 - step: 480, training_loss: 1.74568e+01
2025-07-11 19:18:59,300 - step: 481, training_loss: 1.77491e+01
2025-07-11 19:19:03,530 - step: 482, training_loss: 1.83206e+01
2025-07-11 19:19:07,588 - step: 483, training_loss: 1.78091e+01
2025-07-11 19:19:11,914 - step: 484, training_loss: 1.82356e+01
2025-07-11 19:19:16,279 - step: 485, training_loss: 1.75840e+01
2025-07-11 19:19:20,367 - step: 486, training_loss: 1.85461e+01
2025-07-11 19:19:24,470 - step: 487, training_loss: 1.78588e+01
2025-07-11 19:19:28,965 - step: 488, training_loss: 1.85359e+01
2025-07-11 19:19:33,245 - step: 489, training_loss: 1.84712e+01
2025-07-11 19:19:37,376 - step: 490, training_loss: 1.78403e+01
2025-07-11 19:19:41,816 - step: 491, training_loss: 1.81057e+01
2025-07-11 19:19:46,188 - step: 492, training_loss: 1.84565e+01
2025-07-11 19:19:50,366 - step: 493, training_loss: 1.81564e+01
2025-07-11 19:19:54,576 - step: 494, training_loss: 1.80323e+01
2025-07-11 19:19:59,241 - step: 495, training_loss: 1.78866e+01
2025-07-11 19:20:03,606 - step: 496, training_loss: 1.82233e+01
2025-07-11 19:20:07,807 - step: 497, training_loss: 1.86895e+01
2025-07-11 19:20:12,073 - step: 498, training_loss: 1.80730e+01
2025-07-11 19:20:16,509 - step: 499, training_loss: 1.86155e+01
2025-07-11 19:20:20,724 - step: 500, training_loss: 1.77140e+01
2025-07-11 19:20:21,008 - step: 500, evaluation_loss: 1.79542e+01
2025-07-11 19:20:21,187 - Generating samples at step: 500
2025-07-11 19:27:00,995 - step: 501, training_loss: 1.82958e+01
2025-07-11 19:27:05,211 - step: 502, training_loss: 1.81243e+01
2025-07-11 19:27:09,436 - step: 503, training_loss: 1.78133e+01
2025-07-11 19:27:13,656 - step: 504, training_loss: 1.77256e+01
2025-07-11 19:27:17,884 - step: 505, training_loss: 1.76181e+01
2025-07-11 19:27:22,113 - step: 506, training_loss: 1.83522e+01
2025-07-11 19:27:26,361 - step: 507, training_loss: 1.82321e+01
2025-07-11 19:27:30,597 - step: 508, training_loss: 1.82716e+01
2025-07-11 19:27:34,847 - step: 509, training_loss: 1.76670e+01
2025-07-11 19:27:39,106 - step: 510, training_loss: 1.89596e+01
2025-07-11 19:27:43,364 - step: 511, training_loss: 1.79987e+01
2025-07-11 19:27:47,632 - step: 512, training_loss: 1.72874e+01
2025-07-11 19:27:51,929 - step: 513, training_loss: 1.78484e+01
2025-07-11 19:27:56,197 - step: 514, training_loss: 1.78162e+01
2025-07-11 19:28:00,489 - step: 515, training_loss: 1.78026e+01
2025-07-11 19:28:04,815 - step: 516, training_loss: 1.78211e+01
2025-07-11 19:28:09,137 - step: 517, training_loss: 1.81342e+01
2025-07-11 19:28:13,448 - step: 518, training_loss: 1.86419e+01
2025-07-11 19:28:17,760 - step: 519, training_loss: 1.81218e+01
2025-07-11 19:28:22,105 - step: 520, training_loss: 1.74134e+01
2025-07-11 19:28:26,426 - step: 521, training_loss: 1.79769e+01
2025-07-11 19:28:30,751 - step: 522, training_loss: 1.75750e+01
2025-07-11 19:28:35,087 - step: 523, training_loss: 1.78458e+01
2025-07-11 19:28:39,456 - step: 524, training_loss: 1.85202e+01
2025-07-11 19:28:43,830 - step: 525, training_loss: 1.75917e+01
2025-07-11 19:28:48,191 - step: 526, training_loss: 1.74167e+01
2025-07-11 19:28:52,580 - step: 527, training_loss: 1.82498e+01
2025-07-11 19:28:56,947 - step: 528, training_loss: 1.73926e+01
2025-07-11 19:29:01,359 - step: 529, training_loss: 1.79542e+01
2025-07-11 19:29:05,774 - step: 530, training_loss: 1.78320e+01
2025-07-11 19:29:10,212 - step: 531, training_loss: 1.81182e+01
2025-07-11 19:29:14,644 - step: 532, training_loss: 1.84451e+01
2025-07-11 19:29:19,054 - step: 533, training_loss: 1.76135e+01
2025-07-11 19:29:23,496 - step: 534, training_loss: 1.82221e+01
2025-07-11 19:29:27,932 - step: 535, training_loss: 1.79684e+01
2025-07-11 19:29:32,376 - step: 536, training_loss: 1.75109e+01
2025-07-11 19:29:36,879 - step: 537, training_loss: 1.73970e+01
2025-07-11 19:29:41,760 - step: 538, training_loss: 1.74316e+01
2025-07-11 19:29:46,425 - step: 539, training_loss: 1.77564e+01
2025-07-11 19:29:50,888 - step: 540, training_loss: 1.73610e+01
2025-07-11 19:29:55,361 - step: 541, training_loss: 1.82920e+01
2025-07-11 19:30:00,114 - step: 542, training_loss: 1.78394e+01
2025-07-11 19:30:04,590 - step: 543, training_loss: 1.77925e+01
2025-07-11 19:30:09,077 - step: 544, training_loss: 1.77179e+01
2025-07-11 19:30:13,579 - step: 545, training_loss: 1.73969e+01
2025-07-11 19:30:18,089 - step: 546, training_loss: 1.76840e+01
2025-07-11 19:30:22,592 - step: 547, training_loss: 1.81802e+01
2025-07-11 19:30:27,104 - step: 548, training_loss: 1.80428e+01
2025-07-11 19:30:31,636 - step: 549, training_loss: 1.84633e+01
2025-07-11 19:30:36,192 - step: 550, training_loss: 1.82121e+01
2025-07-11 19:30:41,124 - step: 551, training_loss: 1.85439e+01
2025-07-11 19:30:45,687 - step: 552, training_loss: 1.73685e+01
2025-07-11 19:30:50,226 - step: 553, training_loss: 1.74791e+01
2025-07-11 19:30:54,797 - step: 554, training_loss: 1.81089e+01
2025-07-11 19:30:59,831 - step: 555, training_loss: 1.82929e+01
2025-07-11 19:31:04,402 - step: 556, training_loss: 1.75671e+01
2025-07-11 19:31:08,961 - step: 557, training_loss: 1.77799e+01
2025-07-11 19:31:13,554 - step: 558, training_loss: 1.75590e+01
2025-07-11 19:31:18,160 - step: 559, training_loss: 1.84084e+01
2025-07-11 19:31:22,749 - step: 560, training_loss: 1.75969e+01
2025-07-11 19:31:27,354 - step: 561, training_loss: 1.74817e+01
2025-07-11 19:31:31,952 - step: 562, training_loss: 1.76581e+01
2025-07-11 19:31:36,592 - step: 563, training_loss: 1.80072e+01
2025-07-11 19:31:41,757 - step: 564, training_loss: 1.79838e+01
2025-07-11 19:31:46,684 - step: 565, training_loss: 1.76547e+01
2025-07-11 19:31:51,310 - step: 566, training_loss: 1.74732e+01
2025-07-11 19:31:55,942 - step: 567, training_loss: 1.77862e+01
2025-07-11 19:32:00,605 - step: 568, training_loss: 1.77523e+01
2025-07-11 19:32:05,243 - step: 569, training_loss: 1.78885e+01
2025-07-11 19:32:09,904 - step: 570, training_loss: 1.75623e+01
2025-07-11 19:32:14,547 - step: 571, training_loss: 1.77925e+01
2025-07-11 19:32:19,200 - step: 572, training_loss: 1.77218e+01
2025-07-11 19:32:23,881 - step: 573, training_loss: 1.73910e+01
2025-07-11 19:32:28,576 - step: 574, training_loss: 1.74715e+01
2025-07-11 19:32:33,581 - step: 575, training_loss: 1.78056e+01
2025-07-11 19:32:38,298 - step: 576, training_loss: 1.78180e+01
2025-07-11 19:32:43,007 - step: 577, training_loss: 1.83019e+01
2025-07-11 19:32:47,732 - step: 578, training_loss: 1.80201e+01
2025-07-11 19:32:52,442 - step: 579, training_loss: 1.71975e+01
2025-07-11 19:32:57,167 - step: 580, training_loss: 1.64617e+01
2025-07-11 19:33:01,877 - step: 581, training_loss: 1.78782e+01
2025-07-11 19:33:06,668 - step: 582, training_loss: 1.70257e+01
2025-07-11 19:33:11,986 - step: 583, training_loss: 1.72207e+01
2025-07-11 19:33:17,002 - step: 584, training_loss: 1.77040e+01
2025-07-11 19:33:21,761 - step: 585, training_loss: 1.66101e+01
2025-07-11 19:33:26,527 - step: 586, training_loss: 1.77906e+01
2025-07-11 19:33:31,191 - step: 587, training_loss: 1.77551e+01
2025-07-11 19:33:35,989 - step: 588, training_loss: 1.69157e+01
2025-07-11 19:33:41,221 - step: 589, training_loss: 1.80510e+01
2025-07-11 19:33:46,106 - step: 590, training_loss: 1.73350e+01
2025-07-11 19:33:50,900 - step: 591, training_loss: 1.78983e+01
2025-07-11 19:33:55,720 - step: 592, training_loss: 1.77448e+01
2025-07-11 19:34:00,748 - step: 593, training_loss: 1.74402e+01
2025-07-11 19:34:05,541 - step: 594, training_loss: 1.71757e+01
2025-07-11 19:34:10,351 - step: 595, training_loss: 1.73937e+01
2025-07-11 19:34:15,175 - step: 596, training_loss: 1.76434e+01
2025-07-11 19:34:19,994 - step: 597, training_loss: 1.73516e+01
2025-07-11 19:34:24,874 - step: 598, training_loss: 1.73742e+01
2025-07-11 19:34:30,205 - step: 599, training_loss: 1.75625e+01
2025-07-11 19:34:35,067 - step: 600, training_loss: 1.75206e+01
2025-07-11 19:34:35,351 - step: 600, evaluation_loss: 1.77976e+01
2025-07-11 19:34:40,235 - step: 601, training_loss: 1.72180e+01
2025-07-11 19:34:45,113 - step: 602, training_loss: 1.75005e+01
2025-07-11 19:34:49,979 - step: 603, training_loss: 1.70051e+01
2025-07-11 19:34:54,854 - step: 604, training_loss: 1.73539e+01
2025-07-11 19:35:00,242 - step: 605, training_loss: 1.69465e+01
2025-07-11 19:35:05,157 - step: 606, training_loss: 1.74791e+01
2025-07-11 19:35:10,076 - step: 607, training_loss: 1.80854e+01
2025-07-11 19:35:14,992 - step: 608, training_loss: 1.69414e+01
2025-07-11 19:35:19,906 - step: 609, training_loss: 1.71248e+01
2025-07-11 19:35:24,852 - step: 610, training_loss: 1.79500e+01
2025-07-11 19:35:30,309 - step: 611, training_loss: 1.68356e+01
2025-07-11 19:35:35,254 - step: 612, training_loss: 1.70582e+01
2025-07-11 19:35:40,221 - step: 613, training_loss: 1.73944e+01
2025-07-11 19:35:45,188 - step: 614, training_loss: 1.72928e+01
2025-07-11 19:35:50,142 - step: 615, training_loss: 1.71707e+01
2025-07-11 19:35:55,163 - step: 616, training_loss: 1.79342e+01
2025-07-11 19:36:00,498 - step: 617, training_loss: 1.73542e+01
2025-07-11 19:36:05,469 - step: 618, training_loss: 1.83591e+01
2025-07-11 19:36:10,488 - step: 619, training_loss: 1.73461e+01
2025-07-11 19:36:15,473 - step: 620, training_loss: 1.74263e+01
2025-07-11 19:36:20,471 - step: 621, training_loss: 1.67064e+01
2025-07-11 19:36:25,495 - step: 622, training_loss: 1.68086e+01
2025-07-11 19:36:30,821 - step: 623, training_loss: 1.67253e+01
2025-07-11 19:36:35,839 - step: 624, training_loss: 1.62397e+01
2025-07-11 19:36:40,959 - step: 625, training_loss: 1.77512e+01
2025-07-11 19:36:45,978 - step: 626, training_loss: 1.71170e+01
2025-07-11 19:36:51,002 - step: 627, training_loss: 1.74218e+01
2025-07-11 19:36:56,052 - step: 628, training_loss: 1.72237e+01
2025-07-11 19:37:01,101 - step: 629, training_loss: 1.69322e+01
2025-07-11 19:37:06,205 - step: 630, training_loss: 1.73832e+01
2025-07-11 19:37:11,596 - step: 631, training_loss: 1.70695e+01
2025-07-11 19:37:17,044 - step: 632, training_loss: 1.72900e+01
2025-07-11 19:37:22,109 - step: 633, training_loss: 1.79160e+01
2025-07-11 19:37:27,182 - step: 634, training_loss: 1.70065e+01
2025-07-11 19:37:32,249 - step: 635, training_loss: 1.66850e+01
2025-07-11 19:37:37,291 - step: 636, training_loss: 1.71014e+01
2025-07-11 19:37:42,636 - step: 637, training_loss: 1.71351e+01
2025-07-11 19:37:47,733 - step: 638, training_loss: 1.69394e+01
2025-07-11 19:37:52,860 - step: 639, training_loss: 1.71867e+01
2025-07-11 19:37:57,971 - step: 640, training_loss: 1.70348e+01
2025-07-11 19:38:03,464 - step: 641, training_loss: 1.74116e+01
2025-07-11 19:38:08,610 - step: 642, training_loss: 1.65987e+01
2025-07-11 19:38:13,770 - step: 643, training_loss: 1.68855e+01
2025-07-11 19:38:18,923 - step: 644, training_loss: 1.71440e+01
2025-07-11 19:38:24,061 - step: 645, training_loss: 1.71159e+01
2025-07-11 19:38:29,246 - step: 646, training_loss: 1.75234e+01
2025-07-11 19:38:34,633 - step: 647, training_loss: 1.79230e+01
2025-07-11 19:38:39,826 - step: 648, training_loss: 1.77657e+01
2025-07-11 19:38:44,990 - step: 649, training_loss: 1.76601e+01
2025-07-11 19:38:50,155 - step: 650, training_loss: 1.69926e+01
2025-07-11 19:38:55,359 - step: 651, training_loss: 1.71293e+01
2025-07-11 19:39:00,988 - step: 652, training_loss: 1.78889e+01
2025-07-11 19:39:06,191 - step: 653, training_loss: 1.69744e+01
2025-07-11 19:39:11,769 - step: 654, training_loss: 1.69364e+01
2025-07-11 19:39:17,269 - step: 655, training_loss: 1.68234e+01
2025-07-11 19:39:22,486 - step: 656, training_loss: 1.74158e+01
2025-07-11 19:39:27,711 - step: 657, training_loss: 1.70276e+01
2025-07-11 19:39:32,992 - step: 658, training_loss: 1.67884e+01
2025-07-11 19:39:38,319 - step: 659, training_loss: 1.71226e+01
2025-07-11 19:39:43,577 - step: 660, training_loss: 1.67865e+01
2025-07-11 19:39:48,819 - step: 661, training_loss: 1.70146e+01
2025-07-11 19:39:54,066 - step: 662, training_loss: 1.62145e+01
2025-07-11 19:39:59,350 - step: 663, training_loss: 1.66365e+01
2025-07-11 19:40:04,801 - step: 664, training_loss: 1.69536e+01
2025-07-11 19:40:10,079 - step: 665, training_loss: 1.71526e+01
2025-07-11 19:40:15,374 - step: 666, training_loss: 1.68830e+01
2025-07-11 19:40:20,681 - step: 667, training_loss: 1.66910e+01
2025-07-11 19:40:26,004 - step: 668, training_loss: 1.64488e+01
2025-07-11 19:40:31,293 - step: 669, training_loss: 1.64808e+01
2025-07-11 19:40:36,656 - step: 670, training_loss: 1.76784e+01
2025-07-11 19:40:42,507 - step: 671, training_loss: 1.65058e+01
2025-07-11 19:40:47,833 - step: 672, training_loss: 1.69958e+01
2025-07-11 19:40:53,158 - step: 673, training_loss: 1.70161e+01
2025-07-11 19:40:58,510 - step: 674, training_loss: 1.68010e+01
2025-07-11 19:41:04,272 - step: 675, training_loss: 1.58299e+01
2025-07-11 19:41:09,638 - step: 676, training_loss: 1.58825e+01
2025-07-11 19:41:14,992 - step: 677, training_loss: 1.68773e+01
2025-07-11 19:41:20,353 - step: 678, training_loss: 1.76949e+01
2025-07-11 19:41:25,772 - step: 679, training_loss: 1.69766e+01
2025-07-11 19:41:31,292 - step: 680, training_loss: 1.64422e+01
2025-07-11 19:41:36,737 - step: 681, training_loss: 1.68514e+01
2025-07-11 19:41:42,584 - step: 682, training_loss: 1.70556e+01
2025-07-11 19:41:47,973 - step: 683, training_loss: 1.69950e+01
2025-07-11 19:41:53,379 - step: 684, training_loss: 1.69713e+01
2025-07-11 19:41:58,696 - step: 685, training_loss: 1.68450e+01
2025-07-11 19:42:04,349 - step: 686, training_loss: 1.62495e+01
2025-07-11 19:42:09,796 - step: 687, training_loss: 1.65960e+01
2025-07-11 19:42:15,223 - step: 688, training_loss: 1.72428e+01
2025-07-11 19:42:20,656 - step: 689, training_loss: 1.65695e+01
2025-07-11 19:42:26,124 - step: 690, training_loss: 1.75503e+01
2025-07-11 19:42:31,564 - step: 691, training_loss: 1.61654e+01
2025-07-11 19:42:37,043 - step: 692, training_loss: 1.69685e+01
2025-07-11 19:42:42,942 - step: 693, training_loss: 1.67492e+01
2025-07-11 19:42:48,407 - step: 694, training_loss: 1.65636e+01
2025-07-11 19:42:53,906 - step: 695, training_loss: 1.67129e+01
2025-07-11 19:42:59,385 - step: 696, training_loss: 1.68756e+01
2025-07-11 19:43:04,996 - step: 697, training_loss: 1.68229e+01
2025-07-11 19:43:10,485 - step: 698, training_loss: 1.65797e+01
2025-07-11 19:43:15,980 - step: 699, training_loss: 1.71182e+01
2025-07-11 19:43:21,473 - step: 700, training_loss: 1.66734e+01
2025-07-11 19:43:21,757 - step: 700, evaluation_loss: 1.69863e+01
2025-07-11 19:43:27,286 - step: 701, training_loss: 1.65575e+01
2025-07-11 19:43:32,880 - step: 702, training_loss: 1.73955e+01
2025-07-11 19:43:38,585 - step: 703, training_loss: 1.64608e+01
2025-07-11 19:43:44,134 - step: 704, training_loss: 1.63766e+01
2025-07-11 19:43:49,681 - step: 705, training_loss: 1.64470e+01
2025-07-11 19:43:55,262 - step: 706, training_loss: 1.64514e+01
2025-07-11 19:44:01,197 - step: 707, training_loss: 1.67924e+01
2025-07-11 19:44:06,812 - step: 708, training_loss: 1.67268e+01
2025-07-11 19:44:12,907 - step: 709, training_loss: 1.69011e+01
2025-07-11 19:44:18,504 - step: 710, training_loss: 1.62116e+01
2025-07-11 19:44:24,105 - step: 711, training_loss: 1.67088e+01
2025-07-11 19:44:29,740 - step: 712, training_loss: 1.62418e+01
2025-07-11 19:44:35,332 - step: 713, training_loss: 1.67342e+01
2025-07-11 19:44:40,959 - step: 714, training_loss: 1.64539e+01
2025-07-11 19:44:46,578 - step: 715, training_loss: 1.58955e+01
2025-07-11 19:44:52,216 - step: 716, training_loss: 1.67541e+01
2025-07-11 19:44:57,848 - step: 717, training_loss: 1.62475e+01
2025-07-11 19:45:03,612 - step: 718, training_loss: 1.62661e+01
2025-07-11 19:45:09,285 - step: 719, training_loss: 1.68806e+01
2025-07-11 19:45:14,922 - step: 720, training_loss: 1.69400e+01
2025-07-11 19:45:20,569 - step: 721, training_loss: 1.67079e+01
2025-07-11 19:45:26,224 - step: 722, training_loss: 1.59100e+01
2025-07-11 19:45:31,905 - step: 723, training_loss: 1.64602e+01
2025-07-11 19:45:37,629 - step: 724, training_loss: 1.59410e+01
2025-07-11 19:45:43,520 - step: 725, training_loss: 1.71599e+01
2025-07-11 19:45:49,231 - step: 726, training_loss: 1.67125e+01
2025-07-11 19:45:55,008 - step: 727, training_loss: 1.70443e+01
2025-07-11 19:46:01,236 - step: 728, training_loss: 1.68383e+01
2025-07-11 19:46:06,995 - step: 729, training_loss: 1.62626e+01
2025-07-11 19:46:13,225 - step: 730, training_loss: 1.66435e+01
2025-07-11 19:46:18,963 - step: 731, training_loss: 1.71963e+01
2025-07-11 19:46:24,688 - step: 732, training_loss: 1.67230e+01
2025-07-11 19:46:30,718 - step: 733, training_loss: 1.64587e+01
2025-07-11 19:46:36,377 - step: 734, training_loss: 1.66869e+01
2025-07-11 19:46:42,521 - step: 735, training_loss: 1.61325e+01
2025-07-11 19:46:48,272 - step: 736, training_loss: 1.65865e+01
2025-07-11 19:46:54,030 - step: 737, training_loss: 1.60818e+01
2025-07-11 19:46:59,842 - step: 738, training_loss: 1.55752e+01
2025-07-11 19:47:05,619 - step: 739, training_loss: 1.60075e+01
2025-07-11 19:47:11,433 - step: 740, training_loss: 1.65428e+01
2025-07-11 19:47:17,468 - step: 741, training_loss: 1.69066e+01
2025-07-11 19:47:23,264 - step: 742, training_loss: 1.65480e+01
2025-07-11 19:47:29,115 - step: 743, training_loss: 1.67024e+01
2025-07-11 19:47:35,158 - step: 744, training_loss: 1.63790e+01
2025-07-11 19:47:40,981 - step: 745, training_loss: 1.63178e+01
2025-07-11 19:47:46,806 - step: 746, training_loss: 1.57595e+01
2025-07-11 19:47:52,647 - step: 747, training_loss: 1.65758e+01
2025-07-11 19:47:58,491 - step: 748, training_loss: 1.68260e+01
2025-07-11 19:48:04,668 - step: 749, training_loss: 1.57362e+01
2025-07-11 19:48:10,534 - step: 750, training_loss: 1.62823e+01
2025-07-11 19:48:16,407 - step: 751, training_loss: 1.69680e+01
2025-07-11 19:48:22,259 - step: 752, training_loss: 1.61411e+01
2025-07-11 19:48:28,173 - step: 753, training_loss: 1.52800e+01
2025-07-11 19:48:34,470 - step: 754, training_loss: 1.71477e+01
2025-07-11 19:48:40,386 - step: 755, training_loss: 1.68686e+01
2025-07-11 19:48:46,285 - step: 756, training_loss: 1.66964e+01
2025-07-11 19:48:52,176 - step: 757, training_loss: 1.67025e+01
2025-07-11 19:48:58,086 - step: 758, training_loss: 1.63948e+01
2025-07-11 19:49:04,380 - step: 759, training_loss: 1.57982e+01
2025-07-11 19:49:10,283 - step: 760, training_loss: 1.55158e+01
2025-07-11 19:49:16,207 - step: 761, training_loss: 1.63041e+01
2025-07-11 19:49:22,150 - step: 762, training_loss: 1.60373e+01
2025-07-11 19:49:28,102 - step: 763, training_loss: 1.55966e+01
2025-07-11 19:49:34,528 - step: 764, training_loss: 1.62373e+01
2025-07-11 19:49:40,463 - step: 765, training_loss: 1.62614e+01
2025-07-11 19:49:46,431 - step: 766, training_loss: 1.60089e+01
2025-07-11 19:49:52,384 - step: 767, training_loss: 1.63401e+01
2025-07-11 19:49:58,377 - step: 768, training_loss: 1.58711e+01
2025-07-11 19:50:04,792 - step: 769, training_loss: 1.65767e+01
2025-07-11 19:50:10,770 - step: 770, training_loss: 1.61111e+01
2025-07-11 19:50:16,755 - step: 771, training_loss: 1.64376e+01
2025-07-11 19:50:22,738 - step: 772, training_loss: 1.66989e+01
2025-07-11 19:50:28,761 - step: 773, training_loss: 1.60903e+01
2025-07-11 19:50:35,094 - step: 774, training_loss: 1.63107e+01
2025-07-11 19:50:41,152 - step: 775, training_loss: 1.65570e+01
2025-07-11 19:50:47,176 - step: 776, training_loss: 1.64538e+01
2025-07-11 19:50:53,221 - step: 777, training_loss: 1.64146e+01
2025-07-11 19:50:59,293 - step: 778, training_loss: 1.63109e+01
2025-07-11 19:51:05,552 - step: 779, training_loss: 1.60911e+01
2025-07-11 19:51:11,644 - step: 780, training_loss: 1.60911e+01
2025-07-11 19:51:17,892 - step: 781, training_loss: 1.65838e+01
2025-07-11 19:51:23,945 - step: 782, training_loss: 1.61820e+01
2025-07-11 19:51:29,917 - step: 783, training_loss: 1.65343e+01
2025-07-11 19:51:36,059 - step: 784, training_loss: 1.62872e+01
2025-07-11 19:51:42,561 - step: 785, training_loss: 1.52666e+01
2025-07-11 19:51:48,642 - step: 786, training_loss: 1.61673e+01
2025-07-11 19:51:54,752 - step: 787, training_loss: 1.64121e+01
2025-07-11 19:52:01,297 - step: 788, training_loss: 1.61697e+01
2025-07-11 19:52:07,419 - step: 789, training_loss: 1.72146e+01
2025-07-11 19:52:13,813 - step: 790, training_loss: 1.63615e+01
2025-07-11 19:52:19,954 - step: 791, training_loss: 1.54954e+01
2025-07-11 19:52:26,087 - step: 792, training_loss: 1.58495e+01
2025-07-11 19:52:32,248 - step: 793, training_loss: 1.64345e+01
2025-07-11 19:52:38,390 - step: 794, training_loss: 1.56193e+01
2025-07-11 19:52:44,561 - step: 795, training_loss: 1.63435e+01
2025-07-11 19:52:50,734 - step: 796, training_loss: 1.60734e+01
2025-07-11 19:52:56,903 - step: 797, training_loss: 1.65494e+01
2025-07-11 19:53:03,141 - step: 798, training_loss: 1.55408e+01
2025-07-11 19:53:09,388 - step: 799, training_loss: 1.59169e+01
2025-07-11 19:53:15,558 - step: 800, training_loss: 1.67312e+01
2025-07-11 19:53:15,842 - step: 800, evaluation_loss: 1.63386e+01
2025-07-11 19:53:22,028 - step: 801, training_loss: 1.63460e+01
2025-07-11 19:53:28,244 - step: 802, training_loss: 1.55618e+01
2025-07-11 19:53:34,914 - step: 803, training_loss: 1.57524e+01
2025-07-11 19:53:41,141 - step: 804, training_loss: 1.57187e+01
2025-07-11 19:53:47,407 - step: 805, training_loss: 1.60849e+01
2025-07-11 19:53:53,628 - step: 806, training_loss: 1.59039e+01
2025-07-11 19:53:59,882 - step: 807, training_loss: 1.60456e+01
2025-07-11 19:54:06,148 - step: 808, training_loss: 1.63249e+01
2025-07-11 19:54:12,437 - step: 809, training_loss: 1.58034e+01
2025-07-11 19:54:18,713 - step: 810, training_loss: 1.59241e+01
2025-07-11 19:54:24,987 - step: 811, training_loss: 1.56001e+01
2025-07-11 19:54:31,703 - step: 812, training_loss: 1.59376e+01
2025-07-11 19:54:38,007 - step: 813, training_loss: 1.63214e+01
2025-07-11 19:54:44,281 - step: 814, training_loss: 1.57750e+01
2025-07-11 19:54:50,588 - step: 815, training_loss: 1.58915e+01
2025-07-11 19:54:56,894 - step: 816, training_loss: 1.55087e+01
2025-07-11 19:55:03,198 - step: 817, training_loss: 1.61621e+01
2025-07-11 19:55:09,534 - step: 818, training_loss: 1.60908e+01
2025-07-11 19:55:15,858 - step: 819, training_loss: 1.65409e+01
2025-07-11 19:55:22,167 - step: 820, training_loss: 1.59887e+01
2025-07-11 19:55:28,494 - step: 821, training_loss: 1.60413e+01
2025-07-11 19:55:35,206 - step: 822, training_loss: 1.59925e+01
2025-07-11 19:55:41,559 - step: 823, training_loss: 1.57956e+01
2025-07-11 19:55:48,129 - step: 824, training_loss: 1.60185e+01
2025-07-11 19:55:54,459 - step: 825, training_loss: 1.63242e+01
2025-07-11 19:56:01,204 - step: 826, training_loss: 1.59655e+01
2025-07-11 19:56:07,591 - step: 827, training_loss: 1.63796e+01
2025-07-11 19:56:14,137 - step: 828, training_loss: 1.57505e+01
2025-07-11 19:56:20,504 - step: 829, training_loss: 1.57992e+01
2025-07-11 19:56:26,877 - step: 830, training_loss: 1.62555e+01
2025-07-11 19:56:33,249 - step: 831, training_loss: 1.58592e+01
2025-07-11 19:56:39,535 - step: 832, training_loss: 1.57312e+01
2025-07-11 19:56:45,920 - step: 833, training_loss: 1.58876e+01
2025-07-11 19:56:52,323 - step: 834, training_loss: 1.62855e+01
2025-07-11 19:56:58,746 - step: 835, training_loss: 1.55885e+01
2025-07-11 19:57:05,509 - step: 836, training_loss: 1.61077e+01
2025-07-11 19:57:11,986 - step: 837, training_loss: 1.61011e+01
2025-07-11 19:57:18,673 - step: 838, training_loss: 1.70942e+01
2025-07-11 19:57:25,158 - step: 839, training_loss: 1.58849e+01
2025-07-11 19:57:31,970 - step: 840, training_loss: 1.60943e+01
2025-07-11 19:57:38,448 - step: 841, training_loss: 1.59142e+01
2025-07-11 19:57:44,902 - step: 842, training_loss: 1.55579e+01
2025-07-11 19:57:51,367 - step: 843, training_loss: 1.58286e+01
2025-07-11 19:57:57,851 - step: 844, training_loss: 1.60738e+01
2025-07-11 19:58:04,421 - step: 845, training_loss: 1.57093e+01
2025-07-11 19:58:10,896 - step: 846, training_loss: 1.59661e+01
2025-07-11 19:58:17,380 - step: 847, training_loss: 1.57347e+01
2025-07-11 19:58:23,870 - step: 848, training_loss: 1.59040e+01
2025-07-11 19:58:30,383 - step: 849, training_loss: 1.51377e+01
2025-07-11 19:58:36,931 - step: 850, training_loss: 1.66465e+01
2025-07-11 19:58:43,870 - step: 851, training_loss: 1.59681e+01
2025-07-11 19:58:50,410 - step: 852, training_loss: 1.61817e+01
2025-07-11 19:58:56,930 - step: 853, training_loss: 1.61971e+01
2025-07-11 19:59:03,454 - step: 854, training_loss: 1.64429e+01
2025-07-11 19:59:10,013 - step: 855, training_loss: 1.61529e+01
2025-07-11 19:59:16,588 - step: 856, training_loss: 1.51929e+01
2025-07-11 19:59:23,164 - step: 857, training_loss: 1.62664e+01
2025-07-11 19:59:29,723 - step: 858, training_loss: 1.56530e+01
2025-07-11 19:59:36,337 - step: 859, training_loss: 1.54341e+01
2025-07-11 19:59:43,365 - step: 860, training_loss: 1.60365e+01
2025-07-11 19:59:49,942 - step: 861, training_loss: 1.58346e+01
2025-07-11 19:59:56,551 - step: 862, training_loss: 1.55035e+01
2025-07-11 20:00:03,184 - step: 863, training_loss: 1.59088e+01
2025-07-11 20:00:09,829 - step: 864, training_loss: 1.58583e+01
2025-07-11 20:00:16,438 - step: 865, training_loss: 1.59371e+01
2025-07-11 20:00:23,057 - step: 866, training_loss: 1.55772e+01
2025-07-11 20:00:29,675 - step: 867, training_loss: 1.59480e+01
2025-07-11 20:00:36,340 - step: 868, training_loss: 1.60441e+01
2025-07-11 20:00:43,461 - step: 869, training_loss: 1.52181e+01
2025-07-11 20:00:50,111 - step: 870, training_loss: 1.54074e+01
2025-07-11 20:00:56,749 - step: 871, training_loss: 1.57797e+01
2025-07-11 20:01:03,400 - step: 872, training_loss: 1.57902e+01
2025-07-11 20:01:10,075 - step: 873, training_loss: 1.53513e+01
2025-07-11 20:01:16,759 - step: 874, training_loss: 1.51142e+01
2025-07-11 20:01:23,440 - step: 875, training_loss: 1.52828e+01
2025-07-11 20:01:30,119 - step: 876, training_loss: 1.53003e+01
2025-07-11 20:01:36,830 - step: 877, training_loss: 1.52323e+01
2025-07-11 20:01:44,009 - step: 878, training_loss: 1.54335e+01
2025-07-11 20:01:50,721 - step: 879, training_loss: 1.56707e+01
2025-07-11 20:01:57,440 - step: 880, training_loss: 1.53701e+01
2025-07-11 20:02:04,060 - step: 881, training_loss: 1.53814e+01
2025-07-11 20:02:10,787 - step: 882, training_loss: 1.54194e+01
2025-07-11 20:02:17,559 - step: 883, training_loss: 1.59417e+01
2025-07-11 20:02:24,304 - step: 884, training_loss: 1.53026e+01
2025-07-11 20:02:31,093 - step: 885, training_loss: 1.54706e+01
2025-07-11 20:02:37,864 - step: 886, training_loss: 1.56630e+01
2025-07-11 20:02:44,623 - step: 887, training_loss: 1.50459e+01
2025-07-11 20:02:51,381 - step: 888, training_loss: 1.62567e+01
2025-07-11 20:02:58,160 - step: 889, training_loss: 1.47420e+01
2025-07-11 20:03:05,370 - step: 890, training_loss: 1.51507e+01
2025-07-11 20:03:12,164 - step: 891, training_loss: 1.59233e+01
2025-07-11 20:03:19,099 - step: 892, training_loss: 1.57611e+01
2025-07-11 20:03:25,926 - step: 893, training_loss: 1.47625e+01
2025-07-11 20:03:32,733 - step: 894, training_loss: 1.55053e+01
2025-07-11 20:03:39,773 - step: 895, training_loss: 1.58326e+01
2025-07-11 20:03:46,577 - step: 896, training_loss: 1.55358e+01
2025-07-11 20:03:53,384 - step: 897, training_loss: 1.56667e+01
2025-07-11 20:04:00,192 - step: 898, training_loss: 1.54285e+01
2025-07-11 20:04:07,026 - step: 899, training_loss: 1.49324e+01
2025-07-11 20:04:14,299 - step: 900, training_loss: 1.52615e+01
2025-07-11 20:04:14,582 - step: 900, evaluation_loss: 1.57755e+01
2025-07-11 20:04:21,447 - step: 901, training_loss: 1.52871e+01
2025-07-11 20:04:28,348 - step: 902, training_loss: 1.57674e+01
2025-07-11 20:04:35,678 - step: 903, training_loss: 1.56409e+01
2025-07-11 20:04:42,553 - step: 904, training_loss: 1.57151e+01
2025-07-11 20:04:49,426 - step: 905, training_loss: 1.55474e+01
2025-07-11 20:04:56,331 - step: 906, training_loss: 1.56401e+01
2025-07-11 20:05:03,210 - step: 907, training_loss: 1.46286e+01
2025-07-11 20:05:10,144 - step: 908, training_loss: 1.50350e+01
2025-07-11 20:05:17,041 - step: 909, training_loss: 1.56548e+01
2025-07-11 20:05:23,945 - step: 910, training_loss: 1.47532e+01
2025-07-11 20:05:30,881 - step: 911, training_loss: 1.59411e+01
2025-07-11 20:05:37,835 - step: 912, training_loss: 1.53484e+01
2025-07-11 20:05:44,769 - step: 913, training_loss: 1.51567e+01
2025-07-11 20:05:51,721 - step: 914, training_loss: 1.56586e+01
2025-07-11 20:05:58,685 - step: 915, training_loss: 1.56028e+01
2025-07-11 20:06:05,955 - step: 916, training_loss: 1.55882e+01
2025-07-11 20:06:12,987 - step: 917, training_loss: 1.50783e+01
2025-07-11 20:06:19,952 - step: 918, training_loss: 1.51898e+01
2025-07-11 20:06:26,918 - step: 919, training_loss: 1.56194e+01
2025-07-11 20:06:33,941 - step: 920, training_loss: 1.50609e+01
2025-07-11 20:06:40,907 - step: 921, training_loss: 1.53796e+01
2025-07-11 20:06:47,913 - step: 922, training_loss: 1.50176e+01
2025-07-11 20:06:54,960 - step: 923, training_loss: 1.46388e+01
2025-07-11 20:07:02,401 - step: 924, training_loss: 1.49746e+01
2025-07-11 20:07:09,438 - step: 925, training_loss: 1.47389e+01
2025-07-11 20:07:16,438 - step: 926, training_loss: 1.52707e+01
2025-07-11 20:07:23,474 - step: 927, training_loss: 1.54079e+01
2025-07-11 20:07:30,523 - step: 928, training_loss: 1.49268e+01
2025-07-11 20:07:37,603 - step: 929, training_loss: 1.49201e+01
2025-07-11 20:07:44,660 - step: 930, training_loss: 1.51452e+01
2025-07-11 20:07:51,715 - step: 931, training_loss: 1.55795e+01
2025-07-11 20:07:58,859 - step: 932, training_loss: 1.52180e+01
2025-07-11 20:08:06,193 - step: 933, training_loss: 1.52129e+01
2025-07-11 20:08:13,678 - step: 934, training_loss: 1.47987e+01
2025-07-11 20:08:20,750 - step: 935, training_loss: 1.53735e+01
2025-07-11 20:08:27,832 - step: 936, training_loss: 1.54944e+01
2025-07-11 20:08:35,010 - step: 937, training_loss: 1.50476e+01
2025-07-11 20:08:42,169 - step: 938, training_loss: 1.51205e+01
2025-07-11 20:08:49,480 - step: 939, training_loss: 1.52308e+01
2025-07-11 20:08:56,599 - step: 940, training_loss: 1.51223e+01
2025-07-11 20:09:03,710 - step: 941, training_loss: 1.54020e+01
2025-07-11 20:09:10,951 - step: 942, training_loss: 1.53679e+01
2025-07-11 20:09:18,116 - step: 943, training_loss: 1.47488e+01
2025-07-11 20:09:25,258 - step: 944, training_loss: 1.47179e+01
2025-07-11 20:09:32,759 - step: 945, training_loss: 1.52635e+01
2025-07-11 20:09:40,111 - step: 946, training_loss: 1.50301e+01
2025-07-11 20:09:47,256 - step: 947, training_loss: 1.49956e+01
2025-07-11 20:09:54,423 - step: 948, training_loss: 1.54800e+01
2025-07-11 20:10:01,853 - step: 949, training_loss: 1.48366e+01
2025-07-11 20:10:09,030 - step: 950, training_loss: 1.51599e+01
2025-07-11 20:10:16,197 - step: 951, training_loss: 1.51685e+01
2025-07-11 20:10:23,396 - step: 952, training_loss: 1.48969e+01
2025-07-11 20:10:30,593 - step: 953, training_loss: 1.48542e+01
2025-07-11 20:10:37,800 - step: 954, training_loss: 1.50097e+01
2025-07-11 20:10:45,047 - step: 955, training_loss: 1.46775e+01
2025-07-11 20:10:52,262 - step: 956, training_loss: 1.52916e+01
2025-07-11 20:10:59,475 - step: 957, training_loss: 1.51287e+01
2025-07-11 20:11:06,780 - step: 958, training_loss: 1.48009e+01
2025-07-11 20:11:14,525 - step: 959, training_loss: 1.46388e+01
2025-07-11 20:11:21,779 - step: 960, training_loss: 1.46482e+01
2025-07-11 20:11:29,049 - step: 961, training_loss: 1.45148e+01
2025-07-11 20:11:36,602 - step: 962, training_loss: 1.57906e+01
2025-07-11 20:11:44,379 - step: 963, training_loss: 1.52381e+01
2025-07-11 20:11:51,671 - step: 964, training_loss: 1.53403e+01
2025-07-11 20:11:58,950 - step: 965, training_loss: 1.47106e+01
2025-07-11 20:12:06,526 - step: 966, training_loss: 1.53173e+01
2025-07-11 20:12:14,415 - step: 967, training_loss: 1.51865e+01
2025-07-11 20:12:21,722 - step: 968, training_loss: 1.49715e+01
2025-07-11 20:12:29,044 - step: 969, training_loss: 1.47054e+01
2025-07-11 20:12:36,660 - step: 970, training_loss: 1.47143e+01
2025-07-11 20:12:44,595 - step: 971, training_loss: 1.53323e+01
2025-07-11 20:12:51,919 - step: 972, training_loss: 1.56281e+01
2025-07-11 20:12:59,272 - step: 973, training_loss: 1.44181e+01
2025-07-11 20:13:06,881 - step: 974, training_loss: 1.43776e+01
2025-07-11 20:13:14,759 - step: 975, training_loss: 1.49809e+01
2025-07-11 20:13:22,097 - step: 976, training_loss: 1.43411e+01
2025-07-11 20:13:29,451 - step: 977, training_loss: 1.45909e+01
2025-07-11 20:13:36,931 - step: 978, training_loss: 1.48761e+01
2025-07-11 20:13:44,655 - step: 979, training_loss: 1.50798e+01
2025-07-11 20:13:52,036 - step: 980, training_loss: 1.45498e+01
2025-07-11 20:13:59,441 - step: 981, training_loss: 1.47350e+01
2025-07-11 20:14:06,958 - step: 982, training_loss: 1.48178e+01
2025-07-11 20:14:14,804 - step: 983, training_loss: 1.45868e+01
2025-07-11 20:14:22,237 - step: 984, training_loss: 1.47951e+01
2025-07-11 20:14:29,660 - step: 985, training_loss: 1.46586e+01
2025-07-11 20:14:37,097 - step: 986, training_loss: 1.51547e+01
2025-07-11 20:14:44,883 - step: 987, training_loss: 1.51598e+01
2025-07-11 20:14:52,325 - step: 988, training_loss: 1.50571e+01
2025-07-11 20:14:59,791 - step: 989, training_loss: 1.48976e+01
2025-07-11 20:15:07,257 - step: 990, training_loss: 1.40423e+01
2025-07-11 20:15:15,047 - step: 991, training_loss: 1.47366e+01
2025-07-11 20:15:22,493 - step: 992, training_loss: 1.46501e+01
2025-07-11 20:15:29,930 - step: 993, training_loss: 1.45590e+01
2025-07-11 20:15:37,413 - step: 994, training_loss: 1.45673e+01
2025-07-11 20:15:45,171 - step: 995, training_loss: 1.47948e+01
2025-07-11 20:15:52,677 - step: 996, training_loss: 1.51177e+01
2025-07-11 20:16:00,164 - step: 997, training_loss: 1.48053e+01
2025-07-11 20:16:07,711 - step: 998, training_loss: 1.42323e+01
2025-07-11 20:16:15,305 - step: 999, training_loss: 1.49266e+01
2025-07-11 20:16:22,795 - step: 1000, training_loss: 1.46563e+01
2025-07-11 20:16:23,079 - step: 1000, evaluation_loss: 1.48415e+01
2025-07-11 20:16:23,735 - Generating samples at step: 1000
2025-07-11 20:23:04,648 - step: 1001, training_loss: 1.46933e+01
2025-07-11 20:23:12,192 - step: 1002, training_loss: 1.47232e+01
2025-07-11 20:23:19,932 - step: 1003, training_loss: 1.44957e+01
2025-07-11 20:23:27,482 - step: 1004, training_loss: 1.50418e+01
2025-07-11 20:23:35,053 - step: 1005, training_loss: 1.54661e+01
2025-07-11 20:23:42,609 - step: 1006, training_loss: 1.45834e+01
2025-07-11 20:23:50,167 - step: 1007, training_loss: 1.46272e+01
2025-07-11 20:23:57,744 - step: 1008, training_loss: 1.46191e+01
2025-07-11 20:24:05,326 - step: 1009, training_loss: 1.44866e+01
2025-07-11 20:24:12,945 - step: 1010, training_loss: 1.49195e+01
2025-07-11 20:24:20,527 - step: 1011, training_loss: 1.43574e+01
2025-07-11 20:24:28,168 - step: 1012, training_loss: 1.43383e+01
2025-07-11 20:24:36,344 - step: 1013, training_loss: 1.47049e+01
2025-07-11 20:24:44,261 - step: 1014, training_loss: 1.48105e+01
2025-07-11 20:24:51,887 - step: 1015, training_loss: 1.41698e+01
2025-07-11 20:24:59,495 - step: 1016, training_loss: 1.54672e+01
2025-07-11 20:25:07,196 - step: 1017, training_loss: 1.50678e+01
2025-07-11 20:25:15,115 - step: 1018, training_loss: 1.50739e+01
2025-07-11 20:25:22,763 - step: 1019, training_loss: 1.48110e+01
2025-07-11 20:25:30,418 - step: 1020, training_loss: 1.48147e+01
2025-07-11 20:25:38,087 - step: 1021, training_loss: 1.48314e+01
2025-07-11 20:25:45,780 - step: 1022, training_loss: 1.49009e+01
2025-07-11 20:25:53,451 - step: 1023, training_loss: 1.46688e+01
2025-07-11 20:26:01,134 - step: 1024, training_loss: 1.48126e+01
2025-07-11 20:26:08,823 - step: 1025, training_loss: 1.51744e+01
2025-07-11 20:26:16,521 - step: 1026, training_loss: 1.45652e+01
2025-07-11 20:26:24,254 - step: 1027, training_loss: 1.52039e+01
2025-07-11 20:26:31,938 - step: 1028, training_loss: 1.53632e+01
2025-07-11 20:26:39,665 - step: 1029, training_loss: 1.39377e+01
2025-07-11 20:26:47,409 - step: 1030, training_loss: 1.45049e+01
2025-07-11 20:26:55,148 - step: 1031, training_loss: 1.47809e+01
2025-07-11 20:27:03,345 - step: 1032, training_loss: 1.45433e+01
2025-07-11 20:27:11,094 - step: 1033, training_loss: 1.39375e+01
2025-07-11 20:27:18,851 - step: 1034, training_loss: 1.50186e+01
2025-07-11 20:27:26,610 - step: 1035, training_loss: 1.47901e+01
2025-07-11 20:27:34,364 - step: 1036, training_loss: 1.50077e+01
2025-07-11 20:27:42,151 - step: 1037, training_loss: 1.49449e+01
2025-07-11 20:27:50,178 - step: 1038, training_loss: 1.44759e+01
2025-07-11 20:27:57,940 - step: 1039, training_loss: 1.50661e+01
2025-07-11 20:28:05,981 - step: 1040, training_loss: 1.43915e+01
2025-07-11 20:28:14,182 - step: 1041, training_loss: 1.51552e+01
2025-07-11 20:28:21,966 - step: 1042, training_loss: 1.51745e+01
2025-07-11 20:28:29,758 - step: 1043, training_loss: 1.40329e+01
2025-07-11 20:28:37,610 - step: 1044, training_loss: 1.50439e+01
2025-07-11 20:28:45,630 - step: 1045, training_loss: 1.42040e+01
2025-07-11 20:28:53,440 - step: 1046, training_loss: 1.46239e+01
2025-07-11 20:29:01,242 - step: 1047, training_loss: 1.51498e+01
2025-07-11 20:29:09,088 - step: 1048, training_loss: 1.46872e+01
2025-07-11 20:29:16,926 - step: 1049, training_loss: 1.43934e+01
2025-07-11 20:29:24,833 - step: 1050, training_loss: 1.41756e+01
2025-07-11 20:29:33,207 - step: 1051, training_loss: 1.47114e+01
2025-07-11 20:29:41,099 - step: 1052, training_loss: 1.48671e+01
2025-07-11 20:29:49,020 - step: 1053, training_loss: 1.47782e+01
2025-07-11 20:29:56,895 - step: 1054, training_loss: 1.45729e+01
2025-07-11 20:30:04,782 - step: 1055, training_loss: 1.42199e+01
2025-07-11 20:30:12,681 - step: 1056, training_loss: 1.42687e+01
