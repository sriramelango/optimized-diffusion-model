defaults:
  - model: unet1d_gto
  - data: gto_halo_1d
  - _self_

# Training configuration for 1D GTO Halo diffusion model
# EXACT parameters matching original GTO Halo DM (batch_size=2000, timesteps=500)

ngpus: 1
dataroot: datasets

training:
  # EXACT MATCH to original GTO Halo DM training parameters
  batch_size: 2000  # Original GTO Halo DM batch size
  n_iters: 400000    # Reduced from 100k for faster training
  continuous: true
  likelihood_weighting: false
  reduce_mean: true
  snapshot_freq: 500
  snapshot_freq_for_preemption: 10000  # Checkpoint for preemption every 1000 steps
  log_freq: 50
  eval_freq: 500
  snapshot_sampling: true
  drop_label: 0.1   # Original cond_drop_prob from GTO Halo DM

optim:
  weight_decay: 0
  optimizer: Adam
  lr: 2e-4  # Original learning rate
  beta1: 0.9
  beta2: 0.999
  eps: 1e-8
  warmup: 5000
  grad_clip: 1.0

eval:
  batch_size: 2000  # Match training batch size
  num_samples: 10000
  begin_ckpt: 1
  end_ckpt: 8

# SDE configuration - EXACT match to original (500 timesteps)
sde:
  name: vesde
  sigma_min: 1e-2
  sigma_max: 50
  num_scales: 500  # EXACT match to original timesteps=500

# Sampling configuration
sampling:
  method: pc
  predictor: euler_maruyama
  corrector: none
  denoiser: none
  n_steps_each: 1
  noise_removal: true
  probability_flow: false
  snr: 0.005
  guidance_scale: 1.5

seed: 42
device: cuda
checkpointing: true

# Hydra configuration
hydra:
  run:
    dir: ../Training Runs/${now:%Y.%m.%d_%H%M%S}_gto_1d
  sweep:
    dir: ../Training Runs/${now:%Y.%m.%d_%H%M%S}_gto_1d
    subdir: ${hydra.job.num}

checkpoint_path: null
