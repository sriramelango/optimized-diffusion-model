defaults:
  - _self_
  - model: ncsnpp
  - data: gto_halo
  - override hydra/launcher: submitit_slurm

ngpus: 1
dataroot: datasets

training:
  batch_size: 448  # Optimized for 80GB GPU
  n_iters: 40000
  snapshot_freq: 500
  log_freq: 1
  eval_freq: 200
  snapshot_freq_for_preemption: 10000
  snapshot_sampling: True
  likelihood_weighting: False
  reduce_mean: False
  drop_label: 0.2

eval:
  batch_size: 448  # Optimized for 80GB GPU

sde: 
  name: vesde
  sigma_min: 0.005
  sigma_max: 10
  num_scales: 2000

sampling:
  n_steps_each: 1
  noise_removal: True
  probability_flow: False
  snr: 0.005
  guidance_scale: 1.5
  method: pc
  predictor: euler_maruyama
  corrector: none
  denoiser: none

optim:
  weight_decay: 0
  optimizer: Adam
  lr: 0.00016  # Increased from 0.00008 to compensate for batch size reduction (512->256)
  beta1: 0.9
  beta2: 0.999
  eps: 1e-8
  warmup: 8000
  grad_clip: 1.0

hydra:
  run:
    dir: ../Training Runs/${now:%Y.%m.%d_%H%M%S}
  sweep:
    dir: ../Training Runs/${now:%Y.%m.%d_%H%M%S}
    subdir: ${hydra.job.num}
  # launcher:
  #   max_num_timeout: null
  #   timeout_min: null
  #   partition: null
  #   account: null
  #   mem_gb: null
  #   cpus_per_task: null
  #   gpus_per_node: ${ngpus}
  #   constraint: null

checkpoint_path: null
